{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project 3: Plausible Utopia \n",
    "\n",
    "### Classification Modeling on Subreddits to Classify Futurists vs. Scientists\n",
    "\n",
    "### Notebook 2 of 3: Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LassoCV, RidgeCV, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, classification_report, accuracy_score, roc_auc_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "     \n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import re\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import string\n",
    "\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "##this will hide deprecation/future warnings\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "pd.set_option('display.max_row', 200) # Set ipython's max row display\n",
    "pd.set_option('display.max_columns', 85) # Set iPython's max column count\n",
    "pd.set_option('display.max_colwidth', 1_000) # Set iPython's max column width\n",
    "\n",
    "# pseudo-markdown in code cells\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "# ref: https://discuss.analyticsvidhya.com/t/how-to-make-a-text-bold-within-print-statement-in-ipython-notebook/14552/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1800, 7)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the cleaned data\n",
    "subred = pd.read_csv('../data/cleaned_data/cleaned_df_1.csv', index_col = 'id')\n",
    "subred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set feature matrix and target variable\n",
    "\n",
    "X = subred['title']\n",
    "y = subred['subreddit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read the following from ISLR:\n",
    "\n",
    "5.2 - The Bootstrap. (You'll want to know the bootstrap well as it will be embedded in methods we'll discuss next week.)\n",
    "Chapter 8 - Tree Based Methods. (We'll learn about classification and regression trees, random forests, bagging and boosting next week.)\n",
    "9.1-9.5 (Support Vector Machines and related methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify an optimal model with a pipeline and GridSearch\n",
    "\n",
    "### Train-test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Ref: 5.05 lesson**\n",
    " \n",
    " Features can be completely different in train/test\n",
    " \n",
    "**IMPORTANT** Instead of splitting we can use entire dataset combined with cross-validation\n",
    " \n",
    " Depending on how big dataset is, significant words in train set will probably appear in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1206,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1206,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(594,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(594,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size = 0.33,\n",
    "                                                    stratify = y,\n",
    "                                                    random_state = 42)\n",
    "\n",
    "display(X_train.shape)\n",
    "display(y_train.shape)\n",
    "\n",
    "display(X_test.shape)\n",
    "display(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline accuracy\n",
    "\n",
    "**51.7% is the baseline accuracy percentage we compare with the model's accuracy.**\n",
    "\n",
    "**If the model does better than the baseline, then it is better than null model (predicting the majority / plurality class).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    0.517222\n",
       "0    0.482778\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1    0.517413\n",
       "0    0.482587\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1    0.516835\n",
       "0    0.483165\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(y.value_counts(normalize=True))\n",
    "\n",
    "display(y_train.value_counts(normalize=True))\n",
    "\n",
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline 1\n",
    "\n",
    "**CountVectorizer (transformer)**:\n",
    "\n",
    "\n",
    "\n",
    "**Multinomial Naive Bayes (estimator)**:\n",
    "\n",
    "* Fast modeling algorithm\n",
    "* Variables are positive integers\n",
    "* Assumes all variables are independent (which is not realistic in NLP, but this assumption is accepted anyway)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set a pipeline up with two stages:\n",
    "# 1. CountVectorizer (transformer)\n",
    "# 2. Multinomial Naive Bayes (estimator)\n",
    "\n",
    "pipe_cvec_nb = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('nb', MultinomialNB())    # Naive Bayes\n",
    "])\n",
    "\n",
    "\n",
    "# Search over the following values of hyperparameters:\n",
    "# Maximum number of features fit\n",
    "# Minimum number of documents needed to include token\n",
    "# Maximum number of documents needed to include token\n",
    "# Check (individual tokens) and also check (individual tokens and 2-grams).\n",
    "\n",
    "pipe_cvec_nb_params = {\n",
    "    'cvec__max_features': [1_000, 2_000, 3_000, 4_000, 5_000],\n",
    "    'cvec__min_df': [1, 2],\n",
    "    'cvec__max_df': [.98, .99],\n",
    "    'cvec__ngram_range': [(1,1), (1,2)]\n",
    "}\n",
    "\n",
    "# Instantiate GridSearchCV.\n",
    "\n",
    "gs_cvec_nb = GridSearchCV(pipe_cvec_nb, # what object are we optimizing?\n",
    "                  param_grid = pipe_cvec_nb_params, # what parameters values are we searching?\n",
    "                  cv=5)      # 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('nb', MultinomialNB())]),\n",
       "             param_grid={'cvec__max_df': [0.98, 0.99],\n",
       "                         'cvec__max_features': [1000, 2000, 3000, 4000, 5000],\n",
       "                         'cvec__min_df': [1, 2],\n",
       "                         'cvec__ngram_range': [(1, 1), (1, 2)]})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit GridSearch to data.\n",
    "gs_cvec_nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Grid searched:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': [1000, 2000, 3000, 4000, 5000],\n",
       " 'cvec__min_df': [1, 2],\n",
       " 'cvec__max_df': [0.98, 0.99],\n",
       " 'cvec__ngram_range': [(1, 1), (1, 2)]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Best score**: 0.8383"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Best estimator / parameters:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cvec',\n",
       "                 CountVectorizer(max_df=0.98, max_features=2000,\n",
       "                                 ngram_range=(1, 2))),\n",
       "                ('nb', MultinomialNB())])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.98,\n",
       " 'cvec__max_features': 2000,\n",
       " 'cvec__min_df': 1,\n",
       " 'cvec__ngram_range': (1, 2)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_cvec__max_df</th>\n",
       "      <th>param_cvec__max_features</th>\n",
       "      <th>param_cvec__min_df</th>\n",
       "      <th>param_cvec__ngram_range</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.130776</td>\n",
       "      <td>0.004719</td>\n",
       "      <td>0.017161</td>\n",
       "      <td>0.000380</td>\n",
       "      <td>0.99</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'cvec__max_df': 0.99, 'cvec__max_features': 2000, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 2)}</td>\n",
       "      <td>0.855372</td>\n",
       "      <td>0.842324</td>\n",
       "      <td>0.86722</td>\n",
       "      <td>0.796680</td>\n",
       "      <td>0.829876</td>\n",
       "      <td>0.838294</td>\n",
       "      <td>0.024278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.139220</td>\n",
       "      <td>0.012633</td>\n",
       "      <td>0.022875</td>\n",
       "      <td>0.008768</td>\n",
       "      <td>0.98</td>\n",
       "      <td>2000</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'cvec__max_df': 0.98, 'cvec__max_features': 2000, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 2)}</td>\n",
       "      <td>0.855372</td>\n",
       "      <td>0.842324</td>\n",
       "      <td>0.86722</td>\n",
       "      <td>0.796680</td>\n",
       "      <td>0.829876</td>\n",
       "      <td>0.838294</td>\n",
       "      <td>0.024278</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.127107</td>\n",
       "      <td>0.004198</td>\n",
       "      <td>0.017386</td>\n",
       "      <td>0.000824</td>\n",
       "      <td>0.99</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'cvec__max_df': 0.99, 'cvec__max_features': 5000, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 2)}</td>\n",
       "      <td>0.851240</td>\n",
       "      <td>0.838174</td>\n",
       "      <td>0.86722</td>\n",
       "      <td>0.788382</td>\n",
       "      <td>0.838174</td>\n",
       "      <td>0.836638</td>\n",
       "      <td>0.026389</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.151211</td>\n",
       "      <td>0.015828</td>\n",
       "      <td>0.022732</td>\n",
       "      <td>0.006197</td>\n",
       "      <td>0.98</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'cvec__max_df': 0.98, 'cvec__max_features': 5000, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 2)}</td>\n",
       "      <td>0.851240</td>\n",
       "      <td>0.838174</td>\n",
       "      <td>0.86722</td>\n",
       "      <td>0.788382</td>\n",
       "      <td>0.838174</td>\n",
       "      <td>0.836638</td>\n",
       "      <td>0.026389</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.049310</td>\n",
       "      <td>0.000819</td>\n",
       "      <td>0.009989</td>\n",
       "      <td>0.000619</td>\n",
       "      <td>0.99</td>\n",
       "      <td>4000</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'cvec__max_df': 0.99, 'cvec__max_features': 4000, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 1)}</td>\n",
       "      <td>0.834711</td>\n",
       "      <td>0.842324</td>\n",
       "      <td>0.86722</td>\n",
       "      <td>0.796680</td>\n",
       "      <td>0.834025</td>\n",
       "      <td>0.834992</td>\n",
       "      <td>0.022633</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "25       0.130776      0.004719         0.017161        0.000380   \n",
       "5        0.139220      0.012633         0.022875        0.008768   \n",
       "37       0.127107      0.004198         0.017386        0.000824   \n",
       "17       0.151211      0.015828         0.022732        0.006197   \n",
       "32       0.049310      0.000819         0.009989        0.000619   \n",
       "\n",
       "   param_cvec__max_df param_cvec__max_features param_cvec__min_df  \\\n",
       "25               0.99                     2000                  1   \n",
       "5                0.98                     2000                  1   \n",
       "37               0.99                     5000                  1   \n",
       "17               0.98                     5000                  1   \n",
       "32               0.99                     4000                  1   \n",
       "\n",
       "   param_cvec__ngram_range  \\\n",
       "25                  (1, 2)   \n",
       "5                   (1, 2)   \n",
       "37                  (1, 2)   \n",
       "17                  (1, 2)   \n",
       "32                  (1, 1)   \n",
       "\n",
       "                                                                                                params  \\\n",
       "25  {'cvec__max_df': 0.99, 'cvec__max_features': 2000, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 2)}   \n",
       "5   {'cvec__max_df': 0.98, 'cvec__max_features': 2000, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 2)}   \n",
       "37  {'cvec__max_df': 0.99, 'cvec__max_features': 5000, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 2)}   \n",
       "17  {'cvec__max_df': 0.98, 'cvec__max_features': 5000, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 2)}   \n",
       "32  {'cvec__max_df': 0.99, 'cvec__max_features': 4000, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 1)}   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "25           0.855372           0.842324            0.86722   \n",
       "5            0.855372           0.842324            0.86722   \n",
       "37           0.851240           0.838174            0.86722   \n",
       "17           0.851240           0.838174            0.86722   \n",
       "32           0.834711           0.842324            0.86722   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "25           0.796680           0.829876         0.838294        0.024278   \n",
       "5            0.796680           0.829876         0.838294        0.024278   \n",
       "37           0.788382           0.838174         0.836638        0.026389   \n",
       "17           0.788382           0.838174         0.836638        0.026389   \n",
       "32           0.796680           0.834025         0.834992        0.022633   \n",
       "\n",
       "    rank_test_score  \n",
       "25                1  \n",
       "5                 1  \n",
       "37                3  \n",
       "17                3  \n",
       "32                5  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "printmd('**Grid searched:**')\n",
    "display(gs_cvec_nb.param_grid)\n",
    "printmd(f'**Best score**: {round(gs_cvec_nb.best_score_, 4)}')\n",
    "printmd('**Best estimator / parameters:**')\n",
    "display(gs_cvec_nb.best_estimator_)\n",
    "display(gs_cvec_nb.best_params_)\n",
    "\n",
    "pd.DataFrame(gs_cvec_nb.cv_results_).sort_values('rank_test_score').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "credit: NLP II: `CountVectorizer`, `TfidfVectorizer`, and Modeling lesson. _Authors: Dave Yerrington (SF), Justin Pounders (ATL), Riley Dallas (ATX), Matt Brems (DC), Noelle Brown (DEN)_"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATgAAAEWCAYAAADy2YssAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de7wVddn38c8XKC0T8Ui4lcQS5aCgkN5pKmoliGfTMB+z9PZ0Z5rWU0k9ZXbbY6aJd3bwkI9KhYfM1CQPaWaWpmwgT2iieEAIBM3wEMJe1/PHzMYF7rX2zGatvfaa/X33mtdeaw6/uTbE5W/mN/O7FBGYmRVRn0YHYGZWL05wZlZYTnBmVlhOcGZWWE5wZlZYTnBmVlhOcAUj6T2SbpH0qqTr16KdoyTdUcvYGkXS7pKebHQc1v3k5+AaQ9KngTOA7YBlwGzgnIi4by3bPRr4ArBrRKxc60B7OEkBbBMRcxsdi/U87sE1gKQzgCnAd4GBwGDgx8BBNWj+A8Dfe0Nyy0JSv0bHYA0UEV66cQE2AF4DDq+yzzokCXBBukwB1km3jQPmA18CFgMLgc+l274NvAWsSM9xHHAW8POytrcCAuiXfv8s8AxJL3IecFTZ+vvKjtsVeAh4Nf25a9m2e4DvAH9O27kD2KTC79Ye/1fK4j8Y2A/4O/AyMLls/52B+4F/pvteDLw73XZv+ru8nv6+nypr/6vAP4Cp7evSYz6YnmOn9PvmwBJgXKP/v+Gl9kvDA+htCzAeWNmeYCrsczbwALAZsCnwF+A76bZx6fFnA+9KE8MbwIbp9jUTWsUEB6wH/AvYNt02CBiRfl6V4ICNgFeAo9Pjjky/b5xuvwd4GhgKvCf9fm6F3609/m+m8R8PvAT8ElgfGAH8G9g63X8M8B/pebcC5gBfLGsvgA910P73SP5D8Z7yBJfuc3zaznuB24HzG/3/Cy/1WXyJ2v02BpZE9UvIo4CzI2JxRLxE0jM7umz7inT7ioiYTtJ72baL8ZSAkZLeExELI+KxDvaZCDwVEVMjYmVETAOeAA4o2+f/RcTfI+JN4DpgdJVzriC537gCuAbYBLgoIpal538M2AEgIloj4oH0vM8ClwB7ZvidvhURy9N4VhMRlwFPAX8lSepf76Q9a1JOcN1vKbBJJ/eGNgeeK/v+XLpuVRtrJMg3gPflDSQiXie5rDsJWCjpVknbZYinPaaWsu//yBHP0ohoSz+3J6BFZdvfbD9e0lBJv5X0D0n/IrlvuUmVtgFeioh/d7LPZcBI4IcRsbyTfa1JOcF1v/tJLsEOrrLPApLBgnaD03Vd8TrJpVi795dvjIjbI+LjJD2ZJ0j+4XcWT3tML3Yxpjx+QhLXNhHRH5gMqJNjqj4aIOl9JPc1fwacJWmjWgRqPY8TXDeLiFdJ7j/9SNLBkt4r6V2SJkg6L91tGvANSZtK2iTd/+ddPOVsYA9JgyVtAJzZvkHSQEkHSloPWE5yqdvWQRvTgaGSPi2pn6RPAcOB33YxpjzWJ7lP+Frauzx5je2LgK1ztnkR0BoR/wncCvx0raO0HskJrgEi4gckz8B9g+QG+wvAKcBv0l3+G5gBPAw8AsxM13XlXHcC16ZttbJ6UupDMhq7gGRkcU/gvzpoYymwf7rvUpIR0P0jYklXYsrpy8CnSUZnLyP5XcqdBVwl6Z+SjuisMUkHkQz0nJSuOgPYSdJRNYvYegw/6GtmheUenJkVlhOcmRWWE5yZFZYTnJkVVo96EXnDjTeOlsGDGx2G5fDY7NmNDsFyiojOniOsavz48bFkSbYB9NbW1tsjYvzanG9t9KgE1zJ4ML+65+5Gh2E5DBvgZ2R7myVLljBjxoxM+6bPcTZMj0pwZtYcSk3yeJkTnJnlEgRt0dELLz2PE5yZ5Vaq/rpvj+EEZ2a5BFCKUqPDyMSPiZhZbiUi01KNpC0l/UHSHEmPSTotXX+WpBclzU6X/cqOOVPSXElPStq3szjdgzOzfCJqNciwEvhSRMyUtD7QKunOdNuFEXF++c6ShgOTSGZ93hz4vaShZXMLvoN7cGaWS1CbHlw6g/TM9PMykmnkW6occhBwTTpT8zxgLknNjoqc4MwslwDaIjItWUnaCtiRZBp5gFMkPSzpCkkbputaSKYWazef6gnRCc7M8iull6mdLSTT888oW05Ys610huUbSIoJ/YtkFucPktT1WAhc0L5rB6FUzaK+B2dmueW4B7ckIsZW2ijpXSTJ7RcR8WuAiFhUtv0y3p6kdT6wZdnhW9DJVP7uwZlZLpHx/luGUVSR1MWYk85y3b5+UNluhwCPpp9vBiZJWkfSEGAb4MFq53APzsxyK9XmOd/dSMphPiKpfdaGycCRkkaTXH4+C5wIEBGPSboOeJxkBPbz1UZQwQnOzHKKINcAQuV24j46vq82vcox5wDnZD2HE5yZ5VajHlzdOcGZWS7Jq1rNkeGc4MwsN/fgzKywmiS/OcGZWT7JJWqjo8jGCc7M8gloa47ZkpzgzCwf9+DMrNCaZBDVCc7Mcgr34MyswNyDM7NCCjzIYGYF5h6cmRVTQERH78j3PE5wZpZL4B6cmRVYk5RFdYIzs/zcgzOzYgootTXHPTjXZDCz/CLjUkWVyvbfl/REWjbwRkkD0vVbSXqzrOL9TzsL0z04M8slUK1GUStVtr8TODMiVkr6HnAm8NX0mKcjYnTWEzjBmVk+UZtBhohYSFL3lIhYJmkO0BIRd5Tt9gDwya6ew5eoZpZf9kvUTgs/Q4eV7dsdC/yu7PsQSbMk/VHS7p2F6R6cmeWWowdXtfAzdFjZvn3910kuY3+RrloIDI6IpZLGAL+RNKL8mDU5wZlZPgFRo1HUjirbp+uPAfYH9olIHkqJiOXA8vRzq6SngaHAjErtO8GZWX41eA6uSmX78SSDCntGxBtl6zcFXo6INklbk1S2f6baOZzgzCyfAGrzJkOlyvb/A6wD3JnkQB6IiJOAPYCzJa0E2oCTIuLlaidwgjOz/Gozipqrsn1E3EByOZuZE5yZ5eZXtcysmIJkbLMJOMGZWX7uwZlZIdVukKHunODMLDc5wZlZYTnBmVkhZZgKqadwgjOz3LSyOTKcE5yZ5eNBBjMrrkCl5ujBeT64tbRw/nyO2f9AJu68C/v/x0e4+ierz6J8xQ9/yLABG/HK0qWr1l36gwvZd8cxTBi7M/fddVd3h2wd6NOnDzNnzuSWW24B4JprrmHWrFnMmjWLefPmMWvWrAZH2MPUYMry7lDXHlw6K8BFQF/g8og4t57na4S+/frxlf/+DiNGj+L1Zcs4bNze7LrXOD603XYsnD+fv/zhHgZtscWq/ec+8QTTb/g1tzzwFxYv/AfHHnwIv2t9iL59+zbwt7DTTjuNOXPm0L9/fwAmTZq0atv555/Pq6++2qjQep7APThJfYEfAROA4cCRkobX63yNstn738+I0aMAWG/99fng0KEsWrgQgHMnf50vf/vbpDMiAHD39N+x32GH8u511mGLrT7A4K2H8HBra0Nit0RLSwsTJ07k8ssv73D7EUccwbRp07o5qh6uFNmWBqvnJerOwNyIeCYi3gKuAQ6q4/ka7sXnnmfOIw8zaswY7p7+OwYOGsR2249cbZ9FCxfy/paWVd8Hbr45i9OEaI0xZcoUvvKVr1AqvfPO+e67786iRYuYO3duAyLrmRTJKGqWpdHqmeBagBfKvs9P161G0gnt87W/snRJHcOpr9dfe41TP3MMX/vud+nbrx+XXHABX5g8+R37RQfTMKjDGWOsO0ycOJHFixczc+bMDrcfeeSR7r29QzLIkGVptHreg+voX+07fuOIuBS4FGDkjjs2/k+kC1asWMFpnzmGAw7/JJ848AD+/tjjzH/ueQ7+aFITY9GCBRy25ziuvev3vH/zzfnHiy+uOnbRggVsOuj9jQq919ttt9048MAD2W+//Vh33XXp378/U6dO5eijj6Zv374ceuihjBkzptFh9iwBapL5kurZg5sPbFn2fQtgQR3P1xARwTdOOZWthw7ls6d8HoChI4bz57l/565H/sZdj/yNgZtvzg1/vIdNBw5krwnjmX7Dr3lr+XLmP/sczz39DDv4H1DDTJ48mS233JIhQ4YwadIk7r77bo4++mgAPvaxj/HEE0/wYtl/kCxVKmVbGqyeCe4hYBtJQyS9G5gE3FzH8zXEzAf+ys3XXstf7/0Th3x0Dw756B788Y47K+6/zbBhjD/kYPbf5SMc/8nD+T/nn+cR1B5q0qRJvjytoBaXqFUq228k6U5JT6U/Nyw75kxJcyU9KWnfTuPs6J5QrUjaD5hC8pjIFRFxTrX9R+64Y/zqnrvrFo/V3rABGzU6BMsp1rIs/bAPjoqr/+/tmfbd+VODWiuVDZQ0CBhUXtkeOBj4LElxmXMlfQ3YMCK+mj6FMY1kAHNz4PfA0Ihoq3T+uj4HFxHTqTC/upk1JwGqQWn7SpXtSZ62GJfudhVwD0mVrYOAa9LygfMkzSVJdvdXOodf1TKzfPI96LuJpPK6pZemA4urWaOy/cA0+RERCyVtlu7WAjxQdliHT2aUc4Izs5wizwBC7sr25Q/Gr7lrx8FU5gRnZvkEqEYjpBUq2y+SNCjtvQ0CFqfrcz+Z4ZftzSw3RWRaqrZRobI9ydMWx6SfjwFuKls/SdI6koaQVLZ/sNo53IMzs3wi0Mqa1A2sVNn+XOA6SccBzwOHJ6eNxyRdBzxOUrjw89VGUMEJzsxyElGrUdRKle0B9qlwzDlA1cfNyjnBmVl+PeAthSyc4MwsnwhUqnpl2GM4wZlZbrW4RO0OTnBmlp8vUc2skCJQ24pGR5GJE5yZ5RTgS1QzKypVf/ysx3CCM7N8IsCjqGZWWL5ENbNCihK0vdXoKDJxgjOzXJIJL32JamaFFOAEZ2ZFFEAnk3j0GE5wZpaTe3BmVlThBGdmhRVEyaOoZlZUNerBSboC2B9YHBEj03XXAtumuwwA/hkRo9PKW3OAJ9NtD0TESdXad4Izs5xqeol6JXAxcPWq1iM+1f5Z0gXAq2X7Px0Ro7M27gRnZvlEEFGTmgxExL1pz+wd0qI0RwB7d7V9V9Uys5yCoC3TspZ2BxZFxFNl64ZImiXpj5J276yBij04ST+kSlHViDg1V6hmVhC5BhkyVbav4EhgWtn3hcDgiFgqaQzwG0kjIuJflRqodok6o8o2M+ulgiDIfInaaWX7jkjqBxwKjFl13ojlwPL0c6ukp4GhVMlVFRNcRFy1xgnXi4jX8wZqZsXTDW8yfAx4IiLmt6+QtCnwckS0SdqapPDzM9Ua6fQenKSPSHqcZHgWSaMk/XitQjezJla7e3CSpgH3A9tKmp8WewaYxOqXpwB7AA9L+hvwK+CkiHi5WvtZRlGnAPsCNwNExN8k7ZHhODMrqFr14CLiyArrP9vBuhuAG/K0n+kxkYh4IRmxXaU53tMws5oLglKTpIAsCe4FSbsCIendwKmkl6tm1gtFUIrljY4ikywJ7iTgIqAFeBG4Hfh8PYMys54sKBXlZfuIWAIc1Q2xmFkTiHSQoRlkGUXdWtItkl6StFjSTekQrZn1UiXaMi2NluVVrV8C1wGDgM2B63nn8K2Z9RpRqASniJgaESvT5edUeYXLzIotgFK0ZVoardq7qBulH/8g6WvANSS/26eAW7shNjPrkUq00fwTXraSJLT2B+BOLNsWwHfqFZSZ9VwBtPWAy88sqr2LOqQ7AzGzZlGsB32RNBIYDqzbvi4irq58hJkVVUBxEpykbwHjSBLcdGACcB9lUwybWW9SrB7cJ4FRwKyI+JykgcDl9Q3LzHqqIFjBikaHkUmWBPdmRJQkrZTUH1gM+EFfs14quUQtNTqMTLIkuBmSBgCXkYysvgY8WNeozKwHi+YfRW0XEf+VfvyppNuA/hHxcH3DMrOeKpkuqcl7cJJ2qrYtImbWJyQz6+mK0IO7oMq2YC1qFVby2OzZDB+wca2btTqK8Ft7zWTs2Nz1X94hmUukNj24CpXtzwKOB15Kd5scEdPTbWcCx5FMuntqRNxerf1qD/rutdbRm1nhBLAie1WtzlzJGpXtUxdGxPnlKyQNJ6nVMIJk4o/fSxoaVeZPd+FnM8ulvQeXZem0rYh7gaqFY8ocBFwTEcsjYh4wF9i52gFOcGaWW5tKmRbSws9lywkZT3GKpIclXSFpw3RdC/BC2T7z03UVZXpVy8ysXc57cF0p/PwTksk82if1uAA4lrcn/lg9nCqyzOgrSf9L0jfT74MlVe0Wmlmx1eoStSMRsSgi2iKiRPL8bXu+mQ9sWbbrFsCCam1luUT9MfARoL1+4TLgR7kiNrPCSKZLylb6uSskDSr7egjwaPr5ZmCSpHUkDSGpbF/1pYMsl6i7RMROkmYBRMQraflAM+uFguCtGj0Hl1a2H0dyr24+8C1gnKTRJLn0WdK5KCPiMUnXAY8DK4HPVxtBhWwJboWkvunJkLQpNMljzGZWc0kPrjYpoEJl+59V2f8c4Jys7WdJcP8D3AhsJukcktlFvpH1BGZWPF29/OxuWd5F/YWkVmAfklGMgyPCle3NeqlYi/tr3S3LhJeDgTeAW8rXRcTz9QzMzHqm9kGGZpDlEvVW3i4+sy4wBHiS5HUJM+tlAnhLzXEbPssl6vbl39NZRk6ssLuZ9QJF6sGtJiJmSvpwPYIxs56vaPfgzij72gfYibenMTGzXia5B9ccsvTg1i/7vJLkntwN9QnHzJpBIXpw6QO+74uI/91N8ZhZDxdAW3Pkt6pTlveLiJXVpi43s94ngLcK0IN7kOR+22xJNwPXA6+3b4yIX9c5NjPrgYp2D24jYClJDYb25+ECcIIz66WKkOA2S0dQH+XtxNauOfqnZlZzRenB9QXeRxdm0TSzYmv6QQZgYUSc3W2RmFlTKEoPrqOem5n1cknZwOZQLcHt021RmFnTSJ6Da47+T8WaDBGRtVahmfUybRmXzqRlARdLerRs3fclPZGWDbxR0oB0/VaS3pQ0O11+2ln7rotqZrkEUAplWjK4Ehi/xro7gZERsQPwd+DMsm1PR8TodDmps8ad4Mwst1r14DqqbB8Rd0TEyvTrAyTlAbvECc7McokQKzIudL2yfbtjgd+VfR8iaZakP0ravbODXdnezHJpv0TNqCuV7QGQ9HWSGYx+ka5aCAyOiKWSxgC/kTQiIv5VqQ0nODPLLUeC6xJJxwD7A/tERABExHJgefq5VdLTwFBgRqV2nODMLJfkQd/6JThJ44GvAntGxBtl6zcFXo6INklbk1S2f6ZaW05wZpZbqUavalWobH8msA5wpySAB9IR0z2AsyWtJBnDOKmzx9mc4Mwsl5z34Kq3laOyfUTcQM7ZxJ3gzCyfECtLzfEAhhOcmeVSyx5cvTnBmVlu4QRnZkXlHpyZFVJkf8+04ZzgzCy3Ng8ymFkRBb4HZ2YF5ktUMyumkHtwZlZcUXKCM7MC8j04MyuugFKbR1HNrJB8D87MCsz34MysmAJokh5cc1xIN5k+ffrQOrOVm2+5GYBRo0bxl/v/wsxZM3nwoQf58Ic/3OAIe7cXXniBvfbai2HDhjFixAguuugiAM466yxaWloYPXo0o0ePZvr06QC89dZbfO5zn2P77bdn1KhR3HPPPQ2MvvECiFK2pdHq1oOTdAXJnOqLI2Jkvc7TE5122mnMmTOH/v37A/C9877H2d8+m9tuu40JEybwvfO+x9577d3gKHuvfv36ccEFF7DTTjuxbNkyxowZw8c//nEATj/9dL785S+vtv9ll10GwCOPPMLixYuZMGECDz30EH369N7+Qa3uwXWUJyRtBFwLbAU8CxwREa+k284EjiOZ0ffUiLi9Wvv1/Bu6kncWdC28lpYW9pu4Hz+7/O1JSSNiVbLbYIMNWLBgQaPCM2DQoEHstNNOAKy//voMGzaMF198seL+jz/+OPvssw8Am222GQMGDGDGjIp1ToovRLT1ybRkcCXvzBNfA+6KiG2Au9LvSBoOTAJGpMf8WFLfao3XLcF1VNC1N7hwyoV89StfpVR6u39++hdP57zvn8dzzz/H98//PpPPnNzACK3cs88+y6xZs9hll10AuPjii9lhhx049thjeeWVV4DkFsNNN93EypUrmTdvHq2trbzwwguNDLvxShmXTlTIEwcBV6WfrwIOLlt/TUQsj4h5wFxg52rtN7yPLemE9qKwjY5lbU2cOJGXFr/EzJkzV1t/8sknc8bpZ/CBwR/gjNPP4PKfXd6gCK3ca6+9xmGHHcaUKVPo378/J598Mk8//TSzZ89m0KBBfOlLXwLg2GOPZYsttmDs2LF88YtfZNddd6Vfv148PhdASdmWrhV+HhgRCwHSn5ul61uA8v+yzE/XVdTwv6WIuBS4FEBSjWr1NMZuu+3GAQcewIT9JrDuuuvSv39/rp56NQcccACnnXYaANdffz2XXX5ZgyO1FStWcNhhh3HUUUdx6KGHAjBw4MBV248//nj2339/ILlnd+GFF67atuuuu7LNNtt0b8A9TGT/l9rlws8d6OjGX9VIGt6DK5LJkyczeMvBbD1ka46cdCR33303nzn6MyxYsIA999wTgL333punnnqqwZH2bhHBcccdx7BhwzjjjDNWrV+4cOGqzzfeeCMjRyZjY2+88Qavv/46AHfeeSf9+vVj+PDh3Rt0T5O9B9cViyQNAkh/Lk7Xzwe2LNtvC6DqDe2G9+B6gxOOP4EpF02hX79+/Pvf/+bEE05sdEi92p///GemTp3K9ttvz+jRowH47ne/y7Rp05g9ezaS2GqrrbjkkksAWLx4Mfvuuy99+vShpaWFqVOnNjL8xgugra7Pwd0MHAOcm/68qWz9LyX9ANicpPDzg9UaUuToa+ZRXtAVWAR8KyI6rHdYdkyojhWzrfZKPeFhJ8ts7NixzJgxY63+kb1rwIDY8KN7Ztr3pVtvbq12idpRngB+A1wHDAaeBw5vL/As6evAscBK4IsR8btq569bD65CQVcza3ZBphHSTE1VzhP7VNj/HOCcrO37EtXM8muSjrsTnJnl1yTPOzjBmVk+7c/BNQEnODPLJ0Arm6ML5wRnZvk1R35zgjOzLvAgg5kVUg0fE6k3Jzgzy6/UHNeoTnBmlpvcgzOzQgqgzT04Myso+RLVzAopIteEcI3kBGdm+bkHZ2ZFJHyJamZFFUBbcwyjOsGZWU7hS1QzK6gAeZDBzAqrBj04SduSVLBvtzXwTWAAcDzwUrp+ckRM78o5nODMLL8a1OKIiCeB0QBphfoXgRuBzwEXRsT5a3sOJzgzyyfqcg9uH+DpiHhOqt1kmq6Lama5qa0t00L2yvaTgGll30+R9LCkKyRt2NU4neDMLKdILlGzLGll+7Ll0jVbk/Ru4EDg+nTVT4APkly+LgQu6GqkvkQ1s3yCWl+iTgBmRsQigPafAJIuA37b1YbdgzOz/LL34LI4krLLU0mDyrYdAjza1TDdgzOznKImo6gAkt4LfBw4sWz1eZJGJyfi2TW25eIEZ2b5BESNLlEj4g1g4zXWHV2TxnGCM7PcAkorGx1EJk5wZpZfyS/bm1kRBUSN7sHVmxOcmeVUu0GGenOCM7P8nODMrIiCIDzIYGaF5HtwZlZc4QRnZgXmBGdmxeQenJkVmBOcmRVSRFDyKKqZFVXgHpyZFZLvwZlZgTnBmVkhBU5wZlZYQQlXtjezIgpqNooq6VlgGdAGrIyIsZI2Iql4vxXJlOVHRMQrXWnfRWfMLJcgKGX8X0Z7RcToiBibfv8acFdEbAPclX7vEic4M8stopRp6aKDgKvSz1cBB3e1ISc4M8utlN6H62yh88r2AdwhqbVs28CIWAiQ/tysq3H6HpyZ5RIEpey9syVll54d2S0iFkjaDLhT0hNrH+HbnODMLLe2aKtJOxGxIP25WNKNwM7AIkmDImJhWgR6cVfb72kJbkkQzzU6iDrYBFjS6CDqQVKjQ6iXov6dfaAGbdxO8ueTRcU/Q0nrAX0iYln6+RPA2cDNwDHAuenPm7oaqCKa43mWZiZpRifddOth/HdWf5K2Bm5Mv/YDfhkR50jaGLgOGAw8DxweES935Rw9rQdnZr1ERDwDjOpg/VJgn1qcw6OoZlZYTnDd49JGB2C5+e+sAHwPzswKyz04MyssJzgzKywnuDqSNF7Sk5LmSuryC8PWfSRdIWmxpEcbHYutPSe4OpHUF/gRMAEYDhwpaXhjo7IMrgTGNzoIqw0nuPrZGZgbEc9ExFvANSSzJFgPFhH3Al16qNR6Hie4+mkBXij7Pj9dZ2bdxAmufjp6SdPP5Jh1Iye4+pkPbFn2fQtgQYNiMeuVnODq5yFgG0lDJL0bmEQyS4KZdRMnuDqJiJXAKSRTy8wBrouIxxoblXVG0jTgfmBbSfMlHdfomKzr/KqWmRWWe3BmVlhOcGZWWE5wZlZYTnBmVlhOcGZWWE5wTURSm6TZkh6VdL2k965FW1dK+mT6+fJqEwFIGidp1y6c41lJ76i+VGn9Gvu8lvNcZ0n6ct4Yrdic4JrLmxExOiJGAm8BJ5VvTGcwyS0i/jMiHq+yyzggd4IzazQnuOb1J+BDae/qD5J+CTwiqa+k70t6SNLDkk4EUOJiSY9LuhXYrL0hSfdIGpt+Hi9ppqS/SbpL0lYkifT0tPe4u6RNJd2QnuMhSbulx24s6Q5JsyRdQsfv465G0m8ktUp6TNIJa2y7II3lLkmbpus+KOm29Jg/SdquFn+YVkwuG9iEJPUjmWfutnTVzsDIiJiXJolXI+LDktYB/izpDmBHYFtge2Ag8DhwxRrtbgpcBuyRtrVRRLws6afAaxFxfrrfL4ELI+I+SYNJ3tYYBnwLuC8izpY0EVgtYVVwbHqO9wAPSbohLRu3HjAzIr4k6Ztp26eQFIM5KSKekrQL8GNg7y78MVov4ATXXN4jaXb6+U/Az0guHR+MiHnp+k8AO7TfXwM2ALYB9gCmRUQbsEDS3R20/x/Ave1tVSm2+zFgeFlV+/6S1k/PcWh67K2SXsnwO50q6ZD085ZprEuBEnBtuv7nwK8lvS/9fa8vO/c6Gc5hvZQTXHN5MyJGl69I/6G/XpxzvNQAAAEySURBVL4K+EJE3L7GfvvR+XRNyrAPJLc2PhIRb3YQS+Z3/ySNI0mWH4mINyTdA6xbYfdIz/vPNf8MzCrxPbjiuR04WdK7ACQNlbQecC8wKb1HNwjYq4Nj7wf2lDQkPXajdP0yYP2y/e4guVwk3a894dwLHJWumwBs2EmsGwCvpMltO5IeZLs+QHsv9NMkl77/AuZJOjw9hyS9ozK6WTsnuOK5nOT+2sy0cMolJD31G4GngEeAnwB/XPPAiHiJ5L7ZryX9jbcvEW8BDmkfZABOBcamgxiP8/Zo7reBPSTNJLlUfr6TWG8D+kl6GPgO8EDZtteBEZJaSe6xnZ2uPwo4Lo3vMTwNvFXh2UTMrLDcgzOzwnKCM7PCcoIzs8JygjOzwnKCM7PCcoIzs8JygjOzwvr/sRiSe2/BcisAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get predictions\n",
    "preds = gs_cvec_nb.predict(X_test)\n",
    "\n",
    "# Save confusion matrix values\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n",
    "\n",
    "# View confusion matrix\n",
    "\n",
    "plot_confusion_matrix(gs_cvec_nb, X_test, y_test, cmap='cubehelix', values_format='d');\n",
    "plt.title('Confusion matrix')\n",
    "\n",
    "printmd('credit: NLP II: `CountVectorizer`, `TfidfVectorizer`, and Modeling lesson. _Authors: Dave Yerrington (SF), Justin Pounders (ATL), Riley Dallas (ATX), Matt Brems (DC), Noelle Brown (DEN)_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8400673400673401\n",
      "Misclassification: 0.15993265993265993\n",
      "Sensitivity: 0.8436482084690554\n",
      "Precision: 0.8464052287581699\n",
      "Specificity: 0.8362369337979094\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy\n",
    "\n",
    "acc = (tp + tn) / (tp + fp + tn + fn)\n",
    "print('Accuracy:', acc)\n",
    "\n",
    "# Calculate the misclassification rate\n",
    "\n",
    "misclass = (fp + fn) / (tp + fp + tn + fn)\n",
    "print('Misclassification:', misclass)\n",
    "\n",
    "# Calculate the sensitivity\n",
    "\n",
    "sens = tp / (tp + fn)\n",
    "print('Sensitivity:', sens)\n",
    "\n",
    "# Calculate the precision\n",
    "\n",
    "prec = tp / (tp + fp)\n",
    "print('Precision:', prec)\n",
    "\n",
    "# Calculate the specificity\n",
    "\n",
    "spec = tn / (tn + fp)\n",
    "print('Specificity:', spec)\n",
    "\n",
    "def metrics(y_test, y_predict, pred_proba):\n",
    "    print('Accuracy score %s ' % accuracy_score(y_test, y_predict), '\\n')\n",
    "    print('----------------------------------------------------------------')\n",
    "    print(pd.DataFrame(confusion_matrix(y_test, y_predict), \n",
    "                            index=['Not Actual Disaster', 'Actual Disaster'], \n",
    "                            columns=['Predicted Not Actual Disaster', 'Predicted Disaster']), '\\n')\n",
    "    print('-----------------------------------------------------------------')\n",
    "    print(classification_report(y_test, y_predict))\n",
    "    print('-----------------------------------------------------------------')\n",
    "    print('ROC_AUC SCORE %s ' %roc_auc_score(y_test, pred_proba))\n",
    "    \n",
    "# credit: Heather Robinson :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update the scoreboard or not? These are artificially high scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model # |     Model metrics     |  Score | Before preprocessing shape | train_test_split  | Value |   Pipeline  |        pipe_cvec_nb       | Pipe hyperparameters |                         Value set                         | GridsearchCV parameters | Value | GridsearchCV BEST parameters | Value  |\n",
    "|:-------:|:---------------------:|:------:|:--------------------------:|:-----------------:|:-----:|:-----------:|:-------------------------:|:--------------------:|:---------------------------------------------------------:|:-----------------------:|:-----:|:----------------------------:|--------|\n",
    "|    1    |       Best score      | 0.8389 |          (1800, 7)         |     test_size     |  0.33 | Transformer | 'cvec', CountVectorizer() |     max_features     | 'cvec__max_features': [1_000, 2_000, 3_000, 4_000, 5_000] | k-fold cross-validation |   5   | cvec__max_df                 | 0.98   |\n",
    "|    1    | |  |                            |      stratify     |   y   |  Estimator  |   'nb', MultinomialNB()   |        min_df        |                   'cvec__min_df': [1, 2]                  |                         |       | cvec__max_features           | 4000   |\n",
    "|    1    |   |  |                            |    random_state   |   42  |             |                           |        max_df        |                 'cvec__max_df': [.98, .99]                |                         |       | cvec__min_df                 | 1      |\n",
    "|    1    |                       |        |                            |                   |       |             |                           |      ngram_range     |             'cvec__ngram_range': [(1,1), (1,2)            |                         |       | cvec__ngram_range            | (1, 2) |\n",
    "|    1    |                       |        |                            |                   |       |             |                           |                      |                                                           |                         |       |                              |        |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy score 0.8400673400673401  \n",
      "\n",
      "----------------------------------------------------------------\n",
      "                     Predicted Not Actual Disaster  Predicted Disaster\n",
      "Not Actual Disaster                            240                  47\n",
      "Actual Disaster                                 48                 259 \n",
      "\n",
      "-----------------------------------------------------------------\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.84      0.83       287\n",
      "           1       0.85      0.84      0.85       307\n",
      "\n",
      "    accuracy                           0.84       594\n",
      "   macro avg       0.84      0.84      0.84       594\n",
      "weighted avg       0.84      0.84      0.84       594\n",
      "\n",
      "-----------------------------------------------------------------\n",
      "ROC_AUC SCORE 0.9160414940584958 \n"
     ]
    }
   ],
   "source": [
    "pred_proba = gs_cvec_nb.predict_proba(X_test)[:, 1]\n",
    "\n",
    "metrics(y_test, preds, pred_proba)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline 2\n",
    "\n",
    "**CountVectorizer (transformer)**:\n",
    "\n",
    "\n",
    "\n",
    "**Logistic Regression (estimator)**:\n",
    "\n",
    "* Relatively interpretable results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set another pipeline up with two stages:\n",
    "# 1. CountVectorizer (transformer)\n",
    "# 2. LogisticRegression (estimator)\n",
    "\n",
    "pipe_log_reg = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('log_reg', LogisticRegression())\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline 3\n",
    "\n",
    "**CountVectorizer (transformer)**:\n",
    "\n",
    "\n",
    "\n",
    "**Random Forest (estimator)**:\n",
    "\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline 4\n",
    "\n",
    "Tout un ensemble\n",
    "\n",
    "https://scikit-learn.org/stable/modules/ensemble.html\n",
    "\n",
    "**CountVectorizer (transformer)**:\n",
    "\n",
    "\n",
    "\n",
    "**Random Forest * LogReg * MNBayes (estimator) **:\n",
    "\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline 5\n",
    "\n",
    "\n",
    "**TfidfVectorizer (transformer)**\n",
    "\n",
    "\n",
    "\n",
    "**SVG (estimator)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
