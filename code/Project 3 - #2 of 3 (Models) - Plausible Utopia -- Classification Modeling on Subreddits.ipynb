{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project 3: Plausible Utopia \n",
    "\n",
    "### Classification Modeling on Subreddits to Classify Futurists vs. Scientists\n",
    "\n",
    "### Notebook 2 of 3: Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LassoCV, RidgeCV, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, classification_report, accuracy_score, roc_auc_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "     \n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import re\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "##this will hide deprecation/future warnings\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "pd.set_option('display.max_row', 200) # Set ipython's max row display\n",
    "pd.set_option('display.max_columns', 85) # Set iPython's max column count\n",
    "pd.set_option('display.max_colwidth', 1_000) # Set iPython's max column width\n",
    "\n",
    "# pseudo-markdown in code cells\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "# ref: https://discuss.analyticsvidhya.com/t/how-to-make-a-text-bold-within-print-statement-in-ipython-notebook/14552/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1800, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>futurology</td>\n",
       "      <td>what would the point be to do anyth if ai could just do it all for us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>futurology</td>\n",
       "      <td>elcc explain the critic renew energi concept you’v never heard of now we live in a day and age where some part of the countri gener more than  of their electr with variabl renew and that number will fast approach  in the decad to come</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>futurology</td>\n",
       "      <td>there a  chanc were live in a simul and here how to find out the probabl will increas as we develop technolog enabl the creation of a simul contain consciou be</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>futurology</td>\n",
       "      <td>eight nation sign nasa artemi accord pledg peac on the moon it a reaffirm of the  outer space treati</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>futurology</td>\n",
       "      <td>merced benz avtr  in action</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    subreddit  \\\n",
       "0  futurology   \n",
       "1  futurology   \n",
       "2  futurology   \n",
       "3  futurology   \n",
       "4  futurology   \n",
       "\n",
       "                                                                                                                                                                                                                                         title  \n",
       "0                                                                                                                                                                       what would the point be to do anyth if ai could just do it all for us   \n",
       "1  elcc explain the critic renew energi concept you’v never heard of now we live in a day and age where some part of the countri gener more than  of their electr with variabl renew and that number will fast approach  in the decad to come   \n",
       "2                                                                             there a  chanc were live in a simul and here how to find out the probabl will increas as we develop technolog enabl the creation of a simul contain consciou be   \n",
       "3                                                                                                                                        eight nation sign nasa artemi accord pledg peac on the moon it a reaffirm of the  outer space treati   \n",
       "4                                                                                                                                                                                                                 merced benz avtr  in action   "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the cleaned data\n",
    "subred = pd.read_csv('../data/cleaned_data/cleaned_df.csv')\n",
    "\n",
    "# Check its shape\n",
    "display(subred.shape)\n",
    "\n",
    "# Preview\n",
    "subred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set feature matrix and target variable\n",
    "\n",
    "X = subred['title']\n",
    "y = subred['subreddit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read the following from ISLR:\n",
    "\n",
    "5.2 - The Bootstrap. (You'll want to know the bootstrap well as it will be embedded in methods we'll discuss next week.)\n",
    "Chapter 8 - Tree Based Methods. (We'll learn about classification and regression trees, random forests, bagging and boosting next week.)\n",
    "9.1-9.5 (Support Vector Machines and related methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify an optimal model with a pipeline and GridSearch\n",
    "\n",
    "### Train-test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Ref: 5.05 lesson**\n",
    " \n",
    " Features can be completely different in train/test\n",
    " \n",
    "**IMPORTANT** Instead of splitting we can use entire dataset combined with cross-validation\n",
    " \n",
    " Depending on how big dataset is, significant words in train set will probably appear in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1206,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1206,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(594,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(594,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size = 0.33,\n",
    "                                                    stratify = y,\n",
    "                                                    random_state = 42)\n",
    "\n",
    "display(X_train.shape)\n",
    "display(y_train.shape)\n",
    "\n",
    "display(X_test.shape)\n",
    "display(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline accuracy\n",
    "\n",
    "**51.7% is the baseline accuracy percentage we compare with the model's accuracy.**\n",
    "\n",
    "**If the model does better than the baseline, then it is better than null model (predicting the majority / plurality class).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "science       0.517222\n",
       "futurology    0.482778\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "science       0.517413\n",
       "futurology    0.482587\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "science       0.516835\n",
       "futurology    0.483165\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(y.value_counts(normalize=True))\n",
    "\n",
    "display(y_train.value_counts(normalize=True))\n",
    "\n",
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cutoff point "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline 1\n",
    "\n",
    "**CountVectorizer (transformer)**:\n",
    "\n",
    "\n",
    "\n",
    "**Multinomial Naive Bayes (estimator)**:\n",
    "\n",
    "* Fast modeling algorithm\n",
    "* Variables are positive integers\n",
    "* Assumes all variables are independent (which is not realistic in NLP, but this assumption is accepted anyway)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set a pipeline up with two stages:\n",
    "# 1. CountVectorizer (transformer)\n",
    "# 2. Multinomial Naive Bayes (estimator)\n",
    "\n",
    "pipe_cvec_nb = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('nb', MultinomialNB())    # Naive Bayes\n",
    "])\n",
    "\n",
    "\n",
    "# Search over the following values of hyperparameters:\n",
    "# Maximum number of features fit\n",
    "# Minimum number of documents needed to include token\n",
    "# Maximum number of documents needed to include token\n",
    "# Check (individual tokens) and also check (individual tokens and 2-grams).\n",
    "\n",
    "pipe_cvec_nb_params = {\n",
    "    'cvec__max_features': [1_000, 2_000, 3_000, 4_000, 5_000],\n",
    "    'cvec__min_df': [1, 2],\n",
    "    'cvec__max_df': [.98, .99],\n",
    "    'cvec__ngram_range': [(1,1), (1,2)]\n",
    "}\n",
    "\n",
    "# Instantiate GridSearchCV.\n",
    "\n",
    "gs_cvec_nb = GridSearchCV(pipe_cvec_nb, # what object are we optimizing?\n",
    "                  param_grid = pipe_cvec_nb_params, # what parameters values are we searching?\n",
    "                  cv=5)      # 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('nb', MultinomialNB())]),\n",
       "             param_grid={'cvec__max_df': [0.98, 0.99],\n",
       "                         'cvec__max_features': [1000, 2000, 3000, 4000, 5000],\n",
       "                         'cvec__min_df': [1, 2],\n",
       "                         'cvec__ngram_range': [(1, 1), (1, 2)]})"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit GridSearch to data.\n",
    "gs_cvec_nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Grid searched:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': [1000, 2000, 3000, 4000, 5000],\n",
       " 'cvec__min_df': [1, 2],\n",
       " 'cvec__max_df': [0.98, 0.99],\n",
       " 'cvec__ngram_range': [(1, 1), (1, 2)]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Best accuracy score**: 0.8416"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Best estimator / parameters:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cvec', CountVectorizer(max_df=0.98, max_features=5000)),\n",
       "                ('nb', MultinomialNB())])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.98,\n",
       " 'cvec__max_features': 5000,\n",
       " 'cvec__min_df': 1,\n",
       " 'cvec__ngram_range': (1, 1)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_cvec__max_df</th>\n",
       "      <th>param_cvec__max_features</th>\n",
       "      <th>param_cvec__min_df</th>\n",
       "      <th>param_cvec__ngram_range</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.062571</td>\n",
       "      <td>0.009460</td>\n",
       "      <td>0.014774</td>\n",
       "      <td>0.003653</td>\n",
       "      <td>0.99</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'cvec__max_df': 0.99, 'cvec__max_features': 5000, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 1)}</td>\n",
       "      <td>0.847107</td>\n",
       "      <td>0.846473</td>\n",
       "      <td>0.875519</td>\n",
       "      <td>0.800830</td>\n",
       "      <td>0.838174</td>\n",
       "      <td>0.841621</td>\n",
       "      <td>0.023994</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.060851</td>\n",
       "      <td>0.006004</td>\n",
       "      <td>0.012761</td>\n",
       "      <td>0.001175</td>\n",
       "      <td>0.98</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'cvec__max_df': 0.98, 'cvec__max_features': 5000, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 1)}</td>\n",
       "      <td>0.847107</td>\n",
       "      <td>0.846473</td>\n",
       "      <td>0.875519</td>\n",
       "      <td>0.800830</td>\n",
       "      <td>0.838174</td>\n",
       "      <td>0.841621</td>\n",
       "      <td>0.023994</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.058286</td>\n",
       "      <td>0.004096</td>\n",
       "      <td>0.012579</td>\n",
       "      <td>0.001354</td>\n",
       "      <td>0.99</td>\n",
       "      <td>4000</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'cvec__max_df': 0.99, 'cvec__max_features': 4000, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 1)}</td>\n",
       "      <td>0.847107</td>\n",
       "      <td>0.846473</td>\n",
       "      <td>0.871369</td>\n",
       "      <td>0.800830</td>\n",
       "      <td>0.838174</td>\n",
       "      <td>0.840791</td>\n",
       "      <td>0.022851</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.059041</td>\n",
       "      <td>0.006636</td>\n",
       "      <td>0.013405</td>\n",
       "      <td>0.001219</td>\n",
       "      <td>0.98</td>\n",
       "      <td>4000</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'cvec__max_df': 0.98, 'cvec__max_features': 4000, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 1)}</td>\n",
       "      <td>0.847107</td>\n",
       "      <td>0.846473</td>\n",
       "      <td>0.871369</td>\n",
       "      <td>0.800830</td>\n",
       "      <td>0.838174</td>\n",
       "      <td>0.840791</td>\n",
       "      <td>0.022851</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.170746</td>\n",
       "      <td>0.007490</td>\n",
       "      <td>0.022751</td>\n",
       "      <td>0.001321</td>\n",
       "      <td>0.99</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'cvec__max_df': 0.99, 'cvec__max_features': 5000, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 2)}</td>\n",
       "      <td>0.863636</td>\n",
       "      <td>0.838174</td>\n",
       "      <td>0.858921</td>\n",
       "      <td>0.804979</td>\n",
       "      <td>0.838174</td>\n",
       "      <td>0.840777</td>\n",
       "      <td>0.020721</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "36       0.062571      0.009460         0.014774        0.003653   \n",
       "16       0.060851      0.006004         0.012761        0.001175   \n",
       "32       0.058286      0.004096         0.012579        0.001354   \n",
       "12       0.059041      0.006636         0.013405        0.001219   \n",
       "37       0.170746      0.007490         0.022751        0.001321   \n",
       "\n",
       "   param_cvec__max_df param_cvec__max_features param_cvec__min_df  \\\n",
       "36               0.99                     5000                  1   \n",
       "16               0.98                     5000                  1   \n",
       "32               0.99                     4000                  1   \n",
       "12               0.98                     4000                  1   \n",
       "37               0.99                     5000                  1   \n",
       "\n",
       "   param_cvec__ngram_range  \\\n",
       "36                  (1, 1)   \n",
       "16                  (1, 1)   \n",
       "32                  (1, 1)   \n",
       "12                  (1, 1)   \n",
       "37                  (1, 2)   \n",
       "\n",
       "                                                                                                params  \\\n",
       "36  {'cvec__max_df': 0.99, 'cvec__max_features': 5000, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 1)}   \n",
       "16  {'cvec__max_df': 0.98, 'cvec__max_features': 5000, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 1)}   \n",
       "32  {'cvec__max_df': 0.99, 'cvec__max_features': 4000, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 1)}   \n",
       "12  {'cvec__max_df': 0.98, 'cvec__max_features': 4000, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 1)}   \n",
       "37  {'cvec__max_df': 0.99, 'cvec__max_features': 5000, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 2)}   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "36           0.847107           0.846473           0.875519   \n",
       "16           0.847107           0.846473           0.875519   \n",
       "32           0.847107           0.846473           0.871369   \n",
       "12           0.847107           0.846473           0.871369   \n",
       "37           0.863636           0.838174           0.858921   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "36           0.800830           0.838174         0.841621        0.023994   \n",
       "16           0.800830           0.838174         0.841621        0.023994   \n",
       "32           0.800830           0.838174         0.840791        0.022851   \n",
       "12           0.800830           0.838174         0.840791        0.022851   \n",
       "37           0.804979           0.838174         0.840777        0.020721   \n",
       "\n",
       "    rank_test_score  \n",
       "36                1  \n",
       "16                1  \n",
       "32                3  \n",
       "12                3  \n",
       "37                5  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "printmd('**Grid searched:**')\n",
    "display(gs_cvec_nb.param_grid)\n",
    "printmd(f'**Best accuracy score**: {round(gs_cvec_nb.best_score_, 4)}')\n",
    "printmd('**Best estimator / parameters:**')\n",
    "display(gs_cvec_nb.best_estimator_)\n",
    "display(gs_cvec_nb.best_params_)\n",
    "\n",
    "pd.DataFrame(gs_cvec_nb.cv_results_).sort_values('rank_test_score').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "credit: NLP II: `CountVectorizer`, `TfidfVectorizer`, and Modeling lesson. _Authors: Dave Yerrington (SF), Justin Pounders (ATL), Riley Dallas (ATX), Matt Brems (DC), Noelle Brown (DEN)_"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get predictions\n",
    "preds = gs_cvec_nb.predict(X_test)\n",
    "\n",
    "# Save confusion matrix values\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n",
    "\n",
    "# View confusion matrix\n",
    "\n",
    "plot_confusion_matrix(gs_cvec_nb, X_test, y_test, cmap='cubehelix', values_format='d');\n",
    "plt.title('Confusion matrix')\n",
    "\n",
    "printmd('credit: NLP II: `CountVectorizer`, `TfidfVectorizer`, and Modeling lesson. _Authors: Dave Yerrington (SF), Justin Pounders (ATL), Riley Dallas (ATX), Matt Brems (DC), Noelle Brown (DEN)_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'fn' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-51-4e700bf7e955>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'fn' is not defined"
     ]
    }
   ],
   "source": [
    "fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8400673400673401\n",
      "Misclassification: 0.15993265993265993\n",
      "Sensitivity: 0.8534201954397395\n",
      "Precision: 0.8397435897435898\n",
      "Specificity: 0.8257839721254355\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy\n",
    "\n",
    "acc = (tp + tn) / (tp + fp + tn + fn)\n",
    "print('Accuracy:', acc)\n",
    "\n",
    "# Calculate the misclassification rate\n",
    "\n",
    "misclass = (fp + fn) / (tp + fp + tn + fn)\n",
    "print('Misclassification:', misclass)\n",
    "\n",
    "# Calculate the sensitivity\n",
    "\n",
    "sens = tp / (tp + fn)\n",
    "print('Sensitivity:', sens)\n",
    "\n",
    "# Calculate the precision\n",
    "\n",
    "prec = tp / (tp + fp)\n",
    "print('Precision:', prec)\n",
    "\n",
    "# Calculate the specificity\n",
    "\n",
    "spec = tn / (tn + fp)\n",
    "print('Specificity:', spec)\n",
    "\n",
    "def metrics(y_test, y_predict, pred_proba):\n",
    "    print('Accuracy score %s ' % accuracy_score(y_test, y_predict), '\\n')\n",
    "    print('----------------------------------------------------------------')\n",
    "    print(pd.DataFrame(confusion_matrix(y_test, y_predict), \n",
    "                            index=['Not Actual Disaster', 'Actual Disaster'], \n",
    "                            columns=['Predicted Not Actual Disaster', 'Predicted Disaster']), '\\n')\n",
    "    print('-----------------------------------------------------------------')\n",
    "    print(classification_report(y_test, y_predict))\n",
    "    print('-----------------------------------------------------------------')\n",
    "    print('ROC_AUC SCORE %s ' %roc_auc_score(y_test, pred_proba))\n",
    "    \n",
    "# credit: Heather Robinson :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update the scoreboard or not? These are artificially high scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model # |     Model metrics     |  Score | Before preprocessing shape | train_test_split  | Value |   Pipeline  |        pipe_cvec_nb       | Pipe hyperparameters |                         Value set                         | GridsearchCV parameters | Value | GridsearchCV BEST parameters | Value  |\n",
    "|:-------:|:---------------------:|:------:|:--------------------------:|:-----------------:|:-----:|:-----------:|:-------------------------:|:--------------------:|:---------------------------------------------------------:|:-----------------------:|:-----:|:----------------------------:|--------|\n",
    "|    1    |       Best score      | 0.8389 |          (1800, 7)         |     test_size     |  0.33 | Transformer | 'cvec', CountVectorizer() |     max_features     | 'cvec__max_features': [1_000, 2_000, 3_000, 4_000, 5_000] | k-fold cross-validation |   5   | cvec__max_df                 | 0.98   |\n",
    "|    1    | |  |                            |      stratify     |   y   |  Estimator  |   'nb', MultinomialNB()   |        min_df        |                   'cvec__min_df': [1, 2]                  |                         |       | cvec__max_features           | 4000   |\n",
    "|    1    |   |  |                            |    random_state   |   42  |             |                           |        max_df        |                 'cvec__max_df': [.98, .99]                |                         |       | cvec__min_df                 | 1      |\n",
    "|    1    |                       |        |                            |                   |       |             |                           |      ngram_range     |             'cvec__ngram_range': [(1,1), (1,2)            |                         |       | cvec__ngram_range            | (1, 2) |\n",
    "|    1    |                       |        |                            |                   |       |             |                           |                      |                                                           |                         |       |                              |        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline 1 Part 2\n",
    "\n",
    "**CountVectorizer (transformer)**:\n",
    "\n",
    "\n",
    "\n",
    "**Multinomial Naive Bayes (estimator)**:\n",
    "\n",
    "* Fast modeling algorithm\n",
    "* Variables are positive integers\n",
    "* Assumes all variables are independent (which is not realistic in NLP, but this assumption is accepted anyway)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set a pipeline up with two stages:\n",
    "# 1. CountVectorizer (transformer)\n",
    "# 2. Multinomial Naive Bayes (estimator)\n",
    "\n",
    "pipe_cvec_nb = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('nb', MultinomialNB())    # Naive Bayes\n",
    "])\n",
    "\n",
    "\n",
    "# Search over the following values of hyperparameters:\n",
    "# Maximum number of features fit\n",
    "# Minimum number of documents needed to include token\n",
    "# Maximum number of documents needed to include token\n",
    "# Check (individual tokens) and also check (individual tokens and 2-grams).\n",
    "\n",
    "pipe_cvec_nb_params = {\n",
    "    'cvec__max_features': [2_000, 4_000, 6_000],\n",
    "    'cvec__min_df': [1, 2],\n",
    "    'cvec__max_df': [.05, .1, .25, .4],\n",
    "    'cvec__ngram_range': [(1, 1), (1, 2)], \n",
    "    'cvec__stop_words': [None, 'english']\n",
    "}\n",
    "\n",
    "# Instantiate GridSearchCV.\n",
    "\n",
    "gs_cvec_nb = GridSearchCV(pipe_cvec_nb, # what object are we optimizing?\n",
    "                  param_grid = pipe_cvec_nb_params, # what parameters values are we searching?\n",
    "                  cv=5)      # 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('nb', MultinomialNB())]),\n",
       "             param_grid={'cvec__max_df': [0.05, 0.1, 0.25, 0.4],\n",
       "                         'cvec__max_features': [2000, 4000, 6000],\n",
       "                         'cvec__min_df': [1, 2],\n",
       "                         'cvec__ngram_range': [(1, 1), (1, 2)],\n",
       "                         'cvec__stop_words': [None, 'english']})"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit GridSearch to data.\n",
    "gs_cvec_nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Grid searched:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': [2000, 4000, 6000],\n",
       " 'cvec__min_df': [1, 2],\n",
       " 'cvec__max_df': [0.05, 0.1, 0.25, 0.4],\n",
       " 'cvec__ngram_range': [(1, 1), (1, 2)],\n",
       " 'cvec__stop_words': [None, 'english']}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Best score**: 0.8458"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Best estimator / parameters:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cvec',\n",
       "                 CountVectorizer(max_df=0.4, max_features=6000,\n",
       "                                 ngram_range=(1, 2))),\n",
       "                ('nb', MultinomialNB())])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.4,\n",
       " 'cvec__max_features': 6000,\n",
       " 'cvec__min_df': 1,\n",
       " 'cvec__ngram_range': (1, 2),\n",
       " 'cvec__stop_words': None}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_cvec__max_df</th>\n",
       "      <th>param_cvec__max_features</th>\n",
       "      <th>param_cvec__min_df</th>\n",
       "      <th>param_cvec__ngram_range</th>\n",
       "      <th>param_cvec__stop_words</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.066561</td>\n",
       "      <td>0.018817</td>\n",
       "      <td>0.007802</td>\n",
       "      <td>0.002319</td>\n",
       "      <td>0.4</td>\n",
       "      <td>6000</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>{'cvec__max_df': 0.4, 'cvec__max_features': 6000, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 2), 'cvec__stop_words': None}</td>\n",
       "      <td>0.867769</td>\n",
       "      <td>0.834025</td>\n",
       "      <td>0.863071</td>\n",
       "      <td>0.809129</td>\n",
       "      <td>0.854772</td>\n",
       "      <td>0.845753</td>\n",
       "      <td>0.021656</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.054940</td>\n",
       "      <td>0.002049</td>\n",
       "      <td>0.008827</td>\n",
       "      <td>0.001534</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4000</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>{'cvec__max_df': 0.4, 'cvec__max_features': 4000, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 2), 'cvec__stop_words': None}</td>\n",
       "      <td>0.867769</td>\n",
       "      <td>0.834025</td>\n",
       "      <td>0.871369</td>\n",
       "      <td>0.796680</td>\n",
       "      <td>0.846473</td>\n",
       "      <td>0.843263</td>\n",
       "      <td>0.027041</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.086786</td>\n",
       "      <td>0.027238</td>\n",
       "      <td>0.013215</td>\n",
       "      <td>0.006078</td>\n",
       "      <td>0.25</td>\n",
       "      <td>6000</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>None</td>\n",
       "      <td>{'cvec__max_df': 0.25, 'cvec__max_features': 6000, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 2), 'cvec__stop_words': None}</td>\n",
       "      <td>0.867769</td>\n",
       "      <td>0.825726</td>\n",
       "      <td>0.863071</td>\n",
       "      <td>0.804979</td>\n",
       "      <td>0.850622</td>\n",
       "      <td>0.842433</td>\n",
       "      <td>0.023735</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.022837</td>\n",
       "      <td>0.002098</td>\n",
       "      <td>0.003931</td>\n",
       "      <td>0.002585</td>\n",
       "      <td>0.4</td>\n",
       "      <td>4000</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>{'cvec__max_df': 0.4, 'cvec__max_features': 4000, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 1), 'cvec__stop_words': None}</td>\n",
       "      <td>0.842975</td>\n",
       "      <td>0.846473</td>\n",
       "      <td>0.863071</td>\n",
       "      <td>0.800830</td>\n",
       "      <td>0.846473</td>\n",
       "      <td>0.839964</td>\n",
       "      <td>0.020781</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.022250</td>\n",
       "      <td>0.001809</td>\n",
       "      <td>0.004378</td>\n",
       "      <td>0.001911</td>\n",
       "      <td>0.25</td>\n",
       "      <td>4000</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>None</td>\n",
       "      <td>{'cvec__max_df': 0.25, 'cvec__max_features': 4000, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 1), 'cvec__stop_words': None}</td>\n",
       "      <td>0.842975</td>\n",
       "      <td>0.842324</td>\n",
       "      <td>0.871369</td>\n",
       "      <td>0.800830</td>\n",
       "      <td>0.842324</td>\n",
       "      <td>0.839964</td>\n",
       "      <td>0.022530</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "90       0.066561      0.018817         0.007802        0.002319   \n",
       "82       0.054940      0.002049         0.008827        0.001534   \n",
       "66       0.086786      0.027238         0.013215        0.006078   \n",
       "80       0.022837      0.002098         0.003931        0.002585   \n",
       "56       0.022250      0.001809         0.004378        0.001911   \n",
       "\n",
       "   param_cvec__max_df param_cvec__max_features param_cvec__min_df  \\\n",
       "90                0.4                     6000                  1   \n",
       "82                0.4                     4000                  1   \n",
       "66               0.25                     6000                  1   \n",
       "80                0.4                     4000                  1   \n",
       "56               0.25                     4000                  1   \n",
       "\n",
       "   param_cvec__ngram_range param_cvec__stop_words  \\\n",
       "90                  (1, 2)                   None   \n",
       "82                  (1, 2)                   None   \n",
       "66                  (1, 2)                   None   \n",
       "80                  (1, 1)                   None   \n",
       "56                  (1, 1)                   None   \n",
       "\n",
       "                                                                                                                          params  \\\n",
       "90   {'cvec__max_df': 0.4, 'cvec__max_features': 6000, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 2), 'cvec__stop_words': None}   \n",
       "82   {'cvec__max_df': 0.4, 'cvec__max_features': 4000, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 2), 'cvec__stop_words': None}   \n",
       "66  {'cvec__max_df': 0.25, 'cvec__max_features': 6000, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 2), 'cvec__stop_words': None}   \n",
       "80   {'cvec__max_df': 0.4, 'cvec__max_features': 4000, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 1), 'cvec__stop_words': None}   \n",
       "56  {'cvec__max_df': 0.25, 'cvec__max_features': 4000, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 1), 'cvec__stop_words': None}   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "90           0.867769           0.834025           0.863071   \n",
       "82           0.867769           0.834025           0.871369   \n",
       "66           0.867769           0.825726           0.863071   \n",
       "80           0.842975           0.846473           0.863071   \n",
       "56           0.842975           0.842324           0.871369   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "90           0.809129           0.854772         0.845753        0.021656   \n",
       "82           0.796680           0.846473         0.843263        0.027041   \n",
       "66           0.804979           0.850622         0.842433        0.023735   \n",
       "80           0.800830           0.846473         0.839964        0.020781   \n",
       "56           0.800830           0.842324         0.839964        0.022530   \n",
       "\n",
       "    rank_test_score  \n",
       "90                1  \n",
       "82                2  \n",
       "66                3  \n",
       "80                4  \n",
       "56                4  "
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "printmd('**Grid searched:**')\n",
    "display(gs_cvec_nb.param_grid)\n",
    "printmd(f'**Best score**: {round(gs_cvec_nb.best_score_, 4)}')\n",
    "printmd('**Best estimator / parameters:**')\n",
    "display(gs_cvec_nb.best_estimator_)\n",
    "display(gs_cvec_nb.best_params_)\n",
    "\n",
    "pd.DataFrame(gs_cvec_nb.cv_results_).sort_values('rank_test_score').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline 2\n",
    "\n",
    "**CountVectorizer (transformer)**:\n",
    "\n",
    "**TF-IDF (transformer)**:\n",
    "\n",
    "\n",
    "\n",
    "**Logistic Regression (estimator)**:\n",
    "\n",
    "* Relatively interpretable results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-5c938e2b4c5d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcvec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'english'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m pd.DataFrame(cvec.fit_transform(X_train).to_dense(),\n\u001b[0m\u001b[0;32m      3\u001b[0m             columns = cvec.get_feature_names())\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mmax_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1198\u001b[1;33m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0m\u001b[0;32m   1199\u001b[0m                                           self.fixed_vocabulary_)\n\u001b[0;32m   1200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdecoder\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0manalyzer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0manalyzer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, doc)\u001b[0m\n\u001b[0;32m    206\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mstring\u001b[0m \u001b[0mof\u001b[0m \u001b[0municode\u001b[0m \u001b[0msymbols\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \"\"\"\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'filename'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m                 \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1325\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1326\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m   1327\u001b[0m             \u001b[1;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1328\u001b[0m             \u001b[1;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "cvec = CountVectorizer(X_train, stop_words = 'english')\n",
    "pd.DataFrame(cvec.fit_transform(X_train).to_dense(),\n",
    "            columns = cvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set up another pipeline\n",
    "# 1. CountVectorizer (transformer)\n",
    "# 2. TfidfVectorizer (transformer)\n",
    "# 3. LogisticRegression (estimator)\n",
    "\n",
    "pipe_log_reg_with_cvec_tfidf = Pipeline([\n",
    "    ('cvec', CountVectorizer(lowercase = False)),\n",
    "#     ('tvec', TfidfVectorizer(lowercase = False)),\n",
    "    ('log_reg', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Search over the following values of hyperparameters:\n",
    "# Maximum number of features fit\n",
    "# Minimum number of documents needed to include token\n",
    "# Maximum number of documents needed to include token\n",
    "# Check (individual tokens) and also check (individual tokens and 2-grams).\n",
    "\n",
    "# *****************************************************************************************************************\n",
    "# solver_list = ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga']\n",
    "# params = dict(solver=solver_list)\n",
    "# log_reg = LogisticRegression(C=1, n_jobs=-1, random_state=34)\n",
    "# clf = GridSearchCV(log_reg, params, cv=5)\n",
    "# clf.fit(X_train, y_train)\n",
    "# scores = clf.cv_results_['mean_test_score']\n",
    "\n",
    "# for score, solver in zip(scores, solver_list):\n",
    "#     print(f\"  {solver} {score:.3f}\" )\n",
    "\n",
    "# ref: https://towardsdatascience.com/dont-sweat-the-solver-stuff-aea7cddc3451\n",
    "# *****************************************************************************************************************\n",
    "\n",
    "pipe_log_reg_with_cvec_tfidf_params = {\n",
    "    'cvec__max_features': [1_000, 3_000, 5_000],\n",
    "    'cvec__min_df': [1, 2],\n",
    "    'cvec__max_df': [.98, .99],\n",
    "    'cvec__ngram_range': [(1,1), (2,1)],\n",
    "    'cvec__stop_words': [None, 'english'],\n",
    "#     'tvec__max_features': [3_000, 5_000],\n",
    "#     'tvec__stop_words': [None, 'english'],\n",
    "#     'tvec__ngram_range': [(1,1), (1,2)],\n",
    "    'log_reg__C': [.001, .01, .1, 1],\n",
    "    'log_reg__penalty': ['l1', 'l2'],\n",
    "    'log_reg__max_iter': [50, 75, 100],\n",
    "    'log_reg__random_state': [42], \n",
    "    'log_reg__solver': ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga']\n",
    "}\n",
    "\n",
    "# Instantiate GridSearchCV.\n",
    "\n",
    "gs_log_reg_with_cvec_tfidf = GridSearchCV(pipe_log_reg_with_cvec_tfidf, # what object are we optimizing?\n",
    "                  param_grid = pipe_log_reg_with_cvec_tfidf_params, # what parameters values are we searching?\n",
    "                  cv = 5)                                           # 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cvec', CountVectorizer(lowercase=False)),\n",
       "                ('log_reg', LogisticRegression())])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit GridSearch to data.\n",
    "pipe_log_reg_with_cvec_tfidf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Grid searched:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': [1000, 3000, 5000],\n",
       " 'cvec__min_df': [1, 2],\n",
       " 'cvec__max_df': [0.98, 0.99],\n",
       " 'cvec__ngram_range': [(1, 1), (2, 1)],\n",
       " 'cvec__stop_words': [None, 'english'],\n",
       " 'log_reg__C': [0.001, 0.01, 0.1, 1],\n",
       " 'log_reg__penalty': ['l1', 'l2'],\n",
       " 'log_reg__max_iter': [50, 75, 100],\n",
       " 'log_reg__random_state': [42],\n",
       " 'log_reg__solver': ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga']}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_score_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-9a789d8292e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprintmd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'**Grid searched:**'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgs_log_reg_with_cvec_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprintmd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'**Best score**: {round(gs_log_reg_with_cvec_tfidf.best_score_, 4)}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprintmd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'**Best estimator / parameters:**'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgs_log_reg_with_cvec_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_score_'"
     ]
    }
   ],
   "source": [
    "printmd('**Grid searched:**')\n",
    "display(gs_log_reg_with_cvec_tfidf.param_grid)\n",
    "printmd(f'**Best score**: {round(gs_log_reg_with_cvec_tfidf.best_score_, 4)}')\n",
    "printmd('**Best estimator / parameters:**')\n",
    "display(gs_log_reg_with_cvec_tfidf.best_estimator_)\n",
    "display(gs_log_reg_with_cvec_tfidf.best_params_)\n",
    "\n",
    "pd.DataFrame(gs_log_reg_with_cvec_tfidf.cv_results_).sort_values('rank_test_score').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline 3\n",
    "\n",
    "**TfidfVectorizer (transformer)**\n",
    "\n",
    "\n",
    "\n",
    "**Multinomial Naive Bayes (estimator)**:\n",
    "\n",
    "* Fast modeling algorithm\n",
    "* Variables are positive integers\n",
    "* Assumes all variables are independent (which is not realistic in NLP, but this assumption is accepted anyway)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set a pipeline up with two stages:\n",
    "# 1. TfidfVectorizer (transformer)\n",
    "# 2. Multinomial Naive Bayes (estimator)\n",
    "\n",
    "pipe_tvec_nb = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),   # TfidfVectorizer uses natural log, not as interpretable as CountVectorizer\n",
    "    ('nb', MultinomialNB())    # Naive Bayes\n",
    "])\n",
    "\n",
    "\n",
    "# Search over the following values of hyperparameters:\n",
    "# Maximum number of features fit\n",
    "# Minimum number of documents needed to include token\n",
    "# Maximum number of documents needed to include token\n",
    "# Check (individual tokens) and also check (individual tokens and 2-grams).\n",
    "\n",
    "pipe_tvec_nb_params = {\n",
    "    'tvec__max_features': [2_000, 3_000, 4_000, 5_000],\n",
    "    'tvec__stop_words': [None, 'english'],\n",
    "    'tvec__ngram_range': [(1,1), (1,2)]\n",
    "}\n",
    "\n",
    "# Instantiate GridSearchCV.\n",
    "\n",
    "gs_tvec_nb = GridSearchCV(pipe_tvec_nb, # what object are we optimizing?\n",
    "                  param_grid = pipe_tvec_nb_params, # what parameters values are we searching?\n",
    "                  cv = 5)      # 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tvec', TfidfVectorizer()), ('nb', MultinomialNB())])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit GridSearch to data.\n",
    "pipe_tvec_nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Grid searched:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'tvec__max_features': [2000, 3000, 4000, 5000],\n",
       " 'tvec__stop_words': [None, 'english'],\n",
       " 'tvec__ngram_range': [(1, 1), (1, 2)]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_score_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-196-85319eebdbd6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprintmd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'**Grid searched:**'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgs_tvec_nb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprintmd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'**Best accuracy score**: {round(gs_tvec_nb.best_score_, 4)}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprintmd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'**Best estimator / parameters:**'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgs_tvec_nb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_score_'"
     ]
    }
   ],
   "source": [
    "printmd('**Grid searched:**')\n",
    "display(gs_tvec_nb.param_grid)\n",
    "printmd(f'**Best accuracy score**: {round(gs_tvec_nb.best_score_, 4)}')\n",
    "printmd('**Best estimator / parameters:**')\n",
    "display(gs_tvec_nb.best_estimator_)\n",
    "display(gs_tvec_nb.best_params_)\n",
    "\n",
    "pd.DataFrame(gs_tvec_nb.cv_results_).sort_values('rank_test_score').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "credit: NLP II: `CountVectorizer`, `TfidfVectorizer`, and Modeling lesson. _Authors: Dave Yerrington (SF), Justin Pounders (ATL), Riley Dallas (ATX), Matt Brems (DC), Noelle Brown (DEN)_"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get predictions\n",
    "preds = gs_tvec_nb.predict(X_test)\n",
    "\n",
    "# Save confusion matrix values\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n",
    "\n",
    "# View confusion matrix\n",
    "\n",
    "plot_confusion_matrix(gs_tvec_nb, X_test, y_test, cmap='cubehelix', values_format='d');\n",
    "plt.title('Confusion matrix')\n",
    "\n",
    "printmd('credit: NLP II: `CountVectorizer`, `TfidfVectorizer`, and Modeling lesson. _Authors: Dave Yerrington (SF), Justin Pounders (ATL), Riley Dallas (ATX), Matt Brems (DC), Noelle Brown (DEN)_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8400673400673401\n",
      "Misclassification: 0.15993265993265993\n",
      "Sensitivity: 0.8534201954397395\n",
      "Precision: 0.8397435897435898\n",
      "Specificity: 0.8257839721254355\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy\n",
    "\n",
    "acc = (tp + tn) / (tp + fp + tn + fn)\n",
    "print('Accuracy:', acc)\n",
    "\n",
    "# Calculate the misclassification rate\n",
    "\n",
    "misclass = (fp + fn) / (tp + fp + tn + fn)\n",
    "print('Misclassification:', misclass)\n",
    "\n",
    "# Calculate the sensitivity\n",
    "\n",
    "sens = tp / (tp + fn)\n",
    "print('Sensitivity:', sens)\n",
    "\n",
    "# Calculate the precision\n",
    "\n",
    "prec = tp / (tp + fp)\n",
    "print('Precision:', prec)\n",
    "\n",
    "# Calculate the specificity\n",
    "\n",
    "spec = tn / (tn + fp)\n",
    "print('Specificity:', spec)\n",
    "\n",
    "def metrics(y_test, y_predict, pred_proba):\n",
    "    print('Accuracy score %s ' % accuracy_score(y_test, y_predict), '\\n')\n",
    "    print('----------------------------------------------------------------')\n",
    "    print(pd.DataFrame(confusion_matrix(y_test, y_predict), \n",
    "                            index=['Not Actual Disaster', 'Actual Disaster'], \n",
    "                            columns=['Predicted Not Actual Disaster', 'Predicted Disaster']), '\\n')\n",
    "    print('-----------------------------------------------------------------')\n",
    "    print(classification_report(y_test, y_predict))\n",
    "    print('-----------------------------------------------------------------')\n",
    "    print('ROC_AUC SCORE %s ' %roc_auc_score(y_test, pred_proba))\n",
    "    \n",
    "# credit: Heather Robinson :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline 4\n",
    "\n",
    "\n",
    "https://scikit-learn.org/stable/modules/ensemble.html\n",
    "\n",
    "**CountVectorizer (transformer)**:\n",
    "\n",
    "\n",
    "\n",
    "**Random Forest * LogReg * MNBayes (estimator) **:\n",
    "\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline 5\n",
    "\n",
    "\n",
    "**TfidfVectorizer (transformer)**\n",
    "\n",
    "\n",
    "\n",
    "**SVG (estimator)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Break the pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1206, 6000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1206,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(594, 6000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(594,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Instantiate CountVectorizer\n",
    "cvec = CountVectorizer(max_df = 0.4, max_features = 6_000, min_df = 1, ngram_range = (1, 2), stop_words = 'english')\n",
    "\n",
    "# Fit the features training data so the model learns the vocabulary; transform to create vectors from the vocabulary\n",
    "X_train_cvec = pd.DataFrame(cvec.fit_transform(X_train).todense(),\n",
    "                           columns = cvec.get_feature_names())\n",
    "\n",
    "# Fit the features test data so the model learns the vocabulary; \n",
    "X_test_cvec = pd.DataFrame(cvec.transform(X_test).todense(),\n",
    "                           columns = cvec.get_feature_names())\n",
    "\n",
    "# Check the shapes \n",
    "\n",
    "display(X_train_cvec.shape)\n",
    "display(y_train.shape)\n",
    "display(X_test_cvec.shape)\n",
    "display(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1206, 6000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1206,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(594, 6000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(594,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Instantiate the TfidfVectorizer transformer\n",
    "tvec = TfidfVectorizer(max_features = 6_000, stop_words = 'english', ngram_range = (1, 2)) \n",
    "\n",
    "# Fit the features training data so the model learns the vocabulary; transform to create vectors from the vocabulary\n",
    "X_train_tvec = pd.DataFrame(tvec.fit_transform(X_train).todense(),\n",
    "                           columns = tvec.get_feature_names())\n",
    "\n",
    "# Fit the features test data so the model learns the vocabulary; \n",
    "X_test_tvec = pd.DataFrame(tvec.transform(X_test).todense(),\n",
    "                           columns = tvec.get_feature_names())\n",
    "\n",
    "# Check the shapes \n",
    "\n",
    "display(X_train_tvec.shape)\n",
    "display(y_train.shape)\n",
    "display(X_test_tvec.shape)\n",
    "display(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'unit arab emir to launch spacecraft to moon in  '",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-d711c2ddbbc7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Fit the model to train data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlogreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Get accuracy scores for train and test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprintmd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'**Accuracy score on train data: {logreg.score(X_train, y_train):.3f}**'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1340\u001b[0m             \u001b[0m_dtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1342\u001b[1;33m         X, y = self._validate_data(X, y, accept_sparse='csr', dtype=_dtype,\n\u001b[0m\u001b[0;32m   1343\u001b[0m                                    \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"C\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1344\u001b[0m                                    accept_large_sparse=solver != 'liblinear')\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    793\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[0;32m    796\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    596\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    599\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    795\u001b[0m               dtype='datetime64[ns]')\n\u001b[0;32m    796\u001b[0m         \"\"\"\n\u001b[1;32m--> 797\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    798\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m     \u001b[1;31m# ----------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\numpy_.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[0m_HANDLED_TYPES\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'unit arab emir to launch spacecraft to moon in  '"
     ]
    }
   ],
   "source": [
    "# Fit the model to train data\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Get accuracy scores for train and test data\n",
    "printmd(f'**Accuracy score on train data: {logreg.score(X_train, y_train):.3f}**')\n",
    "printmd(f'**Accuracy score on test data: {logreg.score(X_test, y_test):.3f}**')\n",
    "printmd('**The model is overfit**')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 1], 'penalty': ['l1', 'l2']})"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set new parameters\n",
    "params = { 'C': [.001, .01, .1, 1], \n",
    "              'penalty': ['l1', 'l2']}\n",
    "\n",
    "# Instantiate GridSearch cross-validation\n",
    "gs = GridSearchCV(logreg, params, cv = 5)\n",
    "\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Accuracy score on train data: 0.993**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Accuracy score on test data: 0.823**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**The model is still overfit**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Best parameters:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'penalty': 'l2'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get accuracy scores for train and test data\n",
    "printmd(f'**Accuracy score on train data: {gs.score(X_train, y_train):.3f}**')\n",
    "printmd(f'**Accuracy score on test data: {gs.score(X_test, y_test):.3f}**')\n",
    "printmd('**The model is still overfit**')\n",
    "\n",
    "printmd('**Best parameters:**')\n",
    "display(gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'unit arab emir to launch spacecraft to moon in  '",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-222-5fbcd0cf69bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_reg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mean_test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    763\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1340\u001b[0m             \u001b[0m_dtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1342\u001b[1;33m         X, y = self._validate_data(X, y, accept_sparse='csr', dtype=_dtype,\n\u001b[0m\u001b[0;32m   1343\u001b[0m                                    \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"C\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1344\u001b[0m                                    accept_large_sparse=solver != 'liblinear')\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    793\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[0;32m    796\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    596\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    599\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    795\u001b[0m               dtype='datetime64[ns]')\n\u001b[0;32m    796\u001b[0m         \"\"\"\n\u001b[1;32m--> 797\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    798\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m     \u001b[1;31m# ----------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\numpy_.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[0m_HANDLED_TYPES\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'unit arab emir to launch spacecraft to moon in  '"
     ]
    }
   ],
   "source": [
    "params = {'solver': ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "               'C': [.0001, .001, .01, .1, 1], \n",
    "               'penalty': ['l1', 'l2']\n",
    "              }\n",
    "\n",
    "log_reg = LogisticRegression(C=1, random_state=42)\n",
    "\n",
    "clf = GridSearchCV(log_reg, params, cv=5)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "scores = clf.cv_results_['mean_test_score']\n",
    "   \n",
    "# ref: https://towardsdatascience.com/dont-sweat-the-solver-stuff-aea7cddc3451    \n",
    "\n",
    "# Get accuracy scores for train and test data\n",
    "printmd(f'**Accuracy score on train data: {clf.score(X_train, y_train):.3f}**')\n",
    "printmd(f'**Accuracy score on test data: {clf.score(X_test, y_test):.3f}**')\n",
    "printmd('**The model is still overfit**')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {'solver': ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "               'C': [.0001, .001, .01, .1, 1], \n",
    "               'penalty': ['l1', 'l2']\n",
    "              }\n",
    "\n",
    "log_reg = LogisticRegression(C=1, random_state=42)\n",
    "\n",
    "clf = GridSearchCV(log_reg, params, cv=5)\n",
    "\n",
    "clf.fit(X_train_tvec, y_train)\n",
    "\n",
    "scores = clf.cv_results_['mean_test_score']\n",
    "   \n",
    "# ref: https://towardsdatascience.com/dont-sweat-the-solver-stuff-aea7cddc3451    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Grid searched:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'solver': ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'],\n",
       " 'C': [0.0001, 0.001, 0.01, 0.1, 1],\n",
       " 'penalty': ['l1', 'l2']}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Best accuracy score**: 0.8267"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Best estimator / parameters:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, random_state=42, solver='liblinear')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Accuracy score on train data: 0.959**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Accuracy score on test data: 0.835**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**The model is still overfit**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printmd('**Grid searched:**')\n",
    "display(clf.param_grid)\n",
    "printmd(f'**Best accuracy score**: {round(clf.best_score_, 4)}')\n",
    "printmd('**Best estimator / parameters:**')\n",
    "display(clf.best_estimator_)\n",
    "display(clf.best_params_)\n",
    "\n",
    "# Get accuracy scores for train and test data\n",
    "printmd(f'**Accuracy score on train data: {clf.score(X_train_tvec, y_train):.3f}**')\n",
    "printmd(f'**Accuracy score on test data: {clf.score(X_test_tvec, y_test):.3f}**')\n",
    "printmd('**The model is still overfit**')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, random_state=42, solver='liblinear')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression(C = 1, penalty = 'l2', solver = 'liblinear', random_state=42)\n",
    "\n",
    "log_reg.fit(X_train_tvec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0.99168632]),\n",
       " array([[1.36453759, 0.97803806, 1.16858113, ..., 0.89708864, 1.08944299,\n",
       "         1.08944299]]))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(log_reg.intercept_), np.exp(log_reg.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**The strongest coefficients start from the top in the table below.**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "***Holding all else constant, the effect of `studi` is a 12.7 times increase in predictive accuracy.***"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coeff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>studi</th>\n",
       "      <td>12.666914</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>covid</th>\n",
       "      <td>8.479797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dure</th>\n",
       "      <td>4.218854</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>research</th>\n",
       "      <td>4.183251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sarscov</th>\n",
       "      <td>3.984838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>effect</th>\n",
       "      <td>3.599163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new studi</th>\n",
       "      <td>3.545901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use</th>\n",
       "      <td>3.400387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brain</th>\n",
       "      <td>3.246118</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>diseas</th>\n",
       "      <td>3.118300</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>associ</th>\n",
       "      <td>2.753800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>increas</th>\n",
       "      <td>2.659541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peopl</th>\n",
       "      <td>2.626677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>children</th>\n",
       "      <td>2.625140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suggest</th>\n",
       "      <td>2.611144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>infect</th>\n",
       "      <td>2.533080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>black</th>\n",
       "      <td>2.422198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>differ</th>\n",
       "      <td>2.337284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>individu</th>\n",
       "      <td>2.316171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>patient</th>\n",
       "      <td>2.282468</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Coeff\n",
       "studi      12.666914\n",
       "covid       8.479797\n",
       "dure        4.218854\n",
       "research    4.183251\n",
       "sarscov     3.984838\n",
       "effect      3.599163\n",
       "new studi   3.545901\n",
       "use         3.400387\n",
       "brain       3.246118\n",
       "diseas      3.118300\n",
       "associ      2.753800\n",
       "increas     2.659541\n",
       "peopl       2.626677\n",
       "children    2.625140\n",
       "suggest     2.611144\n",
       "infect      2.533080\n",
       "black       2.422198\n",
       "differ      2.337284\n",
       "individu    2.316171\n",
       "patient     2.282468"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "printmd('**The strongest coefficients start from the top in the table below.**')\n",
    "printmd(f'***Holding all else constant, the effect of `studi` is a {log_reg_coef.iloc[0, 0]:.1f} times increase in predictive accuracy.***')\n",
    "\n",
    "log_reg_coef = pd.DataFrame(np.exp(log_reg.coef_).T, index = X_train_tvec.columns, columns = ['Coeff']).sort_values('Coeff', ascending = False)\n",
    "log_reg_coef[:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
