{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project 3: Plausible Utopia \n",
    "\n",
    "### Classification Modeling on Subreddits to Classify Scientists and Futurists\n",
    "\n",
    "### Notebook 2 of 3: Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LassoCV, RidgeCV, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, classification_report, accuracy_score, roc_auc_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "     \n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import re\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "##this will hide deprecation/future warnings\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "pd.set_option('display.max_row', 200) # Set ipython's max row display\n",
    "pd.set_option('display.max_columns', 85) # Set iPython's max column count\n",
    "pd.set_option('display.max_colwidth', 1_000) # Set iPython's max column width\n",
    "\n",
    "# pseudo-markdown in code cells\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "# ref: https://discuss.analyticsvidhya.com/t/how-to-make-a-text-bold-within-print-statement-in-ipython-notebook/14552/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3137, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>robot encroach on up to  million job around the world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>measur in ai polici opportun and challeng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>how egypt is grow forest in middl of the desert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>energi scaveng nanogener find power all around us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>there are polit and cultur problem that occur with social chang in a societi with high andor rise life expect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subreddit  \\\n",
       "0          0   \n",
       "1          0   \n",
       "2          0   \n",
       "3          0   \n",
       "4          0   \n",
       "\n",
       "                                                                                                            title  \n",
       "0                                                          robot encroach on up to  million job around the world   \n",
       "1                                                                      measur in ai polici opportun and challeng   \n",
       "2                                                                how egypt is grow forest in middl of the desert   \n",
       "3                                                              energi scaveng nanogener find power all around us   \n",
       "4  there are polit and cultur problem that occur with social chang in a societi with high andor rise life expect   "
      ]
     },
     "execution_count": 413,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the cleaned data\n",
    "subred = pd.read_csv('../data/cleaned_data/cleaned_df.csv')\n",
    "\n",
    "# Check its shape\n",
    "display(subred.shape)\n",
    "\n",
    "# Preview\n",
    "subred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set feature matrix and target variable\n",
    "X = subred['title']\n",
    "y = subred['subreddit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify an optimal model with a pipeline and GridSearch\n",
    "\n",
    "### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (2101,)\n",
      "y_train shape: (2101,) \n",
      "\n",
      "X_test shape: (1036,)\n",
      "y_test shape: (1036,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size = 0.33,\n",
    "                                                    stratify = y,             # equal balance of yes and no in train and test\n",
    "                                                    random_state = 42)\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('y_train shape:', y_train.shape, '\\n')\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline accuracy\n",
    "\n",
    "**50.1% is the baseline accuracy percentage we compare with the model's accuracy.**\n",
    "\n",
    "**If the model does better than the baseline, then it is better than null model (predicting the majority class).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Balance of classes in `y`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    0.501753\n",
       "1    0.498247\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Balance of classes in `y_train`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    0.501666\n",
       "1    0.498334\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Balance of classes in `y_test`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    0.501931\n",
       "1    0.498069\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 416,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "printmd('**Balance of classes in `y`**')\n",
    "display(y.value_counts(normalize=True))\n",
    "\n",
    "printmd('**Balance of classes in `y_train`**')\n",
    "display(y_train.value_counts(normalize=True))\n",
    "\n",
    "printmd('**Balance of classes in `y_test`**')\n",
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cutoff point "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline 1\n",
    "\n",
    "**CountVectorizer (transformer)**:\n",
    "\n",
    "* Produces term frequencies by count\n",
    "\n",
    "**Multinomial Naive Bayes (estimator)**:\n",
    "\n",
    "* Fast modeling algorithm\n",
    "* Variables are positive integers\n",
    "* Assumes all variables are independent (which is not realistic in NLP, but this assumption is accepted anyway)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set a pipeline up with two stages:\n",
    "# 1. CountVectorizer (transformer)\n",
    "# 2. Multinomial Naive Bayes (estimator)\n",
    "\n",
    "pipe_cvec_nb = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('nb', MultinomialNB())    # Naive Bayes\n",
    "])\n",
    "\n",
    "\n",
    "# Search over the following values of hyperparameters:\n",
    "# Maximum number of features fit\n",
    "# Minimum number of documents needed to include token\n",
    "# Maximum number of documents needed to include token\n",
    "# Check (individual tokens) and also check (individual tokens and 2-grams).\n",
    "\n",
    "pipe_cvec_nb_params = {\n",
    "    'cvec__max_features': [1_000, 2_000, 3_000, 4_000, 5_000],\n",
    "    'cvec__min_df': [1, 2],\n",
    "    'cvec__max_df': [.98, .99],\n",
    "    'cvec__ngram_range': [(1,1), (1,2)]\n",
    "}\n",
    "\n",
    "# Instantiate GridSearchCV.\n",
    "\n",
    "gs_cvec_nb = GridSearchCV(pipe_cvec_nb,             # the object we are optimizing\n",
    "                  param_grid = pipe_cvec_nb_params, # the parameters values we are searching\n",
    "                  cv = 5)                           # Number of folds in cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('nb', MultinomialNB())]),\n",
       "             param_grid={'cvec__max_df': [0.98, 0.99],\n",
       "                         'cvec__max_features': [1000, 2000, 3000, 4000, 5000],\n",
       "                         'cvec__min_df': [1, 2],\n",
       "                         'cvec__ngram_range': [(1, 1), (1, 2)]})"
      ]
     },
     "execution_count": 352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit GridSearch to data.\n",
    "gs_cvec_nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Grid searched:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': [1000, 2000, 3000, 4000, 5000],\n",
       " 'cvec__min_df': [1, 2],\n",
       " 'cvec__max_df': [0.98, 0.99],\n",
       " 'cvec__ngram_range': [(1, 1), (1, 2)]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Best accuracy score**: 0.8648"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Best estimator / parameters:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cvec',\n",
       "                 CountVectorizer(max_df=0.98, max_features=5000, min_df=2,\n",
       "                                 ngram_range=(1, 2))),\n",
       "                ('nb', MultinomialNB())])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.98,\n",
       " 'cvec__max_features': 5000,\n",
       " 'cvec__min_df': 2,\n",
       " 'cvec__ngram_range': (1, 2)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printmd('**Grid searched:**')\n",
    "display(gs_cvec_nb.param_grid)\n",
    "printmd(f'**Best accuracy score**: {round(gs_cvec_nb.best_score_, 4)}')\n",
    "printmd('**Best estimator / parameters:**')\n",
    "display(gs_cvec_nb.best_estimator_)\n",
    "display(gs_cvec_nb.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x17b0a17c340>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "credit: NLP II: `CountVectorizer`, `TfidfVectorizer`, and Modeling lesson. _Authors: Dave Yerrington (SF), Justin Pounders (ATL), Riley Dallas (ATX), Matt Brems (DC), Noelle Brown (DEN)_"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATgAAAEWCAYAAADy2YssAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3debgV1Znv8e8PB0AlRgIoMogaHNAIIqGJ6TZEcxs0RsxAB2Mbr0OrHTJoRsxNR6NNNN6MnUSNQ5Q4gOAQj2irBPUSjRMgGoFGUYicgEwmGieGc977R9WBDTlnn12w99l7F7/P89Rzdq2qWvXuA7ysVatqlSICM7M86lTtAMzMKsUJzsxyywnOzHLLCc7McssJzsxyywnOzHLLCS5nJHWVdI+k1yVN2456TpX0YDljqxZJ/yRpUbXjsI4n3wdXHZI+B3wVOAT4GzAPmBgRj25nvacBXwKOjoiN2x1ojZMUwMCIWFztWKz2uAVXBZK+CvwU+D6wN9AfuBIYU4bq9wNe2BGSWykk7VztGKyKIsJLBy7AnsCbwNgi+3QmSYDL0+WnQOd020igEfgasApYAZyRbvsesB7YkJ7jLOBi4OaCugcAAeycrv9v4GWSVuQS4NSC8kcLjjsaeBp4Pf15dMG2R4BLgcfSeh4EerTx3Vri/2ZB/CcDJwAvAK8B3y7YfzjwOPDXdN9fALum22al3+Wt9Pt+tqD+bwGvAje1lKXHHJieY2i6vi+wBhhZ7b8bXsq/VD2AHW0BRgMbWxJMG/tcAjwB9AJ6An8ALk23jUyPvwTYJU0MbwN7pdu3TmhtJjhgd+AN4OB0W2/gsPTzpgQHdAf+ApyWHndKuv6+dPsjwEvAQUDXdP3yNr5bS/zfTeP/N2A1cCvQDTgMeBc4IN3/KGBEet4BwELg/IL6Anh/K/X/gOQ/iq6FCS7d59/SenYDHgB+WO2/F14qs7iL2vHeB6yJ4l3IU4FLImJVRKwmaZmdVrB9Q7p9Q0TcR9J6OXgb42kGDpfUNSJWRMT8Vvb5OPBiRNwUERsjYjLwP8AnCva5ISJeiIh3gKnAkCLn3EByvXEDMAXoAfwsIv6Wnn8+cARARMyJiCfS8y4FfgV8pITvdFFErEvj2UJEXAu8CDxJktT/Tzv1WZ1ygut4a4Ee7Vwb2hf4U8H6n9KyTXVslSDfBvbIGkhEvEXSrTsPWCHpXkmHlBBPS0x9CtZfzRDP2ohoSj+3JKCVBdvfaTle0kGSpkt6VdIbJNctexSpG2B1RLzbzj7XAocDP4+Ide3sa3XKCa7jPU7SBTu5yD7LSQYLWvRPy7bFWyRdsRb7FG6MiAci4n+RtGT+h+QffnvxtMT0522MKYurSOIaGBHvAb4NqJ1jit4aIGkPkuua1wMXS+pejkCt9jjBdbCIeJ3k+tMvJZ0saTdJu0g6XtIV6W6Tge9I6impR7r/zdt4ynnAMZL6S9oTuLBlg6S9JZ0kaXdgHUlXt6mVOu4DDpL0OUk7S/osMAiYvo0xZdGN5Drhm2nr8t+32r4SOCBjnT8D5kTE2cC9wNXbHaXVJCe4KoiIH5PcA/cdkgvsy4AvAr9Nd/lPYDbwHPBHYG5ati3nmgHcltY1hy2TUieS0djlJCOLHwG+0Eoda4ET033XkoyAnhgRa7Ylpoy+DnyOZHT2WpLvUuhiYJKkv0r6l/YqkzSGZKDnvLToq8BQSaeWLWKrGb7R18xyyy04M8stJzgzyy0nODPLLSc4M8utmnoQuUePHrHfgK1vt7Ja9sycZ6odgmUQBBHR3n2ERY0ePTrWrCltAH3OnDkPRMTo7Tnf9qipBLffgP147MnHqx2GZdC983urHYJl8G5Tew94tG/NmjXMnj27pH3T+zirpqYSnJnVh+Y6ub3MCc7MMgmCpmjtgZfa4wRnZpk1F3/ct2Y4wZlZJgE0R3O1wyiJE5yZZeYWnJnlU4QHGcwsnwK34MwspwJocgvOzPLKXVQzyy0nODPLpSB8Dc7M8qu5PvKbE5yZZRPhQQYzyzG34Mwsl5JHteojwznBmVlmbsGZWW7VSX5zgjOzbJIuarWjKI0TnJllE9BUH7MlOcGZWTZuwZlZrtXJIKoTnJllFPXTgvOLn80ss4jSllJI2knSM5Kmp+vdJc2Q9GL6c6+CfS+UtFjSIkmj2qvbCc7MMgmSQYZSlhJ9BVhYsD4BmBkRA4GZ6TqSBgHjgMOA0cCVknYqVrETnJllVq4WnKS+wMeB6wqKxwCT0s+TgJMLyqdExLqIWAIsBoYXq98JzsyyCYhQSQvQQ9LsguWcrWr7KfBNoLC9t3dErABIf/ZKy/sAywr2a0zL2uRBBjPLJMg0iromIoa1tkHSicCqiJgjaWQJdamNcNrkBGdmmZXptagfBk6SdALQBXiPpJuBlZJ6R8QKSb2BVen+jUC/guP7AsuLncBdVDPLrBzX4CLiwojoGxEDSAYPHoqIfwUagNPT3U4H7k4/NwDjJHWWtD8wEHiq2DncgjOzbAKam1rrLZbN5cBUSWcBrwBjASJivqSpwAJgIzA+IpqKVeQEZ2bZlflG34h4BHgk/bwWOK6N/SYCE0ut1wnOzDIJNo2Q1jwnODPLJso2yFBxTnBmll2dPIvqBGdmmbkFZ2b5FBCVHUUtGyc4M8vOXVQzy6VgyydHa5gTnJll5wRnZnnlKcvNLJ+C5EGpOuAEZ2bZuQVnZrnkQQYzyzM5wZlZbjnBmVkuBb4GZ2b5pY31keGc4MwsGw8ymFl+BWqujxacXzpTJk1NTYwYNpxPnXTyFuU/+dGP6bpzZ9asWQPA2rVrGXXcP9Njz+6c/+WvVCNUKzDwoIE8MfuJTcurr73K+C+P5wNHfICHH32Yp555itt/ezvdunWrdqi1JUpcqqyiCU7SaEmLJC2WNKGS56q2X/zXzzn4kEO2KFu2bBkP/W4m/fr331TWpUsXvvu9i7jsiss7OkRrxYsvvMiIYSMYMWwERw8/mnfefoeG3zZw5a+u5D++/R8MP3I4Db9t4IKvX1DtUGtHgJqjpKXaKpbgJO0E/BI4HhgEnCJpUKXOV02NjY3cf99/c8aZZ2xR/s2vfYOJl1+GtHnurN13350P/+OH6dKlS0eHae346HEf5eWXX2bZK8sYePBAHp31KAAzfzeTMZ8cU+XoakxzlLYUIamLpKckPStpvqTvpeUXS/qzpHnpckLBMRemDaZFkka1F2YlW3DDgcUR8XJErAemALn8W/KNr36diZdfRqdOm3+d0++5h3377MsRg4+oYmSWxdh/Gcu0KdMAWDB/ASd+4kQAPvWZT9G3X99qhlZTFMkoailLO9YBx0bEYGAIMFrSiHTbTyJiSLrcB5A2kMYBhwGjgSvThlSbKpng+gDLCtYb07ItSDpH0mxJs1evXlPBcCrjvun30qtXT4YeNXRT2dtvv80Pvv8DvnvxRVWMzLLYZZddOOETJ3Dn7XcCcN7Z53HOF87hsScfo1u3bqxfv77KEdaS0rqn7XVRI/FmurpLuhQ7aAwwJSLWRcQSYDFJQ6pNlRxFbW1O478LPiKuAa4BOGrYUdXvtGf0+B8eZ/o993L/fz/Aunff5Y033uDM08/gT0uXMnzoBwH4c2MjH/rgCH7/+KPss88+VY7YWjNq9CjmPTOPVatWAfDCohc46fiTAHj/wPcz+oTR1QyvtgSo9PmSekiaXbB+TfpvHth0KWsO8H7glxHxpKTjgS9K+jwwG/haRPyFpIH0REFdrTaaClWyBdcI9CtY7wssr+D5quLS7/8nL/3pZRa99AK/ueUmRn50JFOm3cYrKxpZ9NILLHrpBfr07cvjTz/h5FbDxo7b3D0F6NmzJwCS+Na3v8V1v7quWqHVpubm0hZYExHDCpZrCquJiKaIGEKSH4ZLOhy4CjiQpNu6AvhRuntJjaZClUxwTwMDJe0vaVeSvnNDBc9XNw4+8CC+9fVvcvOkmzhwvwNYuGBhtUPaoXXt2pVjP3Ysd99196aysePG8uyCZ5k3fx4rVqzgNzf+pooR1p5yj6JGxF9J3mw/OiJWpomvGbiWzd3QzI0mRQWn5kxHP34K7AT8OiImFtv/qGFHxWNPPl6xeKz8und+b7VDsAzebXqX5mjerldiHXrg4PjNZQ+UtO/wz/aeExHDWtsmqSewISL+Kqkr8CDwA2BORKxI97kA+IeIGCfpMOBWkoS3LzATGBgRTW2dv6JPMqSjH/dV8hxm1rEEqDwvRu0NTEqvw3UCpkbEdEk3SRpC0v1cCpwLEBHzJU0FFpDMKTy+WHIDP6plZlmlN/pudzURzwFHtlJ+WpFjJgJFe4KFnODMLKNoGUCoeU5wZpZNgJzgzCyvMtwHV1VOcGaWTQTaWB/vDXSCM7NMRJRrFLXinODMLDtfgzOzXIpAzUVvP6sZTnBmlpm7qGaWX+6imlkuRaCmDdWOoiROcGaWUYC7qGaWVyr+jHvNcIIzs2wiwKOoZpZb7qKaWS5FMzTVx0t4nODMLJNkwkt3Uc0slwKc4MwsjwJoZ6bwmuEEZ2YZuQVnZnkV9ZPgKvleVDPLpSCa15e0FCOpi6SnJD0rab6k76Xl3SXNkPRi+nOvgmMulLRY0iJJo9qL1AnOzLKLptKW4tYBx0bEYJK32I+WNAKYAMyMiIEk7z6dACBpEMkL5A8DRgNXpq8cbJMTnJllFGVJcJF4M13dJV0CGANMSssnASenn8cAUyJiXUQsARaz+a33rXKCM7NsIojYWNIC9JA0u2A5p7AqSTtJmgesAmZExJPA3i1vtk9/9kp37wMsKzi8MS1rkwcZzCyjICh5kGFNRAxrs6bkfpMhkt4L3CXp8CJ1qdVgimgzwUn6ebGDI+LLxSo2s7yKdgcQMtcY8VdJj5BcW1spqXdErJDUm6R1B0mLrV/BYX2B5cXqLdaCm70d8ZpZTgVBsP2vDZTUE9iQJreuwMeAHwANwOnA5enPu9NDGoBbJf0Y2BcYCDxV7BxtJriImFS4Lmn3iHhrG7+LmeVImZ5k6A1MSkdCOwFTI2K6pMeBqZLOAl4BxibnjPmSpgILgI3A+GgnkHavwUn6EHA9sAfQX9Jg4NyI+MJ2fDEzq1uZrsG1XUvEc8CRrZSvBY5r45iJwMRSz1HKKOpPgVHA2vQEzwLHlHoCM8ufiKaSlmoraRQ1IpZJWwxgVD9yM6uKIGiukxRQSoJbJuloICTtCnwZWFjZsMysZkXQHOuqHUVJSklw5wE/I7mh7s/AA8D4SgZlZrUsaK6B7mcp2k1wEbEGOLUDYjGzOhBlGmToCO0OMkg6QNI9klZLWiXpbkkHdERwZlabmmkqaam2UkZRbwWmktyzsi8wDZhcyaDMrJZFrhKcIuKmiNiYLjfTzvNfZpZfATRHU0lLtRV7FrV7+vFhSROAKSTf7bPAvR0Qm5nVpGaaqP/XBs4hSWgtN8CdW7AtgEsrFZSZ1a4Ammqg+1mKYs+i7t+RgZhZvcjXjb6kczQNArq0lEXEbyoVlJnVroD8JDhJFwEjSRLcfcDxwKOAE5zZDilfLbjPAIOBZyLiDEl7A9dVNiwzq1VBsIEN1Q6jJKUkuHciolnSRknvIZld0zf6mu2gki5qc7XDKEkpCW52Ol/6tSQjq2/SziyaZpZnUf+jqC0KJra8WtL9wHvSierMbAeUTJdU5y04SUOLbYuIuZUJycxqXR5acD8qsi2AY8scC3PnzKXrzp3LXa1VUISf2qsnw4a1+Qa/kiVzidR5Cy4iPtqRgZhZfQhgQxneqtUR/GZ7M8ukpQVXylKMpH6SHpa0UNJ8SV9Jyy+W9GdJ89LlhIJjLpS0WNIiSaPai9VvtjezzJpUli7qRuBrETFXUjdgjqQZ6bafRMQPC3eWNAgYBxxGMnXb7yQdVOzVgU5wZpZJua7BRcQKYEX6+W+SFpK8GqEtY4ApEbEOWCJpMTAceLytA0qZ0VeS/lXSd9P1/pKGZ/geZpYzGbqoPSTNLljOaa0+SQNI3pH6ZFr0RUnPSfq1pL3Ssj7AsoLDGimeEEu6Bncl8CHglHT9b8AvSzjOzHIomS4pSlqANRExrGC5Zuv6JO0B3AGcHxFvAFcBBwJDSFp4LXd0aOtjaWfy3VK6qP8QEUMlPQMQEX9JXx9oZjugIFhfpvvgJO1CktxuiYg7ASJiZcH2a4Hp6Woj0K/g8L7A8mL1l9KC2yBpJ9JMKakn1MlNMGZWdkkLriyjqAKuBxZGxI8LynsX7PZJ4Pn0cwMwTlJnSfsDA2nnsdFSWnD/BdwF9JI0kWR2ke+UcJyZ5VRTeV7L8mHgNOCPkualZd8GTpE0hCSXLiWdTTwi5kuaCiwgGYEdX2wEFUp7FvUWSXOA40j6wCdHhN9sb7aDis3X17avnohHaf262n1FjpkITCz1HKVMeNkfeBu4p7AsIl4p9SRmlh8tgwz1oJQu6r1sfvlMF2B/YBHJzXZmtoMJYH15bvStuFK6qB8oXE9nGTm3jd3NbAeQpxbcFtLHKj5YiWDMrPaV6xpcRyjlGtxXC1Y7AUOB1RWLyMxqWnINrj6U0oLrVvB5I8k1uTsqE46Z1YNctODSG3z3iIhvdFA8ZlbjAmiqj/xWdMrynSNiY7Gpy81sxxPA+hy04J4iud42T1IDMA14q2Vjy3NjZrZjyds1uO7AWpJ3MLTcDxeAE5zZDioPCa5XOoL6PJsTW4v6aJ+aWdnlpQW3E7AH2zAHk5nlW90PMgArIuKSDovEzOpCXlpwrbXczGwHl7w2sD4US3DHdVgUZlY3kvvg6qP9U+zFz691ZCBmVj/y0EU1M/s7ATTXewvOzKwtbsGZWS5FiA110oIr5a1aZmabtHRRS1mKkdRP0sOSFkqaL+kraXl3STMkvZj+3KvgmAslLZa0SNKo9mJ1gjOzzMqR4EimX/taRBwKjADGSxoETABmRsRAYGa6TrptHMnrEkYDV6YzHrXJCc7MMklu9FVJS9F6IlZExNz089+AhUAfYAwwKd1tEnBy+nkMMCUi1kXEEmAxMLzYOXwNzswyay79Ua0ekmYXrF8TEddsvZOkAcCRwJPA3hGxApIkKKlXulsf4ImCwxrTsjY5wZlZJhlvE1kTEcOK7SBpD5JZws+PiDeSF963vmsb4bTJCc7Msgmxsbk8V7ck7UKS3G4pmGNypaTeaeutN7AqLW8E+hUc3hdYXqx+X4Mzs0zKOIoq4HpgYUT8uGBTA3B6+vl04O6C8nGSOkvaHxhIMjFvm9yCM7PMojz3wX0YOA34o6R5adm3gcuBqZLOAl4BxibnjPmSpgILSEZgx0dE0XuOneDMLLNyPKoVEY/S9qxFrU72ERETgYmlnsMJzswyidLucasJTnBmlllTmQYZKs0JzswyCcp2Da7inODMLDN3Uc0sn0JuwZlZfkWzE5yZ5ZCvwZlZfgU0N3kU1cxyydfgzCzHfA3OzPIpgDppwdVHR7qO7LnnnkybNo2FCxeyYMECRowYwRFHHMEf/vAHnnvuORoaGujWrVu1wzSgqamJI488khNPPHGL8h/+8IdIYs2aNQDccsstDBkyZNPSqVMn5s2b11qVO4QAorm0pdoqluAk/VrSKknPV+octehnP/sZ999/P4ceeiiDBw9m4cKFXHfddUyYMIEjjjiCu+66i2984xvVDtNI/qwOPfTQLcqWLVvGjBkz6N+//6ayU089lXnz5jFv3jxuuukmBgwYwJAhQzo63JoS6b1w7S3VVskW3I0kL4bYYXTr1o1jjjmG66+/HoANGzbw+uuvc/DBBzNr1iwAZsyYwac//elqhmlAY2Mj9957L2efffYW5RdccAFXXHEFbc0qO3nyZE455ZSOCLF2hYimTiUt1VaxCCJiFvBapeqvRQcccACrV6/mhhtuYO7cuVx77bXstttuPP/885x00kkAjB07ln79+rVTk1Xa+eefzxVXXEGnTpv/CTQ0NNCnTx8GDx7c5nG33XabExxAc4lLlVU9xUo6R9LsrV5MUZd23nlnhg4dylVXXcXQoUN56623mDBhAmeeeSbjx49n9uzZdOvWjfXr11c71B3a9OnT6dWrF0cdddSmsrfffpuJEydyySWXtHnck08+yW677cbhhx/eEWHWrgCaVdpSZVVPcBFxTUQMa+/FFPWgsbGRxsZGnnoqmUX59ttvZ+jQoSxatIhRo0YxbNgwJk+ezEsvvVTlSHdsjz32GA0NDQwYMIBx48bx0EMPcdppp7FkyRIGDx7MgAEDaGxsZOjQobz66qubjpsyZYpbb6mI0pZqq3qCy5OVK1eybNkyDjroIACOO+44FixYQM+ePQGQxHe+8x2uvvrqaoa5w7vssstobGxk6dKlTJkyhWOPPZY77riDVatWsXTpUpYuXUrfvn2ZO3cu++yzDwDNzc1MmzaNcePGVTn6GlEnLTjfB1dmX/rSl7jlllvYddddefnllznjjDP4/Oc/z/jx4wG48847ueGGG6ocpWU1a9Ys+vbtywEHHFDtUKovgKbqJ69SKCrUjpQ0GRgJ9ABWAhdFxPXtHFMDjVrLolJ/f6wyhg0bxuzZs7crO+3y3vfGXv/4kZL2XX1vw5xqXn6q5CjqKRHROyJ2iYi+7SU3M6sTQdlGUVu7X1bSxZL+LGleupxQsO1CSYslLZI0qr36fQ3OzLIr320iN9L6/bI/iYgh6XIfgKRBwDjgsPSYKyXtVKxyJzgzyy5KXNqrJtv9smOAKRGxLiKWAIuB4cUOcIIzs2yy3QfXo+U+13Q5p8SzfFHSc2kXdq+0rA+wrGCfxrSsTR5FNbNsArSx5MGlNdswyHAVcGlyJi4FfgScSesviS4aiFtwZpZdmbqorVYdsTIimiKiGbiWzd3QRqDwOce+wPJidTnBmVl2FXwWVVLvgtVPAi0jrA3AOEmdJe0PDASeKlaXu6hmlk3LbSJlUHi/rKRG4CJgpKQh6ZmWAucCRMR8SVOBBcBGYHxENBWr3wnOzLJrLs8N3hHR2sO9bd4zGxETgYml1u8EZ2aZqQamQiqFE5yZZRNAU308oucEZ2aZqUxd1EpzgjOzbGplsrcSOMGZWXZuwZlZHgl3Uc0srwJoqo9hVCc4M8so3EU1s5wKkAcZzCy33IIzs9wKX4MzszwKX4MzsxxTU9FJPGqGE5yZZRTuoppZTgXuoppZjrkFZ2b55C6qmeVVQLiLamb5FNC8sdpBlMQJzsyya66PLqpfG2hm2QRENJe0tCd9c/0qSc8XlHWXNEPSi+nPvQq2XShpsaRFkka1V78TnJlllA4ylLK070Zg9FZlE4CZETEQmJmuI2kQMA44LD3mSkk7FavcCc7MsitTgouIWcBrWxWPASalnycBJxeUT4mIdRGxBFjM5rfet8rX4MwskyCI0gcZekiaXbB+TURc084xe0fECoCIWCGpV1reB3iiYL/GtKxNTnBmlk16Da5EayJiWJnOrNajaZsTnJllFFkS3LZYKal32nrrDaxKyxuBfgX79QWWF6vI1+DMLLvyDTK0pgE4Pf18OnB3Qfk4SZ0l7Q8MBJ4qVpFbcGaWUflacJImAyNJrtU1AhcBlwNTJZ0FvAKMBYiI+ZKmAguAjcD4iCg6b5MTnJllVq4EFxGntLHpuDb2nwhMLLV+JzgzyyQiaPajWmaWV0F9PKrlBGdmGVV8FLVsnODMLDMnODPLpcAJzsxyK2gu/gBBzXCCM7NsAo+imlk+BUGzR1HNLK98Dc7McsvX4Mwsl4Kg2S04M8urpuLPuNeMWktwa4A/VTuICuhB8t1yR2ptDsJcyOuf2X5lqOMBkt9PKar6O1REffSl65mk2WWc1dQ6gP/M8sETXppZbjnBmVluOcF1jPbeImS1x39mOeBrcGaWW27BmVluOcGZWW45wVWQpNGSFklaLGlCteOx9kn6taRVkp6vdiy2/ZzgKkTSTsAvgeOBQcApkgZVNyorwY3A6GoHYeXhBFc5w4HFEfFyRKwHpgBjqhyTtSMiZgGvVTsOKw8nuMrpAywrWG9My8ysgzjBVU5rD2n6nhyzDuQEVzmNQL+C9b7A8irFYrZDcoKrnKeBgZL2l7QrMA5oqHJMZjsUJ7gKiYiNwBdJppZZCEyNiPnVjcraI2ky8DhwsKRGSWdVOybbdn5Uy8xyyy04M8stJzgzyy0nODPLLSc4M8stJzgzyy0nuDoiqUnSPEnPS5omabftqOtGSZ9JP19XbCIASSMlHb0N51gq6e/evtRW+Vb7vJnxXBdL+nrWGC3fnODqyzsRMSQiDgfWA+cVbkxnMMksIs6OiAVFdhkJZE5wZtXmBFe/fg+8P21dPSzpVuCPknaS9H8lPS3pOUnnAijxC0kLJN0L9GqpSNIjkoaln0dLmivpWUkzJQ0gSaQXpK3Hf5LUU9Id6TmelvTh9Nj3SXpQ0jOSfkXrz+NuQdJvJc2RNF/SOVtt+1Eay0xJPdOyAyXdnx7ze0mHlOOXaflUay9+thJI2plknrn706LhwOERsSRNEq9HxAcldQYek/QgcCRwMPABYG9gAfDrrertCVwLHJPW1T0iXpN0NfBmRPww3e9W4CcR8aik/iRPaxwKXAQ8GhGXSPo4sEXCasOZ6Tm6Ak9LuiMi1gK7A3Mj4muSvpvW/UWSl8GcFxEvSvoH4Erg2G34NdoOwAmuvnSVNC/9/HvgepKu41MRsSQt/2fgiJbra8CewEDgGGByRDQByyU91Er9I4BZLXVFRFvzon0MGFTwVvv3SOqWnuNT6bH3SvpLCd/py5I+mX7ul8a6FmgGbkvLbwbulLRH+n2nFZy7cwnnsB2UE1x9eScihhQWpP/Q3yosAr4UEQ9std8JtD9dk0rYB5JLGx+KiHdaiaXkZ/8kjSRJlh+KiLclPQJ0aWP3SM/7161/B2Zt8TW4/HkA+HdJuwBIOkjS7sAsYFx6ja438NFWjn0c+Iik/dNju6flfwO6Fez3IEl3kXS/loQzCzg1LTse2KudWPcE/pImt0NIWpAtOgEtrdDPkXR93wCWSBqbnkOSBrdzDtuBOcHlz3Uk19fmpi9O+RVJS/0u4EXgj8BVwP/b+sCIWE1y3exOSc+yuYt4D/DJlkEG4MvAsHQQYwGbR3O/BxwjaS49oSMAAABZSURBVC5JV/mVdmK9H9hZ0nPApcATBdveAg6TNIfkGtslafmpwFlpfPPxNPBWhGcTMbPccgvOzHLLCc7McssJzsxyywnOzHLLCc7McssJzsxyywnOzHLr/wOj+H/l+6HHjwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get predictions\n",
    "preds = gs_cvec_nb.predict(X_test)\n",
    "\n",
    "# Save confusion matrix values\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n",
    "\n",
    "# View confusion matrix\n",
    "\n",
    "display(plot_confusion_matrix(gs_cvec_nb, X_test, y_test, cmap='cubehelix', values_format='d'));\n",
    "plt.title('Confusion matrix')\n",
    "\n",
    "printmd('credit: NLP II: `CountVectorizer`, `TfidfVectorizer`, and Modeling lesson. _Authors: Dave Yerrington (SF), Justin Pounders (ATL), Riley Dallas (ATX), Matt Brems (DC), Noelle Brown (DEN)_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8571428571428571\n",
      "Misclassification: 0.14285714285714285\n",
      "Sensitivity: 0.8662790697674418\n",
      "Precision: 0.8498098859315589\n",
      "Specificity: 0.8480769230769231\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy\n",
    "\n",
    "acc = (tp + tn) / (tp + fp + tn + fn)\n",
    "print('Accuracy:', acc)\n",
    "\n",
    "# Calculate the misclassification rate\n",
    "\n",
    "misclass = (fp + fn) / (tp + fp + tn + fn)\n",
    "print('Misclassification:', misclass)\n",
    "\n",
    "# Calculate the sensitivity\n",
    "\n",
    "sens = tp / (tp + fn)\n",
    "print('Sensitivity:', sens)\n",
    "\n",
    "# Calculate the precision\n",
    "\n",
    "prec = tp / (tp + fp)\n",
    "print('Precision:', prec)\n",
    "\n",
    "# Calculate the specificity\n",
    "\n",
    "spec = tn / (tn + fp)\n",
    "print('Specificity:', spec)\n",
    "\n",
    "# credit: Heather Robinson at General Assembly  :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline 1 Part 2\n",
    "\n",
    "**CountVectorizer (transformer)**:\n",
    "\n",
    "* Produces term frequencies by count \n",
    "\n",
    "\n",
    "**Multinomial Naive Bayes (estimator)**:\n",
    "\n",
    "* Fast modeling algorithm\n",
    "* Variables are positive integers\n",
    "* Assumes all variables are independent (which is not realistic in NLP, but this assumption is accepted anyway)\n",
    "\n",
    "**GridSearchCV parameter search**:\n",
    "\n",
    "* Comparing the grid searched and the best parameters from Pipeline 1 Part 1, I varied the range of the parameters to see what the search would come up with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set a pipeline up with two stages:\n",
    "# 1. CountVectorizer (transformer)\n",
    "# 2. Multinomial Naive Bayes (estimator)\n",
    "\n",
    "pipe_cvec_nb = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('nb', MultinomialNB())    # Naive Bayes\n",
    "])\n",
    "\n",
    "\n",
    "# Search over the following values of hyperparameters:\n",
    "# Maximum number of features fit\n",
    "# Minimum number of documents needed to include token\n",
    "# Check (individual tokens) and also check (individual tokens and 2-grams).\n",
    "\n",
    "pipe_cvec_nb_params = {\n",
    "    'cvec__max_features': [2_000, 4_000, 6_000],\n",
    "    'cvec__min_df': [1, 2],\n",
    "    'cvec__max_df': [.05, .1, .25, .4],\n",
    "    'cvec__ngram_range': [(1, 1), (1, 2)], \n",
    "    'cvec__stop_words': [None, 'english']\n",
    "}\n",
    "\n",
    "# Instantiate GridSearchCV.\n",
    "\n",
    "gs_cvec_nb = GridSearchCV(pipe_cvec_nb, \n",
    "                  param_grid = pipe_cvec_nb_params, \n",
    "                  cv=5)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('nb', MultinomialNB())]),\n",
       "             param_grid={'cvec__max_df': [0.05, 0.1, 0.25, 0.4],\n",
       "                         'cvec__max_features': [2000, 4000, 6000],\n",
       "                         'cvec__min_df': [1, 2],\n",
       "                         'cvec__ngram_range': [(1, 1), (1, 2)],\n",
       "                         'cvec__stop_words': [None, 'english']})"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit GridSearch to data.\n",
    "gs_cvec_nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Grid searched:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': [2000, 4000, 6000],\n",
       " 'cvec__min_df': [1, 2],\n",
       " 'cvec__max_df': [0.05, 0.1, 0.25, 0.4],\n",
       " 'cvec__ngram_range': [(1, 1), (1, 2)],\n",
       " 'cvec__stop_words': [None, 'english']}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Best score**: 0.8749"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Best estimator / parameters:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cvec', CountVectorizer(max_df=0.25, max_features=6000)),\n",
       "                ('nb', MultinomialNB())])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.25,\n",
       " 'cvec__max_features': 6000,\n",
       " 'cvec__min_df': 1,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__stop_words': None}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printmd('**Grid searched:**')\n",
    "display(gs_cvec_nb.param_grid)\n",
    "printmd(f'**Best score**: {round(gs_cvec_nb.best_score_, 4)}')\n",
    "printmd('**Best estimator / parameters:**')\n",
    "display(gs_cvec_nb.best_estimator_)\n",
    "display(gs_cvec_nb.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x17b68490220>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "credit: NLP II: `CountVectorizer`, `TfidfVectorizer`, and Modeling lesson. _Authors: Dave Yerrington (SF), Justin Pounders (ATL), Riley Dallas (ATX), Matt Brems (DC), Noelle Brown (DEN)_"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get predictions\n",
    "preds = gs_cvec_nb.predict(X_test)\n",
    "\n",
    "# Save confusion matrix values\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n",
    "\n",
    "# View confusion matrix\n",
    "\n",
    "display(plot_confusion_matrix(gs_cvec_nb, X_test, y_test, cmap='cubehelix', values_format='d'));\n",
    "plt.title('Confusion matrix')\n",
    "\n",
    "printmd('credit: NLP II: `CountVectorizer`, `TfidfVectorizer`, and Modeling lesson. _Authors: Dave Yerrington (SF), Justin Pounders (ATL), Riley Dallas (ATX), Matt Brems (DC), Noelle Brown (DEN)_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8770226537216829\n",
      "Misclassification: 0.12297734627831715\n",
      "Sensitivity: 0.8831341301460823\n",
      "Precision: 0.8670143415906127\n",
      "Specificity: 0.8712121212121212\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy\n",
    "\n",
    "acc = (tp + tn) / (tp + fp + tn + fn)\n",
    "print('Accuracy:', acc)\n",
    "\n",
    "# Calculate the misclassification rate\n",
    "\n",
    "misclass = (fp + fn) / (tp + fp + tn + fn)\n",
    "print('Misclassification:', misclass)\n",
    "\n",
    "# Calculate the sensitivity\n",
    "\n",
    "sens = tp / (tp + fn)\n",
    "print('Sensitivity:', sens)\n",
    "\n",
    "# Calculate the precision\n",
    "\n",
    "prec = tp / (tp + fp)\n",
    "print('Precision:', prec)\n",
    "\n",
    "# Calculate the specificity\n",
    "\n",
    "spec = tn / (tn + fp)\n",
    "print('Specificity:', spec)\n",
    "\n",
    "# credit: Heather Robinson at General Assembly  :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline 3\n",
    "\n",
    "**TfidfVectorizer (transformer)**\n",
    "\n",
    "\n",
    "\n",
    "**Multinomial Naive Bayes (estimator)**:\n",
    "\n",
    "* Fast modeling algorithm\n",
    "* Variables are positive integers\n",
    "* Assumes all variables are independent (which is not realistic in NLP, but this assumption is accepted anyway)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set a pipeline up with two stages:\n",
    "# 1. TfidfVectorizer (transformer)\n",
    "# 2. Multinomial Naive Bayes (estimator)\n",
    "\n",
    "pipe_tvec_nb = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),   # TfidfVectorizer uses natural log, not as interpretable as CountVectorizer\n",
    "    ('nb', MultinomialNB())    # Naive Bayes\n",
    "])\n",
    "\n",
    "\n",
    "# Search over the following values of hyperparameters:\n",
    "# Maximum number of features fit\n",
    "# Minimum number of documents needed to include token\n",
    "# Maximum number of documents needed to include token\n",
    "# Check (individual tokens) and also check (individual tokens and 2-grams).\n",
    "\n",
    "pipe_tvec_nb_params = {\n",
    "    'tvec__max_features': [2_000, 3_000, 4_000, 5_000],\n",
    "    'tvec__stop_words': [None, 'english'],\n",
    "    'tvec__ngram_range': [(1,1), (1,2)]\n",
    "}\n",
    "\n",
    "# Instantiate GridSearchCV.\n",
    "\n",
    "gs_tvec_nb = GridSearchCV(pipe_tvec_nb, # what object are we optimizing?\n",
    "                  param_grid = pipe_tvec_nb_params, # what parameters values are we searching?\n",
    "                  cv = 5)      # 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tvec', TfidfVectorizer()), ('nb', MultinomialNB())])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit GridSearch to data.\n",
    "pipe_tvec_nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Grid searched:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'tvec__max_features': [2000, 3000, 4000, 5000],\n",
       " 'tvec__stop_words': [None, 'english'],\n",
       " 'tvec__ngram_range': [(1, 1), (1, 2)]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_score_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-196-85319eebdbd6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprintmd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'**Grid searched:**'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgs_tvec_nb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprintmd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'**Best accuracy score**: {round(gs_tvec_nb.best_score_, 4)}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprintmd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'**Best estimator / parameters:**'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgs_tvec_nb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_score_'"
     ]
    }
   ],
   "source": [
    "printmd('**Grid searched:**')\n",
    "display(gs_tvec_nb.param_grid)\n",
    "printmd(f'**Best accuracy score**: {round(gs_tvec_nb.best_score_, 4)}')\n",
    "printmd('**Best estimator / parameters:**')\n",
    "display(gs_tvec_nb.best_estimator_)\n",
    "display(gs_tvec_nb.best_params_)\n",
    "\n",
    "pd.DataFrame(gs_tvec_nb.cv_results_).sort_values('rank_test_score').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "credit: NLP II: `CountVectorizer`, `TfidfVectorizer`, and Modeling lesson. _Authors: Dave Yerrington (SF), Justin Pounders (ATL), Riley Dallas (ATX), Matt Brems (DC), Noelle Brown (DEN)_"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get predictions\n",
    "preds = gs_tvec_nb.predict(X_test)\n",
    "\n",
    "# Save confusion matrix values\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n",
    "\n",
    "# View confusion matrix\n",
    "\n",
    "plot_confusion_matrix(gs_tvec_nb, X_test, y_test, cmap='cubehelix', values_format='d');\n",
    "plt.title('Confusion matrix')\n",
    "\n",
    "printmd('credit: NLP II: `CountVectorizer`, `TfidfVectorizer`, and Modeling lesson. _Authors: Dave Yerrington (SF), Justin Pounders (ATL), Riley Dallas (ATX), Matt Brems (DC), Noelle Brown (DEN)_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8400673400673401\n",
      "Misclassification: 0.15993265993265993\n",
      "Sensitivity: 0.8534201954397395\n",
      "Precision: 0.8397435897435898\n",
      "Specificity: 0.8257839721254355\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy\n",
    "\n",
    "acc = (tp + tn) / (tp + fp + tn + fn)\n",
    "print('Accuracy:', acc)\n",
    "\n",
    "# Calculate the misclassification rate\n",
    "\n",
    "misclass = (fp + fn) / (tp + fp + tn + fn)\n",
    "print('Misclassification:', misclass)\n",
    "\n",
    "# Calculate the sensitivity\n",
    "\n",
    "sens = tp / (tp + fn)\n",
    "print('Sensitivity:', sens)\n",
    "\n",
    "# Calculate the precision\n",
    "\n",
    "prec = tp / (tp + fp)\n",
    "print('Precision:', prec)\n",
    "\n",
    "# Calculate the specificity\n",
    "\n",
    "spec = tn / (tn + fp)\n",
    "print('Specificity:', spec)\n",
    "\n",
    "def metrics(y_test, y_predict, pred_proba):\n",
    "    print('Accuracy score %s ' % accuracy_score(y_test, y_predict), '\\n')\n",
    "    print('----------------------------------------------------------------')\n",
    "    print(pd.DataFrame(confusion_matrix(y_test, y_predict), \n",
    "                            index=['Not Actual Disaster', 'Actual Disaster'], \n",
    "                            columns=['Predicted Not Actual Disaster', 'Predicted Disaster']), '\\n')\n",
    "    print('-----------------------------------------------------------------')\n",
    "    print(classification_report(y_test, y_predict))\n",
    "    print('-----------------------------------------------------------------')\n",
    "    print('ROC_AUC SCORE %s ' %roc_auc_score(y_test, pred_proba))\n",
    "    \n",
    "# credit: Heather Robinson :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline 4\n",
    "\n",
    "\n",
    "\n",
    "**CountVectorizer (transformer)**:\n",
    "\n",
    "\n",
    "\n",
    "**Random Forest (estimator)**:\n",
    "\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set a pipeline up with two stages:\n",
    "# 1. CountVectorizer (transformer)\n",
    "# 2. Random Forest (estimator)\n",
    "\n",
    "pipe_cvec_rf = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('rf', RandomForestClassifier()) \n",
    "])\n",
    "\n",
    "\n",
    "# Search over the following values of hyperparameters:\n",
    "# Maximum number of features fit\n",
    "# Minimum number of documents needed to include token\n",
    "# Maximum number of documents needed to include token\n",
    "# Check (individual tokens) and also check (individual tokens and 2-grams).\n",
    "\n",
    "pipe_cvec_rf_params = {\n",
    "    'cvec__max_features': [5_000],\n",
    "    'cvec__min_df': [1],\n",
    "    'cvec__max_df': [.75],\n",
    "    'cvec__ngram_range': [(1,1)],\n",
    "    'rf__n_estimators': [100, 200], \n",
    "    'rf__max_depth': [None, .25],\n",
    "    'rf__max_features': ['auto', 2_000]\n",
    "}\n",
    "\n",
    "# Instantiate GridSearchCV.\n",
    "\n",
    "gs_cvec_rf = GridSearchCV(pipe_cvec_rf,             # the object we are optimizing\n",
    "                  param_grid = pipe_cvec_rf_params, # the parameters values we are searching\n",
    "                  cv = 5)                           # Number of folds in cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('rf', RandomForestClassifier())]),\n",
       "             param_grid={'cvec__max_df': [0.75], 'cvec__max_features': [5000],\n",
       "                         'cvec__min_df': [1], 'cvec__ngram_range': [(1, 1)],\n",
       "                         'rf__max_depth': [None, 0.25],\n",
       "                         'rf__max_features': ['auto', 2000],\n",
       "                         'rf__n_estimators': [100, 200]})"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit GridSearch to data.\n",
    "gs_cvec_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Grid searched:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': [5000],\n",
       " 'cvec__min_df': [1],\n",
       " 'cvec__max_df': [0.75],\n",
       " 'cvec__ngram_range': [(1, 1)],\n",
       " 'rf__n_estimators': [100, 200],\n",
       " 'rf__max_depth': [None, 0.25],\n",
       " 'rf__max_features': ['auto', 2000]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Best accuracy score**: 0.832"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Best estimator / parameters:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cvec', CountVectorizer(max_df=0.75, max_features=5000)),\n",
       "                ('rf', RandomForestClassifier())])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.75,\n",
       " 'cvec__max_features': 5000,\n",
       " 'cvec__min_df': 1,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'rf__max_depth': None,\n",
       " 'rf__max_features': 'auto',\n",
       " 'rf__n_estimators': 100}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Accuracy score on train set:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Accuracy score on test set:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8426640926640927"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printmd('**Grid searched:**')\n",
    "display(gs_cvec_rf.param_grid)\n",
    "printmd(f'**Best accuracy score**: {round(gs_cvec_rf.best_score_, 4)}')\n",
    "printmd('**Best estimator / parameters:**')\n",
    "display(gs_cvec_rf.best_estimator_)\n",
    "display(gs_cvec_rf.best_params_)\n",
    "printmd('**Accuracy score on train set:**')\n",
    "display(gs_cvec_rf.score(X_train, y_train))\n",
    "printmd('**Accuracy score on test set:**')\n",
    "display(gs_cvec_rf.score(X_test, y_test))\n",
    "\n",
    "\n",
    "# *****************************************************************\n",
    "# cross val .8912 best score, .99 train, .89 test\n",
    "# Grid searched:\n",
    "\n",
    "# {'cvec__max_features': [5000],\n",
    "#  'cvec__min_df': [1],\n",
    "#  'cvec__max_df': [0.75],\n",
    "#  'cvec__ngram_range': [(1, 1)],\n",
    "#  'rf__n_estimators': [100, 200],\n",
    "#  'rf__max_depth': [None, 0.25],\n",
    "#  'rf__max_features': ['auto', 2000]}\n",
    "# Best accuracy score: 0.8912\n",
    "\n",
    "# Best estimator / parameters:\n",
    "\n",
    "# Pipeline(steps=[('cvec', CountVectorizer(max_df=0.75, max_features=5000)),\n",
    "#                 ('rf', RandomForestClassifier(n_estimators=200))])\n",
    "# {'cvec__max_df': 0.75,\n",
    "#  'cvec__max_features': 5000,\n",
    "#  'cvec__min_df': 1,\n",
    "#  'cvec__ngram_range': (1, 1),\n",
    "#  'rf__max_depth': None,\n",
    "#  'rf__max_features': 'auto',\n",
    "#  'rf__n_estimators': 200}\n",
    "# Accuracy score on train set:\n",
    "\n",
    "# 0.9974473516273133\n",
    "# Accuracy score on test set:\n",
    "\n",
    "# 0.8964401294498382"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2101, 5000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2101,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1036, 5000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1036,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Accuracy score on train set:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Accuracy score on test set:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8426640926640927"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Instantiate CountVectorizer\n",
    "cvec = CountVectorizer(max_df = 0.75, max_features = 5_000, min_df = 1, ngram_range = (1, 1), stop_words = 'english')\n",
    "\n",
    "# Fit the features training data so the model learns the vocabulary; transform to create vectors from the vocabulary\n",
    "X_train_cvec = pd.DataFrame(cvec.fit_transform(X_train).todense(),\n",
    "                           columns = cvec.get_feature_names())\n",
    "\n",
    "# Fit the features test data so the model learns the vocabulary; \n",
    "X_test_cvec = pd.DataFrame(cvec.transform(X_test).todense(),\n",
    "                           columns = cvec.get_feature_names())\n",
    "\n",
    "# Check the shapes \n",
    "\n",
    "display(X_train_cvec.shape)\n",
    "display(y_train.shape)\n",
    "display(X_test_cvec.shape)\n",
    "display(y_test.shape)\n",
    "\n",
    "rf_ex_pipe = RandomForestClassifier(n_estimators = 200)\n",
    "\n",
    "rf_ex_pipe.fit(X_train_cvec, y_train)\n",
    "\n",
    "printmd('**Accuracy score on train set:**')\n",
    "display(gs_cvec_rf.score(X_train, y_train))\n",
    "printmd('**Accuracy score on test set:**')\n",
    "display(gs_cvec_rf.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's look into the most important features and set up for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = X_train_cvec.columns\n",
    "importances = rf_ex_pipe.feature_importances_\n",
    "indices = np.argsort(importances)[-20:]\n",
    "\n",
    "plt.subplots(figsize = (6, 6))\n",
    "plt.barh(range(len(indices)), importances[indices], color = 'thistle')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices], size = 11);\n",
    "plt.title('Top 20 feature importances in r/ science and r/ futurology', size = 12)\n",
    "plt.ylabel('Feature', size = 11);\n",
    "\n",
    "# ref: https://www.analyticsvidhya.com/blog/2018/08/dimensionality-reduction-techniques-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# This SelectFromModel library is a meta-transformer for selecting features based on importance weights\n",
    "\n",
    "selected_from_model = SelectFromModel(estimator = RandomForestClassifier()).fit(X_train_cvec, y_train)\n",
    "\n",
    "# ref: https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFromModel.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaa</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abil</th>\n",
       "      <th>abl</th>\n",
       "      <th>abnorm</th>\n",
       "      <th>abort</th>\n",
       "      <th>abov</th>\n",
       "      <th>absolut</th>\n",
       "      <th>absorb</th>\n",
       "      <th>abstin</th>\n",
       "      <th>abund</th>\n",
       "      <th>abus</th>\n",
       "      <th>academ</th>\n",
       "      <th>academi</th>\n",
       "      <th>academia</th>\n",
       "      <th>acceler</th>\n",
       "      <th>accept</th>\n",
       "      <th>access</th>\n",
       "      <th>accid</th>\n",
       "      <th>accident</th>\n",
       "      <th>accommod</th>\n",
       "      <th>accomplish</th>\n",
       "      <th>accord</th>\n",
       "      <th>account</th>\n",
       "      <th>accur</th>\n",
       "      <th>accuraci</th>\n",
       "      <th>achiev</th>\n",
       "      <th>acid</th>\n",
       "      <th>acoust</th>\n",
       "      <th>acquir</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>activ</th>\n",
       "      <th>actor</th>\n",
       "      <th>actual</th>\n",
       "      <th>acut</th>\n",
       "      <th>ad</th>\n",
       "      <th>adapt</th>\n",
       "      <th>add</th>\n",
       "      <th>addict</th>\n",
       "      <th>addit</th>\n",
       "      <th>adequ</th>\n",
       "      <th>...</th>\n",
       "      <th>yang</th>\n",
       "      <th>yanghai</th>\n",
       "      <th>yard</th>\n",
       "      <th>yarn</th>\n",
       "      <th>ychromosom</th>\n",
       "      <th>ye</th>\n",
       "      <th>year</th>\n",
       "      <th>yearold</th>\n",
       "      <th>years</th>\n",
       "      <th>yellowtail</th>\n",
       "      <th>yemen</th>\n",
       "      <th>yen</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yield</th>\n",
       "      <th>yo</th>\n",
       "      <th>yoghurtlik</th>\n",
       "      <th>yokohama</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>youngster</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtub</th>\n",
       "      <th>yr</th>\n",
       "      <th>yunan</th>\n",
       "      <th>zdisc</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zebrafish</th>\n",
       "      <th>zeolit</th>\n",
       "      <th>zeptosecond</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeroemiss</th>\n",
       "      <th>zhengzhou</th>\n",
       "      <th>zika</th>\n",
       "      <th>zinc</th>\n",
       "      <th>ziplin</th>\n",
       "      <th>zircon</th>\n",
       "      <th>zn</th>\n",
       "      <th>zombi</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoonot</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3131</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3132</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3133</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3134</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3135</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2761 rows  5001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aaa  abandon  abil  abl  abnorm  abort  abov  absolut  absorb  abstin  \\\n",
       "0     0.0      0.0   0.0  0.0     0.0    0.0   0.0      0.0     0.0     0.0   \n",
       "1     0.0      0.0   0.0  0.0     0.0    0.0   0.0      0.0     0.0     0.0   \n",
       "2     0.0      0.0   0.0  0.0     0.0    0.0   0.0      0.0     0.0     0.0   \n",
       "3     0.0      0.0   0.0  0.0     0.0    0.0   0.0      0.0     0.0     0.0   \n",
       "4     0.0      0.0   0.0  0.0     0.0    0.0   0.0      0.0     0.0     0.0   \n",
       "...   ...      ...   ...  ...     ...    ...   ...      ...     ...     ...   \n",
       "3131  NaN      NaN   NaN  NaN     NaN    NaN   NaN      NaN     NaN     NaN   \n",
       "3132  NaN      NaN   NaN  NaN     NaN    NaN   NaN      NaN     NaN     NaN   \n",
       "3133  NaN      NaN   NaN  NaN     NaN    NaN   NaN      NaN     NaN     NaN   \n",
       "3134  NaN      NaN   NaN  NaN     NaN    NaN   NaN      NaN     NaN     NaN   \n",
       "3135  NaN      NaN   NaN  NaN     NaN    NaN   NaN      NaN     NaN     NaN   \n",
       "\n",
       "      abund  abus  academ  academi  academia  acceler  accept  access  accid  \\\n",
       "0       0.0   0.0     0.0      0.0       0.0      0.0     0.0     0.0    0.0   \n",
       "1       0.0   0.0     0.0      0.0       0.0      0.0     0.0     0.0    0.0   \n",
       "2       0.0   0.0     0.0      0.0       0.0      0.0     0.0     0.0    0.0   \n",
       "3       0.0   0.0     0.0      0.0       0.0      0.0     0.0     0.0    0.0   \n",
       "4       0.0   0.0     0.0      0.0       0.0      0.0     0.0     0.0    0.0   \n",
       "...     ...   ...     ...      ...       ...      ...     ...     ...    ...   \n",
       "3131    NaN   NaN     NaN      NaN       NaN      NaN     NaN     NaN    NaN   \n",
       "3132    NaN   NaN     NaN      NaN       NaN      NaN     NaN     NaN    NaN   \n",
       "3133    NaN   NaN     NaN      NaN       NaN      NaN     NaN     NaN    NaN   \n",
       "3134    NaN   NaN     NaN      NaN       NaN      NaN     NaN     NaN    NaN   \n",
       "3135    NaN   NaN     NaN      NaN       NaN      NaN     NaN     NaN    NaN   \n",
       "\n",
       "      accident  accommod  accomplish  accord  account  accur  accuraci  \\\n",
       "0          0.0       0.0         0.0     0.0      0.0    0.0       0.0   \n",
       "1          0.0       0.0         0.0     0.0      0.0    0.0       0.0   \n",
       "2          0.0       0.0         0.0     0.0      0.0    0.0       0.0   \n",
       "3          0.0       0.0         0.0     0.0      0.0    0.0       0.0   \n",
       "4          0.0       0.0         0.0     0.0      0.0    0.0       0.0   \n",
       "...        ...       ...         ...     ...      ...    ...       ...   \n",
       "3131       NaN       NaN         NaN     NaN      NaN    NaN       NaN   \n",
       "3132       NaN       NaN         NaN     NaN      NaN    NaN       NaN   \n",
       "3133       NaN       NaN         NaN     NaN      NaN    NaN       NaN   \n",
       "3134       NaN       NaN         NaN     NaN      NaN    NaN       NaN   \n",
       "3135       NaN       NaN         NaN     NaN      NaN    NaN       NaN   \n",
       "\n",
       "      achiev  acid  acoust  acquir  act  action  activ  actor  actual  acut  \\\n",
       "0        0.0   0.0     0.0     0.0  0.0     0.0    0.0    0.0     0.0   0.0   \n",
       "1        0.0   0.0     0.0     0.0  0.0     0.0    0.0    0.0     0.0   0.0   \n",
       "2        0.0   0.0     0.0     0.0  0.0     0.0    0.0    0.0     0.0   0.0   \n",
       "3        0.0   0.0     0.0     0.0  0.0     0.0    0.0    0.0     0.0   0.0   \n",
       "4        0.0   0.0     0.0     0.0  0.0     0.0    0.0    0.0     0.0   0.0   \n",
       "...      ...   ...     ...     ...  ...     ...    ...    ...     ...   ...   \n",
       "3131     NaN   NaN     NaN     NaN  NaN     NaN    NaN    NaN     NaN   NaN   \n",
       "3132     NaN   NaN     NaN     NaN  NaN     NaN    NaN    NaN     NaN   NaN   \n",
       "3133     NaN   NaN     NaN     NaN  NaN     NaN    NaN    NaN     NaN   NaN   \n",
       "3134     NaN   NaN     NaN     NaN  NaN     NaN    NaN    NaN     NaN   NaN   \n",
       "3135     NaN   NaN     NaN     NaN  NaN     NaN    NaN    NaN     NaN   NaN   \n",
       "\n",
       "       ad  adapt  add  addict  addit  adequ  ...  yang  yanghai  yard  yarn  \\\n",
       "0     0.0    0.0  0.0     0.0    0.0    0.0  ...   0.0      0.0   0.0   0.0   \n",
       "1     0.0    0.0  0.0     0.0    0.0    0.0  ...   0.0      0.0   0.0   0.0   \n",
       "2     0.0    0.0  0.0     0.0    0.0    0.0  ...   0.0      0.0   0.0   0.0   \n",
       "3     0.0    0.0  0.0     0.0    0.0    0.0  ...   0.0      0.0   0.0   0.0   \n",
       "4     0.0    0.0  0.0     0.0    0.0    0.0  ...   0.0      0.0   0.0   0.0   \n",
       "...   ...    ...  ...     ...    ...    ...  ...   ...      ...   ...   ...   \n",
       "3131  NaN    NaN  NaN     NaN    NaN    NaN  ...   NaN      NaN   NaN   NaN   \n",
       "3132  NaN    NaN  NaN     NaN    NaN    NaN  ...   NaN      NaN   NaN   NaN   \n",
       "3133  NaN    NaN  NaN     NaN    NaN    NaN  ...   NaN      NaN   NaN   NaN   \n",
       "3134  NaN    NaN  NaN     NaN    NaN    NaN  ...   NaN      NaN   NaN   NaN   \n",
       "3135  NaN    NaN  NaN     NaN    NaN    NaN  ...   NaN      NaN   NaN   NaN   \n",
       "\n",
       "      ychromosom   ye  year  yearold  years  yellowtail  yemen  yen  \\\n",
       "0            0.0  0.0   0.0      0.0    0.0         0.0    0.0  0.0   \n",
       "1            0.0  0.0   0.0      0.0    0.0         0.0    0.0  0.0   \n",
       "2            0.0  0.0   0.0      0.0    0.0         0.0    0.0  0.0   \n",
       "3            0.0  0.0   0.0      0.0    0.0         0.0    0.0  0.0   \n",
       "4            0.0  0.0   0.0      0.0    0.0         0.0    0.0  0.0   \n",
       "...          ...  ...   ...      ...    ...         ...    ...  ...   \n",
       "3131         NaN  NaN   NaN      NaN    NaN         NaN    NaN  NaN   \n",
       "3132         NaN  NaN   NaN      NaN    NaN         NaN    NaN  NaN   \n",
       "3133         NaN  NaN   NaN      NaN    NaN         NaN    NaN  NaN   \n",
       "3134         NaN  NaN   NaN      NaN    NaN         NaN    NaN  NaN   \n",
       "3135         NaN  NaN   NaN      NaN    NaN         NaN    NaN  NaN   \n",
       "\n",
       "      yesterday  yield   yo  yoghurtlik  yokohama  york  young  younger  \\\n",
       "0           0.0    0.0  0.0         0.0       0.0   0.0    0.0      0.0   \n",
       "1           0.0    0.0  0.0         0.0       0.0   0.0    0.0      0.0   \n",
       "2           0.0    0.0  0.0         0.0       0.0   0.0    0.0      0.0   \n",
       "3           0.0    0.0  0.0         0.0       0.0   0.0    0.0      0.0   \n",
       "4           0.0    0.0  0.0         0.0       0.0   0.0    0.0      0.0   \n",
       "...         ...    ...  ...         ...       ...   ...    ...      ...   \n",
       "3131        NaN    NaN  NaN         NaN       NaN   NaN    NaN      NaN   \n",
       "3132        NaN    NaN  NaN         NaN       NaN   NaN    NaN      NaN   \n",
       "3133        NaN    NaN  NaN         NaN       NaN   NaN    NaN      NaN   \n",
       "3134        NaN    NaN  NaN         NaN       NaN   NaN    NaN      NaN   \n",
       "3135        NaN    NaN  NaN         NaN       NaN   NaN    NaN      NaN   \n",
       "\n",
       "      youngster  youth  youtub   yr  yunan  zdisc  zealand  zebrafish  zeolit  \\\n",
       "0           0.0    0.0     0.0  0.0    0.0    0.0      0.0        0.0     0.0   \n",
       "1           0.0    0.0     0.0  0.0    0.0    0.0      0.0        0.0     0.0   \n",
       "2           0.0    0.0     0.0  0.0    0.0    0.0      0.0        0.0     0.0   \n",
       "3           0.0    0.0     0.0  0.0    0.0    0.0      0.0        0.0     0.0   \n",
       "4           0.0    0.0     0.0  0.0    0.0    0.0      0.0        0.0     0.0   \n",
       "...         ...    ...     ...  ...    ...    ...      ...        ...     ...   \n",
       "3131        NaN    NaN     NaN  NaN    NaN    NaN      NaN        NaN     NaN   \n",
       "3132        NaN    NaN     NaN  NaN    NaN    NaN      NaN        NaN     NaN   \n",
       "3133        NaN    NaN     NaN  NaN    NaN    NaN      NaN        NaN     NaN   \n",
       "3134        NaN    NaN     NaN  NaN    NaN    NaN      NaN        NaN     NaN   \n",
       "3135        NaN    NaN     NaN  NaN    NaN    NaN      NaN        NaN     NaN   \n",
       "\n",
       "      zeptosecond  zero  zeroemiss  zhengzhou  zika  zinc  ziplin  zircon  \\\n",
       "0             0.0   0.0        0.0        0.0   0.0   0.0     0.0     0.0   \n",
       "1             0.0   0.0        0.0        0.0   0.0   0.0     0.0     0.0   \n",
       "2             0.0   0.0        0.0        0.0   0.0   0.0     0.0     0.0   \n",
       "3             0.0   0.0        0.0        0.0   0.0   0.0     0.0     0.0   \n",
       "4             0.0   0.0        0.0        0.0   0.0   0.0     0.0     0.0   \n",
       "...           ...   ...        ...        ...   ...   ...     ...     ...   \n",
       "3131          NaN   NaN        NaN        NaN   NaN   NaN     NaN     NaN   \n",
       "3132          NaN   NaN        NaN        NaN   NaN   NaN     NaN     NaN   \n",
       "3133          NaN   NaN        NaN        NaN   NaN   NaN     NaN     NaN   \n",
       "3134          NaN   NaN        NaN        NaN   NaN   NaN     NaN     NaN   \n",
       "3135          NaN   NaN        NaN        NaN   NaN   NaN     NaN     NaN   \n",
       "\n",
       "       zn  zombi  zone  zoonot  subreddit  \n",
       "0     0.0    0.0   0.0     0.0        0.0  \n",
       "1     0.0    0.0   0.0     0.0        NaN  \n",
       "2     0.0    0.0   0.0     0.0        0.0  \n",
       "3     0.0    0.0   0.0     0.0        0.0  \n",
       "4     0.0    0.0   0.0     0.0        NaN  \n",
       "...   ...    ...   ...     ...        ...  \n",
       "3131  NaN    NaN   NaN     NaN        1.0  \n",
       "3132  NaN    NaN   NaN     NaN        1.0  \n",
       "3133  NaN    NaN   NaN     NaN        1.0  \n",
       "3134  NaN    NaN   NaN     NaN        1.0  \n",
       "3135  NaN    NaN   NaN     NaN        1.0  \n",
       "\n",
       "[2761 rows x 5001 columns]"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([X_train_cvec, y_train], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**The strongest coefficients start from the top in the table below.**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Holding all else constant, the effect of the stemmed word `studi` is a 0.046 increase in classification ability.**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coeff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>studi</th>\n",
       "      <td>0.050425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suggest</th>\n",
       "      <td>0.015479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>covid</th>\n",
       "      <td>0.013561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>research</th>\n",
       "      <td>0.012980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>increas</th>\n",
       "      <td>0.009638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new</th>\n",
       "      <td>0.009087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ai</th>\n",
       "      <td>0.008677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>power</th>\n",
       "      <td>0.008580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dure</th>\n",
       "      <td>0.007330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robot</th>\n",
       "      <td>0.006877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sarscov</th>\n",
       "      <td>0.006749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>effect</th>\n",
       "      <td>0.006039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>women</th>\n",
       "      <td>0.005735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>world</th>\n",
       "      <td>0.005674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peopl</th>\n",
       "      <td>0.005657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>futur</th>\n",
       "      <td>0.005067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>men</th>\n",
       "      <td>0.004976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reduc</th>\n",
       "      <td>0.004787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>0.004697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elon</th>\n",
       "      <td>0.004475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Coeff\n",
       "studi     0.050425\n",
       "suggest   0.015479\n",
       "covid     0.013561\n",
       "research  0.012980\n",
       "increas   0.009638\n",
       "new       0.009087\n",
       "ai        0.008677\n",
       "power     0.008580\n",
       "dure      0.007330\n",
       "robot     0.006877\n",
       "sarscov   0.006749\n",
       "effect    0.006039\n",
       "women     0.005735\n",
       "world     0.005674\n",
       "peopl     0.005657\n",
       "futur     0.005067\n",
       "men       0.004976\n",
       "reduc     0.004787\n",
       "like      0.004697\n",
       "elon      0.004475"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's look at the strongest coefficients by feature\n",
    "\n",
    "printmd('**The strongest coefficients start from the top in the table below.**')\n",
    "printmd('**Holding all else constant, the effect of the stemmed word `studi` is a 0.046 increase in classification ability.**')\n",
    "\n",
    "feature_importances_df = (pd.DataFrame(selected_from_model.estimator_.feature_importances_,\n",
    "                                      index = X_train_cvec.columns, columns = ['Coeff'])\n",
    "                                      .sort_values('Coeff', ascending = False))\n",
    "display(feature_importances_df[:20])\n",
    "\n",
    "# Export to combine with other top 100 features that I'm able to pull from other models\n",
    "feature_importances_df[:100].to_csv('../data/feature_selection/feature_selection_randomforest.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x17b03b05280>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "credit: NLP II: `CountVectorizer`, `TfidfVectorizer`, and Modeling lesson. _Authors: Dave Yerrington (SF), Justin Pounders (ATL), Riley Dallas (ATX), Matt Brems (DC), Noelle Brown (DEN)_"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get predictions\n",
    "preds = rf_ex_pipe.predict(X_test_cvec)\n",
    "\n",
    "# Save confusion matrix values\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n",
    "\n",
    "# View confusion matrix\n",
    "\n",
    "display(plot_confusion_matrix(rf_ex_pipe, X_test_cvec, y_test, cmap='cubehelix', values_format='d'));\n",
    "plt.title('Confusion matrix')\n",
    "\n",
    "printmd('credit: NLP II: `CountVectorizer`, `TfidfVectorizer`, and Modeling lesson. _Authors: Dave Yerrington (SF), Justin Pounders (ATL), Riley Dallas (ATX), Matt Brems (DC), Noelle Brown (DEN)_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8166023166023166\n",
      "Misclassification: 0.1833976833976834\n",
      "Sensitivity: 0.8158914728682171\n",
      "Precision: 0.8158914728682171\n",
      "Specificity: 0.8173076923076923\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy\n",
    "\n",
    "acc = (tp + tn) / (tp + fp + tn + fn)\n",
    "print('Accuracy:', acc)\n",
    "\n",
    "# Calculate the misclassification rate\n",
    "\n",
    "misclass = (fp + fn) / (tp + fp + tn + fn)\n",
    "print('Misclassification:', misclass)\n",
    "\n",
    "# Calculate the sensitivity\n",
    "\n",
    "sens = tp / (tp + fn)\n",
    "print('Sensitivity:', sens)\n",
    "\n",
    "# Calculate the precision\n",
    "\n",
    "prec = tp / (tp + fp)\n",
    "print('Precision:', prec)\n",
    "\n",
    "# Calculate the specificity\n",
    "\n",
    "spec = tn / (tn + fp)\n",
    "print('Specificity:', spec)\n",
    "\n",
    "# credit: Heather Robinson at General Assembly  :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set a pipeline up with two stages:\n",
    "# 1. CountVectorizer (transformer)\n",
    "# 2. Random Forest (estimator)\n",
    "\n",
    "pipe_cvec_rf = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('rf', RandomForestClassifier()) \n",
    "])\n",
    "\n",
    "\n",
    "# Search over the following values of hyperparameters:\n",
    "# Maximum number of features fit\n",
    "# Minimum number of documents needed to include token\n",
    "# Maximum number of documents needed to include token\n",
    "# Check (individual tokens) and also check (individual tokens and 2-grams).\n",
    "\n",
    "pipe_cvec_rf_params = {\n",
    "    'cvec__max_features': [5_000],\n",
    "    'cvec__min_df': [1],\n",
    "    'cvec__max_df': [.75],\n",
    "    'cvec__ngram_range': [(1,1)],\n",
    "    'rf__n_estimators': [100, 200], \n",
    "    'rf__max_depth': [None, .25],\n",
    "    'rf__max_features': ['auto', 2_000]\n",
    "}\n",
    "\n",
    "# Instantiate GridSearchCV.\n",
    "\n",
    "gs_cvec_rf = GridSearchCV(pipe_cvec_rf,             # the object we are optimizing\n",
    "                  param_grid = pipe_cvec_rf_params, # the parameters values we are searching\n",
    "                  cv = 5)                           # Number of folds in cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('rf', RandomForestClassifier())]),\n",
       "             param_grid={'cvec__max_df': [0.75], 'cvec__max_features': [5000],\n",
       "                         'cvec__min_df': [1], 'cvec__ngram_range': [(1, 1)],\n",
       "                         'rf__max_depth': [None, 0.25],\n",
       "                         'rf__max_features': ['auto', 2000],\n",
       "                         'rf__n_estimators': [100, 200]})"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit GridSearch to data.\n",
    "gs_cvec_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline 5\n",
    "\n",
    "\n",
    "\n",
    "**CountVectorizer (transformer)**:\n",
    "\n",
    "\n",
    "\n",
    "**Support Vector Machine (estimator)**:\n",
    "\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set a pipeline up with two stages:\n",
    "# 1. CountVectorizer (transformer)\n",
    "# 2. Random Forest (estimator)\n",
    "\n",
    "pipe_cvec_rf = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('rf', RandomForestClassifier()) \n",
    "])\n",
    "\n",
    "\n",
    "# Search over the following values of hyperparameters:\n",
    "# Maximum number of features fit\n",
    "# Minimum number of documents needed to include token\n",
    "# Maximum number of documents needed to include token\n",
    "# Check (individual tokens) and also check (individual tokens and 2-grams).\n",
    "\n",
    "pipe_cvec_rf_params = {\n",
    "    'cvec__max_features': [5_000],\n",
    "    'cvec__min_df': [1],\n",
    "    'cvec__max_df': [.75],\n",
    "    'cvec__ngram_range': [(1,1)],\n",
    "    'rf__n_estimators': [100, 200], \n",
    "    'rf__max_depth': [None, .25],\n",
    "    'rf__max_features': ['auto', 2_000]\n",
    "}\n",
    "\n",
    "# Instantiate GridSearchCV.\n",
    "\n",
    "gs_cvec_rf = GridSearchCV(pipe_cvec_rf,             # the object we are optimizing\n",
    "                  param_grid = pipe_cvec_rf_params, # the parameters values we are searching\n",
    "                  cv = 5)                           # Number of folds in cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('rf', RandomForestClassifier())]),\n",
       "             param_grid={'cvec__max_df': [0.75], 'cvec__max_features': [5000],\n",
       "                         'cvec__min_df': [1], 'cvec__ngram_range': [(1, 1)],\n",
       "                         'rf__max_depth': [None, 0.25],\n",
       "                         'rf__max_features': ['auto', 2000],\n",
       "                         'rf__n_estimators': [100, 200]})"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit GridSearch to data.\n",
    "gs_cvec_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Break the pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2101, 6000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2101,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1036, 6000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1036,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Instantiate CountVectorizer\n",
    "cvec = CountVectorizer(max_df = 0.4, max_features = 6_000, min_df = 1, ngram_range = (1, 2), stop_words = 'english')\n",
    "\n",
    "# Fit the features training data so the model learns the vocabulary; transform to create vectors from the vocabulary\n",
    "X_train_cvec = pd.DataFrame(cvec.fit_transform(X_train).todense(),\n",
    "                           columns = cvec.get_feature_names())\n",
    "\n",
    "# Fit the features test data so the model learns the vocabulary; \n",
    "X_test_cvec = pd.DataFrame(cvec.transform(X_test).todense(),\n",
    "                           columns = cvec.get_feature_names())\n",
    "\n",
    "# Check the shapes \n",
    "\n",
    "display(X_train_cvec.shape)\n",
    "display(y_train.shape)\n",
    "display(X_test_cvec.shape)\n",
    "display(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2101, 6000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2101,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1036, 6000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1036,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Instantiate the TfidfVectorizer transformer\n",
    "tvec = TfidfVectorizer(max_features = 6_000, stop_words = 'english', ngram_range = (1, 2)) \n",
    "\n",
    "# Fit the features training data so the model learns the vocabulary; transform to create vectors from the vocabulary\n",
    "X_train_tvec = pd.DataFrame(tvec.fit_transform(X_train).todense(),\n",
    "                           columns = tvec.get_feature_names())\n",
    "\n",
    "# Fit the features test data so the model learns the vocabulary; \n",
    "X_test_tvec = pd.DataFrame(tvec.transform(X_test).todense(),\n",
    "                           columns = tvec.get_feature_names())\n",
    "\n",
    "# Check the shapes \n",
    "\n",
    "display(X_train_tvec.shape)\n",
    "display(y_train.shape)\n",
    "display(X_test_tvec.shape)\n",
    "display(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 431,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Accuracy score on train data: 0.996**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Accuracy score on test data: 0.835**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**The model is overfit**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Fit the model to train data\n",
    "logreg.fit(X_train_cvec, y_train)\n",
    "\n",
    "# Get accuracy scores for train and test data\n",
    "printmd(f'**Accuracy score on train data: {logreg.score(X_train_cvec, y_train):.3f}**')\n",
    "printmd(f'**Accuracy score on test data: {logreg.score(X_test_cvec, y_test):.3f}**')\n",
    "printmd('**The model is overfit**')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 441,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x17b0363c040>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "credit: NLP II: `CountVectorizer`, `TfidfVectorizer`, and Modeling lesson. _Authors: Dave Yerrington (SF), Justin Pounders (ATL), Riley Dallas (ATX), Matt Brems (DC), Noelle Brown (DEN)_"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get predictions\n",
    "preds = logreg.predict(X_test_cvec)\n",
    "\n",
    "# Save confusion matrix values\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n",
    "\n",
    "# View confusion matrix\n",
    "\n",
    "display(plot_confusion_matrix(logreg, X_test_cvec, y_test, cmap='cubehelix', values_format='d'))\n",
    "plt.title('Confusion matrix');\n",
    "\n",
    "printmd('credit: NLP II: `CountVectorizer`, `TfidfVectorizer`, and Modeling lesson. _Authors: Dave Yerrington (SF), Justin Pounders (ATL), Riley Dallas (ATX), Matt Brems (DC), Noelle Brown (DEN)_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**This model is misclassifying `science` posts as `futurology`. Let's see how the next model improves on this.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.834942084942085\n",
      "Misclassification: 0.16505791505791506\n",
      "Sensitivity: 0.8275193798449613\n",
      "Precision: 0.8388998035363457\n",
      "Specificity: 0.8423076923076923\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy\n",
    "\n",
    "acc = (tp + tn) / (tp + fp + tn + fn)\n",
    "print('Accuracy:', acc)\n",
    "\n",
    "# Calculate the misclassification rate\n",
    "\n",
    "misclass = (fp + fn) / (tp + fp + tn + fn)\n",
    "print('Misclassification:', misclass)\n",
    "\n",
    "# Calculate the sensitivity\n",
    "\n",
    "sens = tp / (tp + fn)\n",
    "print('Sensitivity:', sens)\n",
    "\n",
    "# Calculate the precision\n",
    "\n",
    "prec = tp / (tp + fp)\n",
    "print('Precision:', prec)\n",
    "\n",
    "# Calculate the specificity\n",
    "\n",
    "spec = tn / (tn + fp)\n",
    "print('Specificity:', spec)\n",
    "\n",
    "# credit: Heather Robinson at General Assembly  :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 1], 'penalty': ['l1', 'l2']})"
      ]
     },
     "execution_count": 399,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set new parameters\n",
    "params = { 'C': [.001, .01, .1, 1], \n",
    "              'penalty': ['l1', 'l2']}\n",
    "\n",
    "# Instantiate GridSearch cross-validation\n",
    "gs = GridSearchCV(logreg, params, cv = 5)\n",
    "\n",
    "gs.fit(X_train_cvec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Accuracy score on train data: 0.996**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Accuracy score on test data: 0.835**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**The model is still overfit**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Best parameters:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'penalty': 'l2'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get accuracy scores for train and test data\n",
    "printmd(f'**Accuracy score on train data: {gs.score(X_train_cvec, y_train):.3f}**')\n",
    "printmd(f'**Accuracy score on test data: {gs.score(X_test_cvec, y_test):.3f}**')\n",
    "printmd('**The model is still overfit**')\n",
    "\n",
    "printmd('**Best parameters:**')\n",
    "display(gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Accuracy score on train data: 0.996**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Accuracy score on test data: 0.837**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**The model is still overfit**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Best parameters:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "params = {'solver': ['liblinear', 'sag'],\n",
    "               'C': [1], \n",
    "               'penalty': ['l2']\n",
    "              }\n",
    "\n",
    "gs = GridSearchCV(log_reg, params, cv=5)\n",
    "\n",
    "gs.fit(X_train_cvec, y_train)\n",
    "\n",
    "scores = gs.cv_results_['mean_test_score']\n",
    "   \n",
    "# ref: https://towardsdatascience.com/dont-sweat-the-solver-stuff-aea7cddc3451    \n",
    "\n",
    "# Get accuracy scores for train and test data\n",
    "printmd(f'**Accuracy score on train data: {gs.score(X_train_cvec, y_train):.3f}**')\n",
    "printmd(f'**Accuracy score on test data: {gs.score(X_test_cvec, y_test):.3f}**')\n",
    "printmd('**The model is still overfit**')\n",
    "\n",
    "printmd('**Best parameters:**')\n",
    "display(gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Metrics for Logistic Regression model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 419,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, random_state=42, solver='liblinear')"
      ]
     },
     "execution_count": 419,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression(C = 1, penalty = 'l2', solver = 'liblinear', random_state=42)\n",
    "\n",
    "log_reg.fit(X_train_cvec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Accuracy score on train data: 0.996**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Accuracy score on test data: 0.837**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**The model is still overfit**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get accuracy scores for train and test data\n",
    "printmd(f'**Accuracy score on train data: {log_reg.score(X_train_cvec, y_train):.3f}**')\n",
    "printmd(f'**Accuracy score on test data: {log_reg.score(X_test_cvec, y_test):.3f}**')\n",
    "printmd('**The model is still overfit**')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 442,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x17b0936f5b0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "credit: NLP II: `CountVectorizer`, `TfidfVectorizer`, and Modeling lesson. _Authors: Dave Yerrington (SF), Justin Pounders (ATL), Riley Dallas (ATX), Matt Brems (DC), Noelle Brown (DEN)_"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get predictions\n",
    "preds = log_reg.predict(X_test_cvec)\n",
    "\n",
    "# Save confusion matrix values\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n",
    "\n",
    "# View confusion matrix\n",
    "\n",
    "display(plot_confusion_matrix(log_reg, X_test_cvec, y_test, cmap='cubehelix', values_format='d'))\n",
    "plt.title('Logistic Regression: Confusion matrix');\n",
    "\n",
    "printmd('credit: NLP II: `CountVectorizer`, `TfidfVectorizer`, and Modeling lesson. _Authors: Dave Yerrington (SF), Justin Pounders (ATL), Riley Dallas (ATX), Matt Brems (DC), Noelle Brown (DEN)_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This model improved on the misclassifying of `science` posts as `futurology` by ***only two posts!*** (`0` predicted / `1` true went from 89 to 87).\n",
    "\n",
    "**Let's see a different model improves on this.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8368725868725869\n",
      "Misclassification: 0.16312741312741313\n",
      "Sensitivity: 0.8313953488372093\n",
      "Precision: 0.8395303326810176\n",
      "Specificity: 0.8423076923076923\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy\n",
    "\n",
    "acc = (tp + tn) / (tp + fp + tn + fn)\n",
    "print('Accuracy:', acc)\n",
    "\n",
    "# Calculate the misclassification rate\n",
    "\n",
    "misclass = (fp + fn) / (tp + fp + tn + fn)\n",
    "print('Misclassification:', misclass)\n",
    "\n",
    "# Calculate the sensitivity\n",
    "\n",
    "sens = tp / (tp + fn)\n",
    "print('Sensitivity:', sens)\n",
    "\n",
    "# Calculate the precision\n",
    "\n",
    "prec = tp / (tp + fp)\n",
    "print('Precision:', prec)\n",
    "\n",
    "# Calculate the specificity\n",
    "\n",
    "spec = tn / (tn + fp)\n",
    "print('Specificity:', spec)\n",
    "\n",
    "# credit: Heather Robinson at General Assembly  :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.71636754]),\n",
       " array([[-0.04387016,  0.51009503,  0.02224827, ...,  0.10128341,\n",
       "         -0.18698559,  0.09486828]]))"
      ]
     },
     "execution_count": 420,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.intercept_, log_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**The strongest coefficients start from the top in the table below.**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "***Holding all else constant, the effect of `studi` is a 1.9 times increase in predictive accuracy.***"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coeff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>studi</th>\n",
       "      <td>1.883410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>covid</th>\n",
       "      <td>1.627200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suggest</th>\n",
       "      <td>1.421749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dure</th>\n",
       "      <td>1.328131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sarscov</th>\n",
       "      <td>1.250659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analysi</th>\n",
       "      <td>1.178087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bird</th>\n",
       "      <td>1.163955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new research</th>\n",
       "      <td>1.125783</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>increas</th>\n",
       "      <td>1.089082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>associ</th>\n",
       "      <td>1.052911</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>effect</th>\n",
       "      <td>1.050273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>individu</th>\n",
       "      <td>0.969160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>men</th>\n",
       "      <td>0.941513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dog</th>\n",
       "      <td>0.910346</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ice</th>\n",
       "      <td>0.905442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>link</th>\n",
       "      <td>0.899291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>speci</th>\n",
       "      <td>0.894398</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>review</th>\n",
       "      <td>0.885455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>physic</th>\n",
       "      <td>0.873121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>implic</th>\n",
       "      <td>0.860588</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Coeff\n",
       "studi         1.883410\n",
       "covid         1.627200\n",
       "suggest       1.421749\n",
       "dure          1.328131\n",
       "sarscov       1.250659\n",
       "analysi       1.178087\n",
       "bird          1.163955\n",
       "new research  1.125783\n",
       "increas       1.089082\n",
       "associ        1.052911\n",
       "effect        1.050273\n",
       "individu      0.969160\n",
       "men           0.941513\n",
       "dog           0.910346\n",
       "ice           0.905442\n",
       "link          0.899291\n",
       "speci         0.894398\n",
       "review        0.885455\n",
       "physic        0.873121\n",
       "implic        0.860588"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printmd('**The strongest coefficients start from the top in the table below.**')\n",
    "printmd(f'***Holding all else constant, the effect of `studi` is a {log_reg_coef.T.iloc[0, 0]:.1f} times increase in predictive accuracy.***')\n",
    "\n",
    "log_reg_coef = pd.DataFrame(log_reg.coef_.T, index = X_train_tvec.columns, columns = ['Coeff']).sort_values('Coeff', ascending = False)\n",
    "display(log_reg_coef[:20])\n",
    "\n",
    "# Export to combine with other top 100 features that I'm able to pull from other models\n",
    "log_reg_coef[:100].to_csv('../data/feature_selection/feature_selection_logreg.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression model scoreboard\n",
    "\n",
    "| Model # | Accuracy (test) | Accuracy on train data | Specificity (test) |      Estimator      | Estimator hyperparameters |   Transformer   | Transformer hyperparameters (best) |\n",
    "|:-------:|:---------------:|:----------------------:|:------------------:|:-------------------:|:-------------------------:|:---------------:|:----------------------------------:|\n",
    "|    1    |      83.5%      |          99.6%         |        82.7%       | Logistic Regression |          Default          | CountVectorizer |            max_df = 0.4            |\n",
    "|    1    |                 |                        |                    |                     |                           |                 |        max_features = 6_000        |\n",
    "|    1    |                 |                        |                    |                     |                           |                 |             min_df = 1             |\n",
    "|    1    |                 |                        |                    |                     |                           |                 |        ngram_range = (1, 2)        |\n",
    "|    1    |                 |                        |                    |                     |                           |                 |       stop_words = 'english'       |\n",
    "|    2    |      83.5%      |          99.6%         |        82.7%       | Logistic Regression |       penalty = 'l2'      | CountVectorizer |           Same as model 1          |\n",
    "|    2    |                 |                        |                    |                     |           C = 1           |                 |                                    |\n",
    "|    3    |      83.7%      |          99.6%         |        83.1%       | Logistic Regression |       penalty = 'l2'      | CountVectorizer |           Same as model 1          |\n",
    "|    3    |                 |                        |                    |                     |           C = 1           |                 |                                    |\n",
    "|    3    |                 |                        |                    |                     |   'solver': 'liblinear'   |                 |                                    |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7844278316930147\n",
      "{'max_depth': 100, 'max_features': 'auto', 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "params_rf = {\n",
    "    'n_estimators': [25, 100],\n",
    "    'max_depth': [None, 100],\n",
    "    'max_features': ['auto', 500]\n",
    "        }\n",
    "\n",
    "\n",
    "gs_rf = GridSearchCV(rf, param_grid = params_rf)\n",
    "gs_rf.fit(X_train_cvec, y_train)\n",
    "\n",
    "print(gs_rf.best_score_)  # cross val score\n",
    "print(gs_rf.best_params_)  # cross val score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Grid searched:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': [100], 'max_depth': [100, 150], 'max_features': ['auto', 0.5]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Best accuracy score**: 0.7911"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Best estimator / parameters:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=150)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 150, 'max_features': 'auto', 'n_estimators': 100}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Accuracy score on train data: 0.486**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Accuracy score on test data: 0.487**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**The model is still overfit**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "params_rf_2 = {\n",
    "    'n_estimators': [100],\n",
    "    'max_depth': [100, 150],\n",
    "    'max_features': ['auto', .5]\n",
    "        }\n",
    "\n",
    "\n",
    "gs_rf_2 = GridSearchCV(rf, param_grid = params_rf_2)\n",
    "gs_rf_2.fit(X_train_cvec, y_train)\n",
    "\n",
    "printmd('**Grid searched:**')\n",
    "display(gs_rf_2.param_grid)\n",
    "printmd(f'**Best accuracy score**: {round(gs_rf_2.best_score_, 4)}')\n",
    "printmd('**Best estimator / parameters:**')\n",
    "display(gs_rf_2.best_estimator_)\n",
    "display(gs_rf_2.best_params_)\n",
    "\n",
    "# Get accuracy scores for train and test data\n",
    "printmd(f'**Accuracy score on train data: {gs_rf_2.score(X_train_tvec, y_train):.3f}**')\n",
    "printmd(f'**Accuracy score on test data: {gs_rf_2.score(X_test_tvec, y_test):.3f}**')\n",
    "printmd('**The model is still overfit**')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling with selected features\n",
    "\n",
    "#### The methodology is to manually select features using the Random Forest and Logistic Regression models' \"best-of\" lists -- aka, the features with the highest weights / coefficients (respectively). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 137)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>studi</th>\n",
       "      <th>covid</th>\n",
       "      <th>suggest</th>\n",
       "      <th>new studi</th>\n",
       "      <th>research</th>\n",
       "      <th>effect</th>\n",
       "      <th>dure</th>\n",
       "      <th>peopl</th>\n",
       "      <th>sarscov</th>\n",
       "      <th>men</th>\n",
       "      <th>new research</th>\n",
       "      <th>women</th>\n",
       "      <th>children</th>\n",
       "      <th>reduc</th>\n",
       "      <th>like</th>\n",
       "      <th>associ</th>\n",
       "      <th>brain</th>\n",
       "      <th>analysi</th>\n",
       "      <th>adult</th>\n",
       "      <th>infect</th>\n",
       "      <th>rate</th>\n",
       "      <th>evid</th>\n",
       "      <th>death</th>\n",
       "      <th>individu</th>\n",
       "      <th>activ</th>\n",
       "      <th>bird</th>\n",
       "      <th>link</th>\n",
       "      <th>speci</th>\n",
       "      <th>black</th>\n",
       "      <th>behavior</th>\n",
       "      <th>physic</th>\n",
       "      <th>suggest new</th>\n",
       "      <th>wa</th>\n",
       "      <th>use</th>\n",
       "      <th>new</th>\n",
       "      <th>patient</th>\n",
       "      <th>perform</th>\n",
       "      <th>parent</th>\n",
       "      <th>exposur</th>\n",
       "      <th>past</th>\n",
       "      <th>appear</th>\n",
       "      <th>lead</th>\n",
       "      <th>...</th>\n",
       "      <th>ai</th>\n",
       "      <th>power</th>\n",
       "      <th>robot</th>\n",
       "      <th>world</th>\n",
       "      <th>futur</th>\n",
       "      <th>elon</th>\n",
       "      <th>compani</th>\n",
       "      <th>electr</th>\n",
       "      <th>energi</th>\n",
       "      <th>scientist</th>\n",
       "      <th>say</th>\n",
       "      <th>musk</th>\n",
       "      <th>wind</th>\n",
       "      <th>renew</th>\n",
       "      <th>car</th>\n",
       "      <th>climat</th>\n",
       "      <th>space</th>\n",
       "      <th>solar</th>\n",
       "      <th>coal</th>\n",
       "      <th>plan</th>\n",
       "      <th>technolog</th>\n",
       "      <th>fuel</th>\n",
       "      <th>tesla</th>\n",
       "      <th>treatment</th>\n",
       "      <th>project</th>\n",
       "      <th>economi</th>\n",
       "      <th>tech</th>\n",
       "      <th>develop</th>\n",
       "      <th>measur</th>\n",
       "      <th>hydrogen</th>\n",
       "      <th>artifici</th>\n",
       "      <th>time</th>\n",
       "      <th>job</th>\n",
       "      <th>year</th>\n",
       "      <th>human</th>\n",
       "      <th>ha</th>\n",
       "      <th>internet</th>\n",
       "      <th>reveal</th>\n",
       "      <th>water</th>\n",
       "      <th>batteri</th>\n",
       "      <th>chang</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>41</td>\n",
       "      <td>21</td>\n",
       "      <td>12</td>\n",
       "      <td>14</td>\n",
       "      <td>82</td>\n",
       "      <td>16</td>\n",
       "      <td>11</td>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>21</td>\n",
       "      <td>55</td>\n",
       "      <td>6</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>130</td>\n",
       "      <td>211</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>21</td>\n",
       "      <td>...</td>\n",
       "      <td>88</td>\n",
       "      <td>124</td>\n",
       "      <td>82</td>\n",
       "      <td>136</td>\n",
       "      <td>111</td>\n",
       "      <td>58</td>\n",
       "      <td>72</td>\n",
       "      <td>83</td>\n",
       "      <td>126</td>\n",
       "      <td>77</td>\n",
       "      <td>92</td>\n",
       "      <td>60</td>\n",
       "      <td>54</td>\n",
       "      <td>71</td>\n",
       "      <td>63</td>\n",
       "      <td>120</td>\n",
       "      <td>46</td>\n",
       "      <td>122</td>\n",
       "      <td>56</td>\n",
       "      <td>66</td>\n",
       "      <td>64</td>\n",
       "      <td>66</td>\n",
       "      <td>46</td>\n",
       "      <td>10</td>\n",
       "      <td>48</td>\n",
       "      <td>26</td>\n",
       "      <td>31</td>\n",
       "      <td>48</td>\n",
       "      <td>11</td>\n",
       "      <td>50</td>\n",
       "      <td>36</td>\n",
       "      <td>89</td>\n",
       "      <td>45</td>\n",
       "      <td>116</td>\n",
       "      <td>98</td>\n",
       "      <td>128</td>\n",
       "      <td>30</td>\n",
       "      <td>15</td>\n",
       "      <td>57</td>\n",
       "      <td>33</td>\n",
       "      <td>100</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>499</td>\n",
       "      <td>173</td>\n",
       "      <td>184</td>\n",
       "      <td>231</td>\n",
       "      <td>263</td>\n",
       "      <td>103</td>\n",
       "      <td>76</td>\n",
       "      <td>199</td>\n",
       "      <td>60</td>\n",
       "      <td>77</td>\n",
       "      <td>72</td>\n",
       "      <td>88</td>\n",
       "      <td>99</td>\n",
       "      <td>94</td>\n",
       "      <td>152</td>\n",
       "      <td>68</td>\n",
       "      <td>93</td>\n",
       "      <td>31</td>\n",
       "      <td>72</td>\n",
       "      <td>70</td>\n",
       "      <td>58</td>\n",
       "      <td>43</td>\n",
       "      <td>45</td>\n",
       "      <td>35</td>\n",
       "      <td>47</td>\n",
       "      <td>18</td>\n",
       "      <td>49</td>\n",
       "      <td>35</td>\n",
       "      <td>43</td>\n",
       "      <td>40</td>\n",
       "      <td>30</td>\n",
       "      <td>74</td>\n",
       "      <td>98</td>\n",
       "      <td>204</td>\n",
       "      <td>487</td>\n",
       "      <td>70</td>\n",
       "      <td>33</td>\n",
       "      <td>37</td>\n",
       "      <td>23</td>\n",
       "      <td>23</td>\n",
       "      <td>31</td>\n",
       "      <td>51</td>\n",
       "      <td>...</td>\n",
       "      <td>6</td>\n",
       "      <td>20</td>\n",
       "      <td>7</td>\n",
       "      <td>36</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>18</td>\n",
       "      <td>32</td>\n",
       "      <td>128</td>\n",
       "      <td>37</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>11</td>\n",
       "      <td>49</td>\n",
       "      <td>7</td>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>14</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>36</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>78</td>\n",
       "      <td>33</td>\n",
       "      <td>5</td>\n",
       "      <td>11</td>\n",
       "      <td>123</td>\n",
       "      <td>16</td>\n",
       "      <td>127</td>\n",
       "      <td>104</td>\n",
       "      <td>150</td>\n",
       "      <td>4</td>\n",
       "      <td>39</td>\n",
       "      <td>40</td>\n",
       "      <td>7</td>\n",
       "      <td>69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2 rows  138 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   studi  covid  suggest  new studi  research  effect  dure  peopl  sarscov  \\\n",
       "0     41     21       12         14        82      16    11     63        1   \n",
       "1    499    173      184        231       263     103    76    199       60   \n",
       "\n",
       "   men  new research  women  children  reduc  like  associ  brain  analysi  \\\n",
       "0    0             2      3        10     21    55       6     24        3   \n",
       "1   77            72     88        99     94   152      68     93       31   \n",
       "\n",
       "   adult  infect  rate  evid  death  individu  activ  bird  link  speci  \\\n",
       "0      8       9    10     8      2         7     13     1     3     10   \n",
       "1     72      70    58    43     45        35     47    18    49     35   \n",
       "\n",
       "   black  behavior  physic  suggest new  wa  use  new  patient  perform  \\\n",
       "0      6         2       5            0  29  130  211       10        7   \n",
       "1     43        40      30           74  98  204  487       70       33   \n",
       "\n",
       "   parent  exposur  past  appear  lead  ...  ai  power  robot  world  futur  \\\n",
       "0       3        0     8       4    21  ...  88    124     82    136    111   \n",
       "1      37       23    23      31    51  ...   6     20      7     36     19   \n",
       "\n",
       "   elon  compani  electr  energi  scientist  say  musk  wind  renew  car  \\\n",
       "0    58       72      83     126         77   92    60    54     71   63   \n",
       "1     0        3      18      32        128   37     0     3      7   11   \n",
       "\n",
       "   climat  space  solar  coal  plan  technolog  fuel  tesla  treatment  \\\n",
       "0     120     46    122    56    66         64    66     46         10   \n",
       "1      49      7     22     6     7         14    12      0         36   \n",
       "\n",
       "   project  economi  tech  develop  measur  hydrogen  artifici  time  job  \\\n",
       "0       48       26    31       48      11        50        36    89   45   \n",
       "1        6        2     1       78      33         5        11   123   16   \n",
       "\n",
       "   year  human   ha  internet  reveal  water  batteri  chang  subreddit  \n",
       "0   116     98  128        30      15     57       33    100          0  \n",
       "1   127    104  150         4      39     40        7     69          1  \n",
       "\n",
       "[2 rows x 138 columns]"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the cleaned data\n",
    "selected_features_df = pd.read_csv('../data/feature_selection/feature_selection_logreg_randomforest_for_model.csv')\n",
    "\n",
    "# Check its shape\n",
    "display(selected_features_df.shape)\n",
    "\n",
    "# Add the target (which is currently just the index)\n",
    "selected_features_df['subreddit'] = pd.Series([0, 1])\n",
    "\n",
    "# Preview\n",
    "selected_features_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set feature matrix and target variable\n",
    "X_selected_features = selected_features_df.drop(columns = 'subreddit')\n",
    "y_selected_features = selected_features_df['subreddit']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 137)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(X_selected_features.shape)\n",
    "display(y_selected_features.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Found input variables with inconsistent numbers of samples: [2, 3137]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-337-c7fe1c0148bf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m X_train_sel, X_test_sel, y_train_sel, y_test_sel = train_test_split(X_selected_features,\n\u001b[0m\u001b[0;32m      2\u001b[0m                                                     \u001b[0my_selected_features\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m                                                     \u001b[0mtest_size\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.33\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m                                                     \u001b[0mstratify\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m             \u001b[1;31m# equal balance of yes and no in train and test\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m                                                     random_state = 42)\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36mtrain_test_split\u001b[1;34m(*arrays, **options)\u001b[0m\n\u001b[0;32m   2150\u001b[0m                      random_state=random_state)\n\u001b[0;32m   2151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2152\u001b[1;33m         \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0marrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mstratify\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2154\u001b[0m     return list(chain.from_iterable((_safe_indexing(a, train),\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py\u001b[0m in \u001b[0;36msplit\u001b[1;34m(self, X, y, groups)\u001b[0m\n\u001b[0;32m   1338\u001b[0m         \u001b[0mto\u001b[0m \u001b[0man\u001b[0m \u001b[0minteger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1339\u001b[0m         \"\"\"\n\u001b[1;32m-> 1340\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mindexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1341\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iter_indices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroups\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1342\u001b[0m             \u001b[1;32myield\u001b[0m \u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mindexable\u001b[1;34m(*iterables)\u001b[0m\n\u001b[0;32m    290\u001b[0m     \"\"\"\n\u001b[0;32m    291\u001b[0m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0m_make_indexable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mX\u001b[0m \u001b[1;32min\u001b[0m \u001b[0miterables\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 292\u001b[1;33m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    293\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[1;34m(*arrays)\u001b[0m\n\u001b[0;32m    253\u001b[0m     \u001b[0muniques\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munique\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlengths\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    254\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 255\u001b[1;33m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0m\u001b[0;32m    256\u001b[0m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [2, 3137]"
     ]
    }
   ],
   "source": [
    "X_train_sel, X_test_sel, y_train_sel, y_test_sel = train_test_split(X_selected_features,\n",
    "                                                    y_selected_features,\n",
    "                                                    test_size = 0.33,\n",
    "                                                    stratify = y,             # equal balance of yes and no in train and test\n",
    "                                                    random_state = 42)\n",
    "\n",
    "print('X_train shape:', X_train_sel.shape)\n",
    "print('y_train shape:', y_train_sel.shape, '\\n')\n",
    "print('X_test shape:', X_test_sel.shape)\n",
    "print('y_test shape:', y_test_sel.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline accuracy\n",
    "\n",
    "**50% is the baseline accuracy percentage we compare with the model's accuracy.**\n",
    "\n",
    "**If the model does better than the baseline, then it is better than null model (predicting the majority class).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Balance of classes in `y`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1    0.5\n",
       "0    0.5\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printmd('**Balance of classes in `y`**')\n",
    "display(y_selected_features.value_counts(normalize=True))\n",
    "\n",
    "# printmd('**Balance of classes in `y_train`**')\n",
    "# display(y_train.value_counts(normalize=True))\n",
    "\n",
    "# printmd('**Balance of classes in `y_test`**')\n",
    "# y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression model using manually selected features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-296-47fa53af7e1c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_reg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_tvec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mean_test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1032\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1033\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    845\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 847\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    848\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    763\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1405\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1406\u001b[0m             \u001b[0mprefer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'processes'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[0;32m   1408\u001b[0m                                \u001b[1;33m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprefer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m             path_func(X, y, pos_class=class_, Cs=[C_],\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1027\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1029\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    845\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 847\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    848\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    763\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[0;32m    795\u001b[0m                 \u001b[0mbeta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1.\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0ml1_ratio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    796\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 797\u001b[1;33m             w0, n_iter_i, warm_start_sag = sag_solver(\n\u001b[0m\u001b[0;32m    798\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m                 \u001b[0mbeta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py\u001b[0m in \u001b[0;36msag_solver\u001b[1;34m(X, y, sample_weight, loss, alpha, beta, max_iter, tol, verbose, random_state, check_input, max_squared_sum, warm_start_mem, is_saga)\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m     \u001b[0msag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msag64\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0msag32\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m     num_seen, n_iter_ = sag(dataset, coef_init,\n\u001b[0m\u001b[0;32m    312\u001b[0m                             \u001b[0mintercept_init\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m                             \u001b[0mn_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params = {'solver': ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "               'C': [.0001, .001, .01, .1, 1], \n",
    "               'penalty': ['l1', 'l2']\n",
    "              }\n",
    "\n",
    "log_reg = LogisticRegression(C=1, random_state=42)\n",
    "\n",
    "clf = GridSearchCV(log_reg, params, cv=5)\n",
    "\n",
    "clf.fit(X_train_tvec, y_train)\n",
    "\n",
    "scores = clf.cv_results_['mean_test_score']\n",
    "   \n",
    "# ref: https://towardsdatascience.com/dont-sweat-the-solver-stuff-aea7cddc3451    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Grid searched:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'solver': ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'],\n",
       " 'C': [0.0001, 0.001, 0.01, 0.1, 1],\n",
       " 'penalty': ['l1', 'l2']}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Best accuracy score**: 0.8267"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Best estimator / parameters:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, random_state=42, solver='liblinear')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Accuracy score on train data: 0.959**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Accuracy score on test data: 0.835**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**The model is still overfit**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printmd('**Grid searched:**')\n",
    "display(clf.param_grid)\n",
    "printmd(f'**Best accuracy score**: {round(clf.best_score_, 4)}')\n",
    "printmd('**Best estimator / parameters:**')\n",
    "display(clf.best_estimator_)\n",
    "display(clf.best_params_)\n",
    "\n",
    "# Get accuracy scores for train and test data\n",
    "printmd(f'**Accuracy score on train data: {clf.score(X_train_tvec, y_train):.3f}**')\n",
    "printmd(f'**Accuracy score on test data: {clf.score(X_test_tvec, y_test):.3f}**')\n",
    "printmd('**The model is still overfit**')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, random_state=42, solver='liblinear')"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression(C = 1, penalty = 'l2', solver = 'liblinear', random_state=42)\n",
    "\n",
    "log_reg.fit(X_train_tvec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.13744292]),\n",
       " array([[-0.10524177,  0.62591884,  0.09646383, ...,  0.06160046,\n",
       "         -0.12670566,  0.06088419]]))"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.intercept_, log_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**The strongest coefficients start from the top in the table below.**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "***Holding all else constant, the effect of `studi` is a 4.6 times increase in predictive accuracy.***"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coeff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>studi</th>\n",
       "      <td>4.569888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>covid</th>\n",
       "      <td>2.735273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suggest</th>\n",
       "      <td>2.426959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new studi</th>\n",
       "      <td>2.098700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>research</th>\n",
       "      <td>2.056223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>increas</th>\n",
       "      <td>1.790901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>effect</th>\n",
       "      <td>1.653257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dure</th>\n",
       "      <td>1.635006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peopl</th>\n",
       "      <td>1.596396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sarscov</th>\n",
       "      <td>1.549757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>men</th>\n",
       "      <td>1.524014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new research</th>\n",
       "      <td>1.460708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>women</th>\n",
       "      <td>1.400299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>children</th>\n",
       "      <td>1.388924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reduc</th>\n",
       "      <td>1.366629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>1.334470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>associ</th>\n",
       "      <td>1.265025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brain</th>\n",
       "      <td>1.252246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analysi</th>\n",
       "      <td>1.185132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adult</th>\n",
       "      <td>1.148202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Coeff\n",
       "studi         4.569888\n",
       "covid         2.735273\n",
       "suggest       2.426959\n",
       "new studi     2.098700\n",
       "research      2.056223\n",
       "increas       1.790901\n",
       "effect        1.653257\n",
       "dure          1.635006\n",
       "peopl         1.596396\n",
       "sarscov       1.549757\n",
       "men           1.524014\n",
       "new research  1.460708\n",
       "women         1.400299\n",
       "children      1.388924\n",
       "reduc         1.366629\n",
       "like          1.334470\n",
       "associ        1.265025\n",
       "brain         1.252246\n",
       "analysi       1.185132\n",
       "adult         1.148202"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printmd('**The strongest coefficients start from the top in the table below.**')\n",
    "printmd(f'***Holding all else constant, the effect of `studi` is a {log_reg_coef.T.iloc[0, 0]:.1f} times increase in predictive accuracy.***')\n",
    "\n",
    "log_reg_coef = pd.DataFrame(log_reg.coef_.T, index = X_train_tvec.columns, columns = ['Coeff']).sort_values('Coeff', ascending = False)\n",
    "display(log_reg_coef[:20])\n",
    "\n",
    "# Export to combine with other top 100 features that I'm able to pull from other models\n",
    "log_reg_coef[:100].to_csv('../data/feature_selection/feature_selection_logreg.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
