{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project 3: Plausible Utopia \n",
    "\n",
    "### Classification Modeling on Subreddits to Classify Futurists vs. Scientists\n",
    "\n",
    "### Notebook 2 of 3: Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import missingno as msno\n",
    "\n",
    "from sklearn.linear_model import LinearRegression, LassoCV, RidgeCV, LogisticRegression\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, classification_report, accuracy_score, roc_auc_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "     \n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import re\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "##this will hide deprecation/future warnings\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "pd.set_option('display.max_row', 200) # Set ipython's max row display\n",
    "pd.set_option('display.max_columns', 85) # Set iPython's max column count\n",
    "pd.set_option('display.max_colwidth', 1_000) # Set iPython's max column width\n",
    "\n",
    "# pseudo-markdown in code cells\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "# ref: https://discuss.analyticsvidhya.com/t/how-to-make-a-text-bold-within-print-statement-in-ipython-notebook/14552/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1800, 7)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the cleaned data\n",
    "subred = pd.read_csv('../data/cleaned_data/cleaned_df_1.csv', index_col = 'id')\n",
    "subred.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set feature matrix and target variable\n",
    "\n",
    "X = subred['title']\n",
    "y = subred['subreddit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "read the following from ISLR:\n",
    "\n",
    "5.2 - The Bootstrap. (You'll want to know the bootstrap well as it will be embedded in methods we'll discuss next week.)\n",
    "Chapter 8 - Tree Based Methods. (We'll learn about classification and regression trees, random forests, bagging and boosting next week.)\n",
    "9.1-9.5 (Support Vector Machines and related methods)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify an optimal model with a pipeline and GridSearch\n",
    "\n",
    "### Train-test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " **Ref: 5.05 lesson**\n",
    " \n",
    " Features can be completely different in train/test\n",
    " \n",
    "**IMPORTANT** Instead of splitting we can use entire dataset combined with cross-validation\n",
    " \n",
    " Depending on how big dataset is, significant words in train set will probably appear in test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1206,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1206,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(594,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(594,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size = 0.33,\n",
    "                                                    stratify = y,\n",
    "                                                    random_state = 42)\n",
    "\n",
    "display(X_train.shape)\n",
    "display(y_train.shape)\n",
    "\n",
    "display(X_test.shape)\n",
    "display(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline accuracy\n",
    "\n",
    "**51.7% is the baseline accuracy percentage we compare with the model's accuracy.**\n",
    "\n",
    "**If the model does better than the baseline, then it is better than null model (predicting the majority / plurality class).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "science       0.517222\n",
       "futurology    0.482778\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "science       0.517413\n",
       "futurology    0.482587\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "science       0.516835\n",
       "futurology    0.483165\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "display(y.value_counts(normalize=True))\n",
    "\n",
    "display(y_train.value_counts(normalize=True))\n",
    "\n",
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cutoff point "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline 1\n",
    "\n",
    "**CountVectorizer (transformer)**:\n",
    "\n",
    "\n",
    "\n",
    "**Multinomial Naive Bayes (estimator)**:\n",
    "\n",
    "* Fast modeling algorithm\n",
    "* Variables are positive integers\n",
    "* Assumes all variables are independent (which is not realistic in NLP, but this assumption is accepted anyway)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set a pipeline up with two stages:\n",
    "# 1. CountVectorizer (transformer)\n",
    "# 2. Multinomial Naive Bayes (estimator)\n",
    "\n",
    "pipe_cvec_nb = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('nb', MultinomialNB())    # Naive Bayes\n",
    "])\n",
    "\n",
    "\n",
    "# Search over the following values of hyperparameters:\n",
    "# Maximum number of features fit\n",
    "# Minimum number of documents needed to include token\n",
    "# Maximum number of documents needed to include token\n",
    "# Check (individual tokens) and also check (individual tokens and 2-grams).\n",
    "\n",
    "pipe_cvec_nb_params = {\n",
    "    'cvec__max_features': [1_000, 2_000, 3_000, 4_000, 5_000],\n",
    "    'cvec__min_df': [1, 2],\n",
    "    'cvec__max_df': [.98, .99],\n",
    "    'cvec__ngram_range': [(1,1), (1,2)]\n",
    "}\n",
    "\n",
    "# Instantiate GridSearchCV.\n",
    "\n",
    "gs_cvec_nb = GridSearchCV(pipe_cvec_nb, # what object are we optimizing?\n",
    "                  param_grid = pipe_cvec_nb_params, # what parameters values are we searching?\n",
    "                  cv=5)      # 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('nb', MultinomialNB())]),\n",
       "             param_grid={'cvec__max_df': [0.98, 0.99],\n",
       "                         'cvec__max_features': [1000, 2000, 3000, 4000, 5000],\n",
       "                         'cvec__min_df': [1, 2],\n",
       "                         'cvec__ngram_range': [(1, 1), (1, 2)]})"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit GridSearch to data.\n",
    "gs_cvec_nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Grid searched:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': [1000, 2000, 3000, 4000, 5000],\n",
       " 'cvec__min_df': [1, 2],\n",
       " 'cvec__max_df': [0.98, 0.99],\n",
       " 'cvec__ngram_range': [(1, 1), (1, 2)]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Best score**: 0.825"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Best estimator / parameters:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cvec', CountVectorizer(max_df=0.98, max_features=5000)),\n",
       "                ('nb', MultinomialNB())])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.98,\n",
       " 'cvec__max_features': 5000,\n",
       " 'cvec__min_df': 1,\n",
       " 'cvec__ngram_range': (1, 1)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_cvec__max_df</th>\n",
       "      <th>param_cvec__max_features</th>\n",
       "      <th>param_cvec__min_df</th>\n",
       "      <th>param_cvec__ngram_range</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.055658</td>\n",
       "      <td>0.005598</td>\n",
       "      <td>0.010372</td>\n",
       "      <td>0.000799</td>\n",
       "      <td>0.99</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'cvec__max_df': 0.99, 'cvec__max_features': 5000, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 1)}</td>\n",
       "      <td>0.826446</td>\n",
       "      <td>0.800830</td>\n",
       "      <td>0.842324</td>\n",
       "      <td>0.821577</td>\n",
       "      <td>0.834025</td>\n",
       "      <td>0.825040</td>\n",
       "      <td>0.013997</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.059448</td>\n",
       "      <td>0.005179</td>\n",
       "      <td>0.013956</td>\n",
       "      <td>0.002828</td>\n",
       "      <td>0.98</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'cvec__max_df': 0.98, 'cvec__max_features': 5000, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 1)}</td>\n",
       "      <td>0.826446</td>\n",
       "      <td>0.800830</td>\n",
       "      <td>0.842324</td>\n",
       "      <td>0.821577</td>\n",
       "      <td>0.834025</td>\n",
       "      <td>0.825040</td>\n",
       "      <td>0.013997</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.153983</td>\n",
       "      <td>0.009230</td>\n",
       "      <td>0.022540</td>\n",
       "      <td>0.001017</td>\n",
       "      <td>0.99</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'cvec__max_df': 0.99, 'cvec__max_features': 5000, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 2)}</td>\n",
       "      <td>0.842975</td>\n",
       "      <td>0.804979</td>\n",
       "      <td>0.834025</td>\n",
       "      <td>0.813278</td>\n",
       "      <td>0.825726</td>\n",
       "      <td>0.824197</td>\n",
       "      <td>0.013712</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.154194</td>\n",
       "      <td>0.020380</td>\n",
       "      <td>0.019754</td>\n",
       "      <td>0.003175</td>\n",
       "      <td>0.98</td>\n",
       "      <td>5000</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 2)</td>\n",
       "      <td>{'cvec__max_df': 0.98, 'cvec__max_features': 5000, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 2)}</td>\n",
       "      <td>0.842975</td>\n",
       "      <td>0.804979</td>\n",
       "      <td>0.834025</td>\n",
       "      <td>0.813278</td>\n",
       "      <td>0.825726</td>\n",
       "      <td>0.824197</td>\n",
       "      <td>0.013712</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.033315</td>\n",
       "      <td>0.003920</td>\n",
       "      <td>0.006380</td>\n",
       "      <td>0.000485</td>\n",
       "      <td>0.99</td>\n",
       "      <td>4000</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'cvec__max_df': 0.99, 'cvec__max_features': 4000, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 1)}</td>\n",
       "      <td>0.830579</td>\n",
       "      <td>0.800830</td>\n",
       "      <td>0.825726</td>\n",
       "      <td>0.809129</td>\n",
       "      <td>0.838174</td>\n",
       "      <td>0.820887</td>\n",
       "      <td>0.013833</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "36       0.055658      0.005598         0.010372        0.000799   \n",
       "16       0.059448      0.005179         0.013956        0.002828   \n",
       "37       0.153983      0.009230         0.022540        0.001017   \n",
       "17       0.154194      0.020380         0.019754        0.003175   \n",
       "32       0.033315      0.003920         0.006380        0.000485   \n",
       "\n",
       "   param_cvec__max_df param_cvec__max_features param_cvec__min_df  \\\n",
       "36               0.99                     5000                  1   \n",
       "16               0.98                     5000                  1   \n",
       "37               0.99                     5000                  1   \n",
       "17               0.98                     5000                  1   \n",
       "32               0.99                     4000                  1   \n",
       "\n",
       "   param_cvec__ngram_range  \\\n",
       "36                  (1, 1)   \n",
       "16                  (1, 1)   \n",
       "37                  (1, 2)   \n",
       "17                  (1, 2)   \n",
       "32                  (1, 1)   \n",
       "\n",
       "                                                                                                params  \\\n",
       "36  {'cvec__max_df': 0.99, 'cvec__max_features': 5000, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 1)}   \n",
       "16  {'cvec__max_df': 0.98, 'cvec__max_features': 5000, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 1)}   \n",
       "37  {'cvec__max_df': 0.99, 'cvec__max_features': 5000, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 2)}   \n",
       "17  {'cvec__max_df': 0.98, 'cvec__max_features': 5000, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 2)}   \n",
       "32  {'cvec__max_df': 0.99, 'cvec__max_features': 4000, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 1)}   \n",
       "\n",
       "    split0_test_score  split1_test_score  split2_test_score  \\\n",
       "36           0.826446           0.800830           0.842324   \n",
       "16           0.826446           0.800830           0.842324   \n",
       "37           0.842975           0.804979           0.834025   \n",
       "17           0.842975           0.804979           0.834025   \n",
       "32           0.830579           0.800830           0.825726   \n",
       "\n",
       "    split3_test_score  split4_test_score  mean_test_score  std_test_score  \\\n",
       "36           0.821577           0.834025         0.825040        0.013997   \n",
       "16           0.821577           0.834025         0.825040        0.013997   \n",
       "37           0.813278           0.825726         0.824197        0.013712   \n",
       "17           0.813278           0.825726         0.824197        0.013712   \n",
       "32           0.809129           0.838174         0.820887        0.013833   \n",
       "\n",
       "    rank_test_score  \n",
       "36                1  \n",
       "16                1  \n",
       "37                3  \n",
       "17                3  \n",
       "32                5  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "printmd('**Grid searched:**')\n",
    "display(gs_cvec_nb.param_grid)\n",
    "printmd(f'**Best score**: {round(gs_cvec_nb.best_score_, 4)}')\n",
    "printmd('**Best estimator / parameters:**')\n",
    "display(gs_cvec_nb.best_estimator_)\n",
    "display(gs_cvec_nb.best_params_)\n",
    "\n",
    "pd.DataFrame(gs_cvec_nb.cv_results_).sort_values('rank_test_score').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "credit: NLP II: `CountVectorizer`, `TfidfVectorizer`, and Modeling lesson. _Authors: Dave Yerrington (SF), Justin Pounders (ATL), Riley Dallas (ATX), Matt Brems (DC), Noelle Brown (DEN)_"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get predictions\n",
    "preds = gs_cvec_nb.predict(X_test)\n",
    "\n",
    "# Save confusion matrix values\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n",
    "\n",
    "# View confusion matrix\n",
    "\n",
    "plot_confusion_matrix(gs_cvec_nb, X_test, y_test, cmap='cubehelix', values_format='d');\n",
    "plt.title('Confusion matrix')\n",
    "\n",
    "printmd('credit: NLP II: `CountVectorizer`, `TfidfVectorizer`, and Modeling lesson. _Authors: Dave Yerrington (SF), Justin Pounders (ATL), Riley Dallas (ATX), Matt Brems (DC), Noelle Brown (DEN)_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8518518518518519\n",
      "Misclassification: 0.14814814814814814\n",
      "Sensitivity: 0.8762214983713354\n",
      "Precision: 0.8432601880877743\n",
      "Specificity: 0.8257839721254355\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy\n",
    "\n",
    "acc = (tp + tn) / (tp + fp + tn + fn)\n",
    "print('Accuracy:', acc)\n",
    "\n",
    "# Calculate the misclassification rate\n",
    "\n",
    "misclass = (fp + fn) / (tp + fp + tn + fn)\n",
    "print('Misclassification:', misclass)\n",
    "\n",
    "# Calculate the sensitivity\n",
    "\n",
    "sens = tp / (tp + fn)\n",
    "print('Sensitivity:', sens)\n",
    "\n",
    "# Calculate the precision\n",
    "\n",
    "prec = tp / (tp + fp)\n",
    "print('Precision:', prec)\n",
    "\n",
    "# Calculate the specificity\n",
    "\n",
    "spec = tn / (tn + fp)\n",
    "print('Specificity:', spec)\n",
    "\n",
    "def metrics(y_test, y_predict, pred_proba):\n",
    "    print('Accuracy score %s ' % accuracy_score(y_test, y_predict), '\\n')\n",
    "    print('----------------------------------------------------------------')\n",
    "    print(pd.DataFrame(confusion_matrix(y_test, y_predict), \n",
    "                            index=['Not Actual Disaster', 'Actual Disaster'], \n",
    "                            columns=['Predicted Not Actual Disaster', 'Predicted Disaster']), '\\n')\n",
    "    print('-----------------------------------------------------------------')\n",
    "    print(classification_report(y_test, y_predict))\n",
    "    print('-----------------------------------------------------------------')\n",
    "    print('ROC_AUC SCORE %s ' %roc_auc_score(y_test, pred_proba))\n",
    "    \n",
    "# credit: Heather Robinson :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update the scoreboard or not? These are artificially high scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model # |     Model metrics     |  Score | Before preprocessing shape | train_test_split  | Value |   Pipeline  |        pipe_cvec_nb       | Pipe hyperparameters |                         Value set                         | GridsearchCV parameters | Value | GridsearchCV BEST parameters | Value  |\n",
    "|:-------:|:---------------------:|:------:|:--------------------------:|:-----------------:|:-----:|:-----------:|:-------------------------:|:--------------------:|:---------------------------------------------------------:|:-----------------------:|:-----:|:----------------------------:|--------|\n",
    "|    1    |       Best score      | 0.8389 |          (1800, 7)         |     test_size     |  0.33 | Transformer | 'cvec', CountVectorizer() |     max_features     | 'cvec__max_features': [1_000, 2_000, 3_000, 4_000, 5_000] | k-fold cross-validation |   5   | cvec__max_df                 | 0.98   |\n",
    "|    1    | |  |                            |      stratify     |   y   |  Estimator  |   'nb', MultinomialNB()   |        min_df        |                   'cvec__min_df': [1, 2]                  |                         |       | cvec__max_features           | 4000   |\n",
    "|    1    |   |  |                            |    random_state   |   42  |             |                           |        max_df        |                 'cvec__max_df': [.98, .99]                |                         |       | cvec__min_df                 | 1      |\n",
    "|    1    |                       |        |                            |                   |       |             |                           |      ngram_range     |             'cvec__ngram_range': [(1,1), (1,2)            |                         |       | cvec__ngram_range            | (1, 2) |\n",
    "|    1    |                       |        |                            |                   |       |             |                           |                      |                                                           |                         |       |                              |        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline 1 Part 2\n",
    "\n",
    "**CountVectorizer (transformer)**:\n",
    "\n",
    "\n",
    "\n",
    "**Multinomial Naive Bayes (estimator)**:\n",
    "\n",
    "* Fast modeling algorithm\n",
    "* Variables are positive integers\n",
    "* Assumes all variables are independent (which is not realistic in NLP, but this assumption is accepted anyway)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set a pipeline up with two stages:\n",
    "# 1. CountVectorizer (transformer)\n",
    "# 2. Multinomial Naive Bayes (estimator)\n",
    "\n",
    "pipe_cvec_nb = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('nb', MultinomialNB())    # Naive Bayes\n",
    "])\n",
    "\n",
    "\n",
    "# Search over the following values of hyperparameters:\n",
    "# Maximum number of features fit\n",
    "# Minimum number of documents needed to include token\n",
    "# Maximum number of documents needed to include token\n",
    "# Check (individual tokens) and also check (individual tokens and 2-grams).\n",
    "\n",
    "pipe_cvec_nb_params = {\n",
    "    'cvec__max_features': [4_000, 6_000],\n",
    "    'cvec__min_df': [1, 2],\n",
    "    'cvec__max_df': [.05, .1, .25, .4],\n",
    "    'cvec__ngram_range': [(1,1)]\n",
    "}\n",
    "\n",
    "# Instantiate GridSearchCV.\n",
    "\n",
    "gs_cvec_nb = GridSearchCV(pipe_cvec_nb, # what object are we optimizing?\n",
    "                  param_grid = pipe_cvec_nb_params, # what parameters values are we searching?\n",
    "                  cv=5)      # 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('nb', MultinomialNB())]),\n",
       "             param_grid={'cvec__max_df': [0.05, 0.1, 0.25, 0.4],\n",
       "                         'cvec__max_features': [6000], 'cvec__min_df': [1],\n",
       "                         'cvec__ngram_range': [(1, 1)]})"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit GridSearch to data.\n",
    "gs_cvec_nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Grid searched:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': [6000],\n",
       " 'cvec__min_df': [1],\n",
       " 'cvec__max_df': [0.05, 0.1, 0.25, 0.4],\n",
       " 'cvec__ngram_range': [(1, 1)]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Best score**: 0.8342"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Best estimator / parameters:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cvec', CountVectorizer(max_df=0.4, max_features=6000)),\n",
       "                ('nb', MultinomialNB())])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.4,\n",
       " 'cvec__max_features': 6000,\n",
       " 'cvec__min_df': 1,\n",
       " 'cvec__ngram_range': (1, 1)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean_fit_time</th>\n",
       "      <th>std_fit_time</th>\n",
       "      <th>mean_score_time</th>\n",
       "      <th>std_score_time</th>\n",
       "      <th>param_cvec__max_df</th>\n",
       "      <th>param_cvec__max_features</th>\n",
       "      <th>param_cvec__min_df</th>\n",
       "      <th>param_cvec__ngram_range</th>\n",
       "      <th>params</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "      <th>split3_test_score</th>\n",
       "      <th>split4_test_score</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>std_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.026922</td>\n",
       "      <td>0.005012</td>\n",
       "      <td>0.004993</td>\n",
       "      <td>0.000632</td>\n",
       "      <td>0.4</td>\n",
       "      <td>6000</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'cvec__max_df': 0.4, 'cvec__max_features': 6000, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 1)}</td>\n",
       "      <td>0.830579</td>\n",
       "      <td>0.813278</td>\n",
       "      <td>0.854772</td>\n",
       "      <td>0.829876</td>\n",
       "      <td>0.842324</td>\n",
       "      <td>0.834165</td>\n",
       "      <td>0.013847</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.024341</td>\n",
       "      <td>0.001346</td>\n",
       "      <td>0.005186</td>\n",
       "      <td>0.000399</td>\n",
       "      <td>0.25</td>\n",
       "      <td>6000</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'cvec__max_df': 0.25, 'cvec__max_features': 6000, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 1)}</td>\n",
       "      <td>0.826446</td>\n",
       "      <td>0.809129</td>\n",
       "      <td>0.846473</td>\n",
       "      <td>0.825726</td>\n",
       "      <td>0.834025</td>\n",
       "      <td>0.828360</td>\n",
       "      <td>0.012171</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.025531</td>\n",
       "      <td>0.002240</td>\n",
       "      <td>0.004388</td>\n",
       "      <td>0.000489</td>\n",
       "      <td>0.1</td>\n",
       "      <td>6000</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'cvec__max_df': 0.1, 'cvec__max_features': 6000, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 1)}</td>\n",
       "      <td>0.830579</td>\n",
       "      <td>0.788382</td>\n",
       "      <td>0.850622</td>\n",
       "      <td>0.821577</td>\n",
       "      <td>0.825726</td>\n",
       "      <td>0.823377</td>\n",
       "      <td>0.020138</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.026728</td>\n",
       "      <td>0.004161</td>\n",
       "      <td>0.004994</td>\n",
       "      <td>0.000641</td>\n",
       "      <td>0.05</td>\n",
       "      <td>6000</td>\n",
       "      <td>1</td>\n",
       "      <td>(1, 1)</td>\n",
       "      <td>{'cvec__max_df': 0.05, 'cvec__max_features': 6000, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 1)}</td>\n",
       "      <td>0.805785</td>\n",
       "      <td>0.788382</td>\n",
       "      <td>0.846473</td>\n",
       "      <td>0.813278</td>\n",
       "      <td>0.821577</td>\n",
       "      <td>0.815099</td>\n",
       "      <td>0.019132</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   mean_fit_time  std_fit_time  mean_score_time  std_score_time  \\\n",
       "3       0.026922      0.005012         0.004993        0.000632   \n",
       "2       0.024341      0.001346         0.005186        0.000399   \n",
       "1       0.025531      0.002240         0.004388        0.000489   \n",
       "0       0.026728      0.004161         0.004994        0.000641   \n",
       "\n",
       "  param_cvec__max_df param_cvec__max_features param_cvec__min_df  \\\n",
       "3                0.4                     6000                  1   \n",
       "2               0.25                     6000                  1   \n",
       "1                0.1                     6000                  1   \n",
       "0               0.05                     6000                  1   \n",
       "\n",
       "  param_cvec__ngram_range  \\\n",
       "3                  (1, 1)   \n",
       "2                  (1, 1)   \n",
       "1                  (1, 1)   \n",
       "0                  (1, 1)   \n",
       "\n",
       "                                                                                               params  \\\n",
       "3   {'cvec__max_df': 0.4, 'cvec__max_features': 6000, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 1)}   \n",
       "2  {'cvec__max_df': 0.25, 'cvec__max_features': 6000, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 1)}   \n",
       "1   {'cvec__max_df': 0.1, 'cvec__max_features': 6000, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 1)}   \n",
       "0  {'cvec__max_df': 0.05, 'cvec__max_features': 6000, 'cvec__min_df': 1, 'cvec__ngram_range': (1, 1)}   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  split3_test_score  \\\n",
       "3           0.830579           0.813278           0.854772           0.829876   \n",
       "2           0.826446           0.809129           0.846473           0.825726   \n",
       "1           0.830579           0.788382           0.850622           0.821577   \n",
       "0           0.805785           0.788382           0.846473           0.813278   \n",
       "\n",
       "   split4_test_score  mean_test_score  std_test_score  rank_test_score  \n",
       "3           0.842324         0.834165        0.013847                1  \n",
       "2           0.834025         0.828360        0.012171                2  \n",
       "1           0.825726         0.823377        0.020138                3  \n",
       "0           0.821577         0.815099        0.019132                4  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "printmd('**Grid searched:**')\n",
    "display(gs_cvec_nb.param_grid)\n",
    "printmd(f'**Best score**: {round(gs_cvec_nb.best_score_, 4)}')\n",
    "printmd('**Best estimator / parameters:**')\n",
    "display(gs_cvec_nb.best_estimator_)\n",
    "display(gs_cvec_nb.best_params_)\n",
    "\n",
    "pd.DataFrame(gs_cvec_nb.cv_results_).sort_values('rank_test_score').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline 2\n",
    "\n",
    "**CountVectorizer (transformer)**:\n",
    "\n",
    "**TF-IDF (transformer)**:\n",
    "\n",
    "\n",
    "\n",
    "**Logistic Regression (estimator)**:\n",
    "\n",
    "* Relatively interpretable results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set up another pipeline\n",
    "# 1. CountVectorizer (transformer)\n",
    "# 2. TfidfVectorizer (transformer)\n",
    "# 3. LogisticRegression (estimator)\n",
    "\n",
    "pipe_log_reg_with_cvec_tfidf = Pipeline([\n",
    "    ('cvec', CountVectorizer(lowercase = False)),\n",
    "#     ('tvec', TfidfVectorizer(lowercase = False)),\n",
    "    ('log_reg', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Search over the following values of hyperparameters:\n",
    "# Maximum number of features fit\n",
    "# Minimum number of documents needed to include token\n",
    "# Maximum number of documents needed to include token\n",
    "# Check (individual tokens) and also check (individual tokens and 2-grams).\n",
    "\n",
    "pipe_log_reg_with_cvec_tfidf_params = {\n",
    "    'cvec__max_features': [1_000, 3_000, 5_000],\n",
    "    'cvec__min_df': [1, 2],\n",
    "    'cvec__max_df': [.98, .99],\n",
    "    'cvec__ngram_range': [(1,1), (2,1)],\n",
    "    'cvec__stop_words': [None, 'english'],\n",
    "#     'tvec__max_features': [3_000, 5_000],\n",
    "    'tvec__stop_words': [None, 'english'],\n",
    "#     'tvec__ngram_range': [(1,1), (1,2)],\n",
    "    'log_reg__C': [1, 0.5],\n",
    "    'log_reg__penalty': ['l1', 'l2']\n",
    "}\n",
    "\n",
    "# Instantiate GridSearchCV.\n",
    "\n",
    "gs_log_reg_with_cvec_tfidf = GridSearchCV(pipe_log_reg_with_cvec_tfidf, # what object are we optimizing?\n",
    "                  param_grid = pipe_log_reg_with_cvec_tfidf_params, # what parameters values are we searching?\n",
    "                  cv=5)      # 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cvec', CountVectorizer(lowercase=False)),\n",
       "                ('log_reg', LogisticRegression())])"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit GridSearch to data.\n",
    "pipe_log_reg_with_cvec_tfidf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Grid searched:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': [1000, 3000, 5000],\n",
       " 'cvec__min_df': [1, 2],\n",
       " 'cvec__max_df': [0.98, 0.99],\n",
       " 'cvec__ngram_range': [(1, 1), (2, 1)],\n",
       " 'cvec__stop_words': [None, 'english'],\n",
       " 'tvec__stop_words': [None, 'english'],\n",
       " 'log_reg__C': [1, 0.5],\n",
       " 'log_reg__penalty': ['l1', 'l2']}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_score_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-83-9a789d8292e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprintmd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'**Grid searched:**'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgs_log_reg_with_cvec_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprintmd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'**Best score**: {round(gs_log_reg_with_cvec_tfidf.best_score_, 4)}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprintmd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'**Best estimator / parameters:**'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgs_log_reg_with_cvec_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_score_'"
     ]
    }
   ],
   "source": [
    "printmd('**Grid searched:**')\n",
    "display(gs_log_reg_with_cvec_tfidf.param_grid)\n",
    "printmd(f'**Best score**: {round(gs_log_reg_with_cvec_tfidf.best_score_, 4)}')\n",
    "printmd('**Best estimator / parameters:**')\n",
    "display(gs_log_reg_with_cvec_tfidf.best_estimator_)\n",
    "display(gs_log_reg_with_cvec_tfidf.best_params_)\n",
    "\n",
    "pd.DataFrame(gs_log_reg_with_cvec_tfidf.cv_results_).sort_values('rank_test_score').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline 3\n",
    "\n",
    "Tout un ensemble\n",
    "\n",
    "https://scikit-learn.org/stable/modules/ensemble.html\n",
    "\n",
    "**CountVectorizer (transformer)**:\n",
    "\n",
    "\n",
    "\n",
    "**Random Forest * LogReg * MNBayes (estimator) **:\n",
    "\n",
    "* "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline 4\n",
    "\n",
    "\n",
    "**TfidfVectorizer (transformer)**\n",
    "\n",
    "\n",
    "\n",
    "**SVG (estimator)**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
