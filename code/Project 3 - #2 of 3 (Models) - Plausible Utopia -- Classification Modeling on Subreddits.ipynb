{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Project 3: Plausible Utopia \n",
    "\n",
    "### Classification Modeling on Subreddits to Classify Futurists vs. Scientists\n",
    "\n",
    "### Notebook 2 of 3: Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Libary imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.linear_model import LassoCV, RidgeCV, LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingClassifier, VotingClassifier\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn import metrics\n",
    "import statsmodels.api as sm\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix, classification_report, accuracy_score, roc_auc_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "     \n",
    "from nltk.tokenize import sent_tokenize, word_tokenize, RegexpTokenizer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "import re\n",
    "\n",
    "import warnings; warnings.simplefilter('ignore')\n",
    "##this will hide deprecation/future warnings\n",
    "\n",
    "from IPython.display import Markdown, display\n",
    "pd.set_option('display.max_row', 200) # Set ipython's max row display\n",
    "pd.set_option('display.max_columns', 85) # Set iPython's max column count\n",
    "pd.set_option('display.max_colwidth', 1_000) # Set iPython's max column width\n",
    "\n",
    "# pseudo-markdown in code cells\n",
    "def printmd(string):\n",
    "    display(Markdown(string))\n",
    "# ref: https://discuss.analyticsvidhya.com/t/how-to-make-a-text-bold-within-print-statement-in-ipython-notebook/14552/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3137, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>robot encroach on up to  million job around the world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>measur in ai polici opportun and challeng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>how egypt is grow forest in middl of the desert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>energi scaveng nanogener find power all around us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>there are polit and cultur problem that occur with social chang in a societi with high andor rise life expect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subreddit  \\\n",
       "0          0   \n",
       "1          0   \n",
       "2          0   \n",
       "3          0   \n",
       "4          0   \n",
       "\n",
       "                                                                                                            title  \n",
       "0                                                          robot encroach on up to  million job around the world   \n",
       "1                                                                      measur in ai polici opportun and challeng   \n",
       "2                                                                how egypt is grow forest in middl of the desert   \n",
       "3                                                              energi scaveng nanogener find power all around us   \n",
       "4  there are polit and cultur problem that occur with social chang in a societi with high andor rise life expect   "
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the cleaned data\n",
    "subred = pd.read_csv('../data/cleaned_data/cleaned_df.csv')\n",
    "\n",
    "# Check its shape\n",
    "display(subred.shape)\n",
    "\n",
    "# Preview\n",
    "subred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set feature matrix and target variable\n",
    "X = subred['title']\n",
    "y = subred['subreddit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify an optimal model with a pipeline and GridSearch\n",
    "\n",
    "### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (2101,)\n",
      "y_train shape: (2101,) \n",
      "\n",
      "X_test shape: (1036,)\n",
      "y_test shape: (1036,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size = 0.33,\n",
    "                                                    stratify = y,             # equal balance of yes and no in train and test\n",
    "                                                    random_state = 42)\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('y_train shape:', y_train.shape, '\\n')\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline accuracy\n",
    "\n",
    "**51.7% is the baseline accuracy percentage we compare with the model's accuracy.**\n",
    "\n",
    "**If the model does better than the baseline, then it is better than null model (predicting the majority / plurality class).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Balance of classes in `y`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    0.501753\n",
       "1    0.498247\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Balance of classes in `y_train`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    0.501666\n",
       "1    0.498334\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Balance of classes in `y_test`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    0.501931\n",
       "1    0.498069\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "printmd('**Balance of classes in `y`**')\n",
    "display(y.value_counts(normalize=True))\n",
    "\n",
    "printmd('**Balance of classes in `y_train`**')\n",
    "display(y_train.value_counts(normalize=True))\n",
    "\n",
    "printmd('**Balance of classes in `y_test`**')\n",
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cutoff point "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline 1\n",
    "\n",
    "**CountVectorizer (transformer)**:\n",
    "\n",
    "* Produces term frequencies by count\n",
    "\n",
    "**Multinomial Naive Bayes (estimator)**:\n",
    "\n",
    "* Fast modeling algorithm\n",
    "* Variables are positive integers\n",
    "* Assumes all variables are independent (which is not realistic in NLP, but this assumption is accepted anyway)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set a pipeline up with two stages:\n",
    "# 1. CountVectorizer (transformer)\n",
    "# 2. Multinomial Naive Bayes (estimator)\n",
    "\n",
    "pipe_cvec_nb = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('nb', MultinomialNB())    # Naive Bayes\n",
    "])\n",
    "\n",
    "\n",
    "# Search over the following values of hyperparameters:\n",
    "# Maximum number of features fit\n",
    "# Minimum number of documents needed to include token\n",
    "# Maximum number of documents needed to include token\n",
    "# Check (individual tokens) and also check (individual tokens and 2-grams).\n",
    "\n",
    "pipe_cvec_nb_params = {\n",
    "    'cvec__max_features': [1_000, 2_000, 3_000, 4_000, 5_000],\n",
    "    'cvec__min_df': [1, 2],\n",
    "    'cvec__max_df': [.98, .99],\n",
    "    'cvec__ngram_range': [(1,1), (1,2)]\n",
    "}\n",
    "\n",
    "# Instantiate GridSearchCV.\n",
    "\n",
    "gs_cvec_nb = GridSearchCV(pipe_cvec_nb,             # the object we are optimizing\n",
    "                  param_grid = pipe_cvec_nb_params, # the parameters values we are searching\n",
    "                  cv = 5)                           # Number of folds in cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('nb', MultinomialNB())]),\n",
       "             param_grid={'cvec__max_df': [0.98, 0.99],\n",
       "                         'cvec__max_features': [1000, 2000, 3000, 4000, 5000],\n",
       "                         'cvec__min_df': [1, 2],\n",
       "                         'cvec__ngram_range': [(1, 1), (1, 2)]})"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit GridSearch to data.\n",
    "gs_cvec_nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Grid searched:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': [1000, 2000, 3000, 4000, 5000],\n",
       " 'cvec__min_df': [1, 2],\n",
       " 'cvec__max_df': [0.98, 0.99],\n",
       " 'cvec__ngram_range': [(1, 1), (1, 2)]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Best accuracy score**: 0.8746"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Best estimator / parameters:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cvec', CountVectorizer(max_df=0.98, max_features=5000)),\n",
       "                ('nb', MultinomialNB())])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.98,\n",
       " 'cvec__max_features': 5000,\n",
       " 'cvec__min_df': 1,\n",
       " 'cvec__ngram_range': (1, 1)}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printmd('**Grid searched:**')\n",
    "display(gs_cvec_nb.param_grid)\n",
    "printmd(f'**Best accuracy score**: {round(gs_cvec_nb.best_score_, 4)}')\n",
    "printmd('**Best estimator / parameters:**')\n",
    "display(gs_cvec_nb.best_estimator_)\n",
    "display(gs_cvec_nb.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x17b64e65a60>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "credit: NLP II: `CountVectorizer`, `TfidfVectorizer`, and Modeling lesson. _Authors: Dave Yerrington (SF), Justin Pounders (ATL), Riley Dallas (ATX), Matt Brems (DC), Noelle Brown (DEN)_"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATgAAAEWCAYAAADy2YssAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de7wV1X338c9XkBMkUUQuctGAiiJqvASJl9YLmgQTFe2jCYoppRCDMfGSpK3avJKY6KONtI212sRbQ2IUMZqKmgf0RUNVggEOlyAogYoignIxiiEKnnN+zx8zR7fI2WcGzmHvPXzfvua1Z6+ZWfPbqD/WWjOzRhGBmVkR7VbpAMzM2osTnJkVlhOcmRWWE5yZFZYTnJkVlhOcmRWWE1zBSOos6RFJb0p6YAfqGSXp8baMrVIk/aWkpZWOw3Y++T64ypB0IfANYBDwFrAAuD4int7Ber8EfB04ISIadjjQKicpgIERsbzSsVj1cQuuAiR9A/gR8H+BXsD+wG3AiDao/uPAH3aF5JaFpI6VjsEqKCK87MQF2Av4E3B+mX3qSBLg6nT5EVCXbjsFWAV8E1gLrAHGpNuuBbYA76bnGAt8D7inpO7+QAAd0+9/A7xA0opcAYwqKX+65LgTgDnAm+nnCSXbZgA/AGam9TwOdG/htzXH//cl8Z8DfA74A/A6cE3J/kOBWcAb6b7/DnRKtz2Z/pZN6e/9Ykn9/wC8Cvy8uSw95sD0HMek3/sA64FTKv3fhpe2XyoewK62AMOBhuYE08I+3weeAXoCPYDfAj9It52SHv99YPc0MfwZ2DvdvnVCazHBAV2AjcAh6bbewGHp+nsJDugG/BH4UnrcBen3fdLtM4D/BQ4GOqffb2zhtzXH/500/i8D64B7gY8BhwHvAAek+38SOC49b3/gOeCKkvoCOGgb9f8TyV8UnUsTXLrPl9N69gCmARMq/d+Fl/ZZ3EXd+fYB1kf5LuQo4PsRsTYi1pG0zL5Usv3ddPu7EfFrktbLIdsZTxNwuKTOEbEmIhZvY5/PA8si4ucR0RAR9wHPA2eV7POfEfGHiHgbmAwcVeac75KMN74LTAK6AzdHxFvp+RcDnwCIiPqIeCY974vAT4CTM/ym70bE5jSeD4iIO4BlwO9Ikvo/tlKf1SgnuJ1vA9C9lbGhPsBLJd9fSsveq2OrBPln4KN5A4mITSTduvHAGkmPSRqUIZ7mmPqWfH81RzwbIqIxXW9OQK+VbH+7+XhJB0t6VNKrkjaSjFt2L1M3wLqIeKeVfe4ADgduiYjNrexrNcoJbuebRdIFO6fMPqtJLhY02z8t2x6bSLpizfYt3RgR0yLi0yQtmedJ/sdvLZ7mmF7Zzpjy+A+SuAZGxJ7ANYBaOabsrQGSPkoyrnkX8D1J3doiUKs+TnA7WUS8STL+dKukcyTtIWl3SWdI+mG6233AtyX1kNQ93f+e7TzlAuAkSftL2gu4unmDpF6SzpbUBdhM0tVt3EYdvwYOlnShpI6SvggMBh7dzpjy+BjJOOGf0tblJVttfw04IGedNwP1ETEOeAz48Q5HaVXJCa4CIuJfSO6B+zbJAPvLwNeA/0p3uQ6YC/weWATMS8u251xPAPenddXzwaS0G8nV2NUkVxZPBr66jTo2AGem+24guQJ6ZkSs356YcvoWcCHJ1dk7SH5Lqe8BEyW9IekLrVUmaQTJhZ7xadE3gGMkjWqziK1q+EZfMysst+DMrLCc4MyssJzgzKywnODMrLCq6kHk7t27R//+/SsdhuUwr35epUOwHIIgIlq7j7Cs4cOHx/r12S6g19fXT4uI4Ttyvh1RVQmuf//+zJ07t9JhWA6dO3SudAiWw+amHX9oY/369Zn/P03v46yYqkpwZlYbmmrk9jInODPLJQgaY1sPvFQfJzgzy62p/OO+VcMJzsxyCaApmiodRiZOcGaWm1twZlZMEb7IYGbFFLgFZ2YFFUCjW3BmVlTuoppZYTnBmVkhBeExODMrrqbayG9OcGaWT4QvMphZgbkFZ2aFlDyqVRsZzgnOzHJzC87MCqtG8psTnJnlk3RRKx1FNk5wZpZPQGNtzJbkBGdm+bgFZ2aFViMXUZ3gzCyncAvOzArMLTgzK6TAFxnMrMDcgjOzYgqIUKWjyMQJzsxyCdyCM7MCq5HXorJbpQMws9oTkW1pjaSukn4p6XlJz0k6XlI3SU9IWpZ+7l2y/9WSlktaKumzrdXvBGdm+QQ0NSrTksHNwNSIGAQcCTwHXAVMj4iBwPT0O5IGAyOBw4DhwG2SOpSr3AnOzPKLjEsZkvYETgLuAoiILRHxBjACmJjuNhE4J10fAUyKiM0RsQJYDgwtdw4nODPLJRAR2Ragu6S5JcvFJVUdAKwD/lPSfEl3SuoC9IqINQDpZ890/77AyyXHr0rLWuSLDGaWT+S6yLA+Ioa0sK0jcAzw9Yj4naSbSbujLdhWn7dsO9EtODPLrw26qCQtsFUR8bv0+y9JEt5rknoDpJ9rS/bfr+T4fsDqcidwgjOz3KIp21K2johXgZclHZIWnQYsAaYAo9Oy0cDD6foUYKSkOkkDgIHA7HLncBfVzPIJiGxXSLP4OvALSZ2AF4AxJA2vyZLGAiuB8wEiYrGkySRJsAG4NCIay1XuBGdm+bXRkwwRsQDY1hjdaS3sfz1wfdb6neDMLJ8AauRJBic4M8vPCc7MisoP25tZMQXJEH8NcIIzs/zcgjOzQvJFBjMrMjnBmVlhOcGZWSFle860KjjBmVluaqiNDOcEZ2b5+CKDmRVXoKbaaMF5uqQ28MYbb3DeeecxaNAgDj30UGbNmsXChQs5/vjjOeKIIzjrrLPYuHHje/vfcMMNHHTQQRxyyCFMmzatgpHvmn585495ac1LzF04972yvffem0enPcqi5xfx6LRH6dq1KwDDTh/GzNkzmbNgDjNnz+TkU0+uVNjVpW3mg2t37ZrgJA1P336zXFK5mTpr2uWXX87w4cN5/vnnWbhwIYceeijjxo3jxhtvZNGiRZx77rncdNNNACxZsoRJkyaxePFipk6dyle/+lUaG8vO+GJt7OcTf86Iz434QNm3/uFbzJg+gyMGHcGM6TP41j98C4AN6zdw3ojzOPaoY/nymC9z98S7KxFydQlQU2RaKq3dElz6tptbgTOAwcAF6VtxCmXjxo08+eSTjB07FoBOnTrRtWtXli5dykknnQTApz/9aR588EEAHn74YUaOHEldXR0DBgzgoIMOYvbssnP2WRub+dRMXn/99Q+UnXn2mdzzs3sAuOdn93DWiLMAWLhgIWvWrAFgyeIl1H2kjk6dOu3cgKtRU2RbKqw9W3BDgeUR8UJEbAEmkbwVp1BeeOEFevTowZgxYzj66KMZN24cmzZt4vDDD2fKlCkAPPDAA7z8cvKujFdeeYX99nt/1uV+/frxyiuvVCR2e1/PXj159dVXAXj11Vfp0bPHh/Y59/+cy8L5C9myZcvODq+qKJKrqFmWSmvPBJfpDTiSLm5+4866devaMZz20dDQwLx587jkkkuYP38+Xbp04cYbb+Tuu+/m1ltv5ZOf/CRvvfXWe3/rxzamYZDabHZUayeHDj6U6264jq9d8rVKh1IFsnVPC91FJeMbcCLi9ogYEhFDevT48N+a1a5fv37069ePT33qUwCcd955zJs3j0GDBvH4449TX1/PBRdcwIEHHvje/s2tOYBVq1bRp0+fisRu71v72lr23XdfAPbdd1/WrX3/L9u+ffty/4P3M+5vxrHihRWVCrF6BCgi01Jp7Zngcr8Bpxbtu+++7LfffixduhSA6dOnM3jwYNauTV4E1NTUxHXXXcf48eMBOPvss5k0aRKbN29mxYoVLFu2jKFDy7671naCxx55jIv++iIALvrri3h0yqMA7LXXXjz0yEN85x+/w6zfzqpkiNWlqSnbUmHtmeDmAAMlDUhfKDGS5K04hXPLLbcwatQoPvGJT7BgwQKuueYa7rvvPg4++GAGDRpEnz59GDNmDACHHXYYX/jCFxg8eDDDhw/n1ltvpUOHDhX+BbuWib+YyIyZMzj4kINZ/tJyRv/taCb80wSGnT6MRc8vYtjpw5jwTxMAGH/peA486ECu+sereKb+GZ6pf4Za7Gm0tVrpompbY0JtVrn0OeBHQAfg7vSFES0aMmRIzJ07t9wuVmU6d+hc6RAsh81Nm2mKph0a9D30wCPjZzdku39z6Bd715d58XO7a9cnGSLi18Cv2/McZrZzCVCOV9tXkh/VMrN80ht9a4ETnJnlFFVxASELJzgzyydATnBmVlTVcI9bFk5wZpZPBGqojfcGerokM8tFBIqmTEurdUkvSlokaYGkuWlZN0lPSFqWfu5dsv/V6exESyV9trX6neDMLL+2fZLh1Ig4quR+uauA6RExEJiefiedjWgkcBgwHLgtnbWoRU5wZpZPBGpqzLRspxHAxHR9InBOSfmkiNgcESuA5SSzFrXICc7McsvRRe3ePFtQuly8VVUBPC6pvmRbr4hYA5B+9kzLM81QVMoXGcwsv+zdz/WtPKp1YkSsltQTeELS82X2zTRDUSknODPLJwI1vttGVcXq9HOtpF+RdDlfk9Q7ItZI6g2sTXfPPUORu6hmllNANGVbypDURdLHmteBzwDPksw6NDrdbTTwcLo+BRgpqU7SAGAgUHa+f7fgzCw3RZu8KKkX8Kt0RuuOwL0RMVXSHGCypLHASuB8gIhYLGkysARoAC6NKB+IE5yZ5RMB23+FtKSaeAE4chvlG4DTWjjmeqDstGulnODMLD9Pl2RmhRRN0FgbbxZzgjOzXJIJL2vjZeVOcGaWU4ATnJkVUQCtXLysGk5wZpaTW3BmVlThBGdmhRVEk6+imllRuQVnZsXkLqqZFVUEEbXxTgYnODPLKQhqvAUn6RbKTCYXEZe1S0RmVuWKcZFh7k6LwsxqRhAENd5FjYiJpd8ldYmITe0fkplVu1p5kqHVGX0lHS9pCfBc+v1ISbe1e2RmVqWSMbgsS6VlmbL8R8BngQ0AEbEQOKk9gzKz6hbRmGmptExXUSPi5XRa4WaVj9zMKiIImmokBWRJcC9LOgEISZ2Ay0i7q2a2C4qgKTZXOopMsiS48cDNJC9YfQWYBlzankGZWTULmqqg+5lFqwkuItYDo3ZCLGZWA6KGbvTNchX1AEmPSFonaa2khyUdsDOCM7Pq1ERjpqXSslxFvReYDPQG+gAPAPe1Z1BmVs2iUAlOEfHziGhIl3so8wiXmRVbAE3RmGmptHLPonZLV38j6SpgEslv+yLw2E6IzcyqUhON1P6zqPUkCa35BrivlGwL4AftFZSZVa8AGqug+5lFuWdRB+zMQMysVhTrRl8kHQ4MBj7SXBYRP2uvoMysegW0aYKT1IFk9qJXIuLMdHjsfqA/8CLwhYj4Y7rv1cBYkqepLouIaeXqznKbyHeBW9LlVOCHwNnb+2PMrNa1+VXUy/ng01FXAdMjYiAwPf2OpMHASOAwYDhwW5ocW5TlKup5wGnAqxExBjgSqMsauZkVSxC8m/Gf1kjqB3weuLOkeATQPF3bROCckvJJEbE5IlYAy4Gh5erPkuDejogmoEHSnsBawDf6mu2iki5qtn+A7pLmliwXb1Xdj4C/h2TnVK+IWAOQfvZMy/sCL5fstyota1GWMbi5kroCd5BcWf0TMDvDcWZWSJHnKur6iBiyrQ2SzgTWRkS9pFMy1KVtlJW9JzfLs6hfTVd/LGkqsGdE/D5DMGZWQMl0SU2t79i6E4GzJX2O5ALmnpLuAV6T1Dsi1kjqTdJrhKTFtl/J8f2A1eVO0GIXVdIxWy9AN6Bjum5mu6jGjP+UExFXR0S/iOhPcvHgvyPiImAKMDrdbTTwcLo+BRgpqU7SAGAgrfQmy7Xg/rlcbMCwstFvh/r6eraaWNOq3PrNb1U6BMvhtON3fDLuZC6RNmnBteRGYLKkscBK4HyAiFgsaTKwBGgALo1Wpg0ud6PvqW0Xr5kVRQDvtvFbtSJiBjAjXd9AcufGtva7Hrg+a71+8bOZ5bITWnBtxgnOzHJrlBOcmRVQLbXgsjyqJUkXSfpO+n1/SWXvHjazYsv2oFblk2CWJxluA44HLki/vwXc2m4RmVlVS6ZLyvbq50rL0kX9VEQcI2k+QET8MX19oJntgoJgS4GmS3o3fWI/ACT1gCpoe5pZRSQtuNpIAVkS3L8BvwJ6SrqeZHaRb7drVGZW1aqh+5lFlmdRfyGpnuTGOwHnRITfbG+2i4oqGV/LotUEJ2l/4M/AI6VlEbGyPQMzs+rUfJGhFmTpoj7G+y+f+QgwAFhKMqumme1iAthSlBt9I+KI0u/pTCJfaWF3M9sFFKkF9wERMU/Sse0RjJlVv6KNwX2j5OtuwDHAunaLyMyqWjIGVxuytOA+VrLeQDIm92D7hGNmtaAQLbj0Bt+PRsTf7aR4zKzKBdBYG/mt5QQnqWNENHh6cjMrFcCWArTgZpOMty2QNAV4ANjUvDEiHmrn2MysChVtDK4bsIHkHQzN98MF4ARntosqQoLrmV5BfZb3E1uz2mifmlmbK0oLrgPwUbbjZatmVmw1f5EBWBMR399pkZhZTShKC84vKDWzD0leG1gbyiW4bb6X0Mx2bcl9cLXR/in34ufXd2YgZlY7itBFNTP7kACaar0FZ2bWklppwWV5baCZ2XsixLsZl3IkfUTSbEkLJS2WdG1a3k3SE5KWpZ97lxxztaTlkpZK+mxrsTrBmVkuzV3ULEsrNgPDIuJI4ChguKTjgKuA6RExEJiefkfSYGAkyWziw4Hb0glBWuQEZ2a5tUWCi8Sf0q+7p0sAI4CJaflE4Jx0fQQwKSI2R8QKYDkwtNw5nODMLJfkRl9lWoDukuaWLBeX1iWpg6QFwFrgiYj4HdArItYApJ890937Ai+XHL4qLWuRLzKYWW5N2R/VWh8RQ1raGBGNwFGSugK/knR4mbpyPzbqBGdmubTHbSIR8YakGSRja69J6h0RayT1JmndQdJi26/ksH7A6nL1uotqZvmEaGjaLdNSjqQeacsNSZ2B04HngSnA6HS30cDD6foUYKSkOkkDgIEk81a2yC04M8ulDVtwvYGJ6ZXQ3YDJEfGopFnAZEljgZXA+QARsVjSZGAJyfthLk27uC1ygjOz3KINElxE/B44ehvlG2jhWfiIuB64Pus5nODMLDc/qmVmhRTZbuKtCk5wZpZbYysXEKqFE5yZ5RK0zRjczuAEZ2a5uYtqZsUUcgvOzIormpzgzKyAPAZnZsUV0NToq6hmVkgegzOzAvMYnJkVUwA10oKrjY50Dbniiit49tlnWbRoEffeey91dXUceeSRzJo1i/nz5zNnzhyOPfbYSoe5y3vzjTcYM/IijjviGI7/xCeZ88zvALjj1h/zqcOP5sSjjuV7V38bgJUvvkS/vXpwyrEncMqxJ/DNSy+vZOgVF0A0ZVsqrd1acJLuBs4E1kZEuVk6C6NPnz5cdtllDB48mHfeeYf777+fkSNHcuGFF3LttdcydepUzjjjDH74wx9y6qmnVjrcXdo13/x7hn3mdP5z0j1s2bKFt//8Z56a8ST/75HHeLL+Gerq6li3dt17+/c/YAAz5vy2ghFXl1oZg2vPFtxPSWbn3KV07NiRzp0706FDB/bYYw9Wr15NRLDnnnsCsNdee7F6ddlJSK2dvbVxI7Oe+i0XjUnmVOzUqRN7de3KT2+/k8v/7hvU1dUB0KNnj0qGWb1CRONumZZKa7cIIuJJ4PX2qr8arV69mgkTJrBy5UrWrFnDm2++yRNPPMEVV1zBTTfdxMqVK5kwYQJXX311pUPdpb244kX26dGdr395PKcOPZHLx1/Kpk2b+N9ly5k187d85i9O5azThzNvbv17x6x88SVOHXoiZ50+nFlPz6xg9FWiKeNSYRVPsZIubn7jTqVj2VFdu3ZlxIgRDBgwgD59+tClSxdGjRrFJZdcwpVXXsn+++/PlVdeyV133VXpUHdpDQ0N/H7+AsZcPI7fzJ5Jlz268G83/QsNDQ28+cc3mPbUf3PtDdcx7sLRRAS9eu/LguVL+M3smfzghzfwldFjeWvjxkr/jMoJoEnZlgqreIKLiNsjYki5N+/UitNPP50VK1awfv16GhoaeOihhzjhhBMYPXo0Dz30EAAPPPAAQ4eWfZWjtbM+ffvSp19fPjk0udhz1l+NYOH8BfTp25fPn3M2kjjm2CHstttubFi/nrq6Orrtsw8ARx1zNP0PGMDyZcsr+RMqLiLbUmkVT3BFsnLlSo477jg6d+4MwGmnncZzzz3H6tWrOfnkkwEYNmwYy5Ytq2SYu7xe+/aib7++LFv6BwCe/M3/cMihgzjj7DN5asb/ALD8D8vY8u4W9unenfXr1tHYmEz9/+ILK3hh+f/Sf0D/CkVfJWqkBef74NrQ7Nmz+eUvf8m8efNoaGhg/vz53H777cyfP5+bb76Zjh078s4773DxxRe3Xpm1qxv+dQLj/2Yc727ZwscH9OeWO/6DPbp04bKLv8pfHD2U3Tt14t/v/AmSmPX0b7nx2uvo2LEju3XowIRbfsTe3bpV+idUTgCNlU9eWSjaqR0p6T7gFKA78Brw3YgoO/gkqQoatZbH+s1vVToEy+G0409iQf28HcpOu3ftGnv/xcmZ9l332JT6Sg4/tVsLLiIuaK+6zayCgqq4QpqFu6hmlp8TnJkVVo0MJjnBmVk+zffB1QAnODPLJ0ANtdGEc4Izs/xqI7/5Rl8z2w5t8CyqpP0k/UbSc5IWS7o8Le8m6QlJy9LPvUuOuVrScklLJX22tTCd4Mwsn+bbRHb8YfsG4JsRcShwHHCppMHAVcD0iBgITE+/k24bCRxGMlPRbZI6lDuBE5yZ5dcU2ZYyImJNRMxL198CngP6AiOAieluE4Fz0vURwKSI2BwRK4DlQNkHuz0GZ2a5Kft9cN23mino9oi4/UP1Sf2Bo4HfAb0iYg0kSVBSz3S3vsAzJYetSsta5ARnZvkE0Jj5KsP61h7VkvRR4EHgiojYKLV4C8q2NpQNxAnOzHJTK93PzPVIu5Mkt19ExENp8WuSeqett97A2rR8FbBfyeH9gLLTY3sMzszyyToZXCsTeShpqt0FPBcR/1KyaQowOl0fDTxcUj5SUp2kAcBAYHa5c7gFZ2b5tU0L7kTgS8AiSQvSsmuAG4HJksYCK4HzASJisaTJwBKSK7CXRkRjuRM4wZlZLqJtuqgR8TTbHlcDOK2FY64Hrs96Dic4M8sngMbamE7ECc7Mcmr9Hrdq4QRnZvkEqBreKJOBE5yZ5ecWnJkVVngMzsyKKDwGZ2YFpsayt59VDSc4M8sp3EU1s4IK3EU1swJzC87MisldVDMrqoBwF9XMiimgqaHSQWTiBGdm+TW5i2pmRRQQHoMzs2LyRQYzKzInODMroiAIX2Qws0LyGJyZFVc4wZlZgTnBmVkxuQVnZgXmBGdmhRQRNPkqqpkVVeAWnJkVksfgzKzAaiXB7VbpAMystgRJgsuytEbS3ZLWSnq2pKybpCckLUs/9y7ZdrWk5ZKWSvpsa/U7wZlZTkFTxiWDnwLDtyq7CpgeEQOB6el3JA0GRgKHpcfcJqlDucqd4Mwsn4CmpoZMS6tVRTwJvL5V8QhgYro+ETinpHxSRGyOiBXAcmBoufo9BmdmuQRBU/arqN0lzS35fntE3N7KMb0iYg1ARKyR1DMt7ws8U7LfqrSsRU5wZpZbjosM6yNiSBudVtsKpdwB7qKaWW5tOAa3La9J6g2Qfq5Ny1cB+5Xs1w9YXa4iJzgzyyUImqIp07KdpgCj0/XRwMMl5SMl1UkaAAwEZperyF1UM8utMRrbpB5J9wGnkIzVrQK+C9wITJY0FlgJnA8QEYslTQaWAA3ApRHlA1FE9bzfUNI64KVKx9EOugPrKx2E5VLUf2cfj4geO1KBpKkkfz5ZrI+IrW8D2WmqKsEVlaS5bTjQajuB/50Vg8fgzKywnODMrLCc4HaO1m5stOrjf2cF4DE4Mysst+DMrLCc4MyssJzg2pGk4em8VcslXVXpeKx125qfzGqXE1w7SeepuhU4AxgMXJDOZ2XV7ad8eH4yq1FOcO1nKLA8Il6IiC3AJJL5rKyKtTA/mdUoJ7j20xd4ueR7q3NXmVnbcoJrP7nnrjKztuUE135yz11lZm3LCa79zAEGShogqRPJyzKmVDgms12KE1w7iYgG4GvANOA5YHJELK5sVNaadH6yWcAhklalc5JZjfKjWmZWWG7BmVlhOcGZWWE5wZlZYTnBmVlhOcGZWWE5wdUQSY2SFkh6VtIDkvbYgbp+Kum8dP3OchMBSDpF0gnbcY4XJX3o7UstlW+1z59ynut7kr6VN0YrNie42vJ2RBwVEYcDW4DxpRvTGUxyi4hxEbGkzC6nALkTnFmlOcHVrqeAg9LW1W8k3QssktRB0k2S5kj6vaSvACjx75KWSHoM6NlckaQZkoak68MlzZO0UNJ0Sf1JEumVaevxLyX1kPRgeo45kk5Mj91H0uOS5kv6Cdt+HvcDJP2XpHpJiyVdvNW2f05jmS6pR1p2oKSp6TFPSRrUFn+YVkx+s30NktSRZJ65qWnRUODwiFiRJok3I+JYSXXATEmPA0cDhwBHAL1I3g5+91b19gDuAE5K6+oWEa9L+jHwp4iYkO53L/CvEfG0pP1JntY4lOSt5E9HxPclfR74QMJqwd+m5+gMzJH0YERsALoA8yLim5K+k9b9NZKXwYyPiGWSPgXcBgzbjj9G2wU4wdWWzpIWpOtPAXeRdB1nR8SKtPwzwCeax9eAvYCBwEnAfRHRCKyW9N/bqP844MnmuiKipXnRTgcGS+810PaU9LH0HH+VHvuYpD9m+E2XSTo3Xd8vjXUD0ATcn5bfAzwk6aPp732g5Nx1Gc5huygnuNrydkQcVVqQ/o++qbQI+HpETNtqv8/R+nRNyrAPJEMbx0fE29uIJfOzf5JOIUmWx0fEnyXNAD7Swu6RnveNrf8MzFriMbjimQZcIml3AEkHS+oCPAmMTMfoegOnbuPYWcDJkgakx3ZLy98CPlay3+Mk3UXS/ZoTzgjLxm8AAADFSURBVJPAqLTsDGDvVmLdC/hjmtwGkbQgm+0GNLdCLyTp+m4EVkg6Pz2HJB3ZyjlsF+YEVzx3koyvzUtfnPITkpb6r4BlwCLgP4D/2frAiFhHMm72kKSFvN9FfAQ4t/kiA3AZMCS9iLGE96/mXgucJGkeSVd5ZSuxTgU6Svo98APgmZJtm4DDJNWTjLF9Py0fBYxN41uMp4G3MjybiJkVlltwZlZYTnBmVlhOcGZWWE5wZlZYTnBmVlhOcGZWWE5wZlZY/x/3Decr0xQ+7AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get predictions\n",
    "preds = gs_cvec_nb.predict(X_test)\n",
    "\n",
    "# Save confusion matrix values\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n",
    "\n",
    "# View confusion matrix\n",
    "\n",
    "display(plot_confusion_matrix(gs_cvec_nb, X_test, y_test, cmap='cubehelix', values_format='d'));\n",
    "plt.title('Confusion matrix')\n",
    "\n",
    "printmd('credit: NLP II: `CountVectorizer`, `TfidfVectorizer`, and Modeling lesson. _Authors: Dave Yerrington (SF), Justin Pounders (ATL), Riley Dallas (ATX), Matt Brems (DC), Noelle Brown (DEN)_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8763754045307444\n",
      "Misclassification: 0.12362459546925567\n",
      "Sensitivity: 0.8804780876494024\n",
      "Precision: 0.8678010471204188\n",
      "Specificity: 0.8724747474747475\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy\n",
    "\n",
    "acc = (tp + tn) / (tp + fp + tn + fn)\n",
    "print('Accuracy:', acc)\n",
    "\n",
    "# Calculate the misclassification rate\n",
    "\n",
    "misclass = (fp + fn) / (tp + fp + tn + fn)\n",
    "print('Misclassification:', misclass)\n",
    "\n",
    "# Calculate the sensitivity\n",
    "\n",
    "sens = tp / (tp + fn)\n",
    "print('Sensitivity:', sens)\n",
    "\n",
    "# Calculate the precision\n",
    "\n",
    "prec = tp / (tp + fp)\n",
    "print('Precision:', prec)\n",
    "\n",
    "# Calculate the specificity\n",
    "\n",
    "spec = tn / (tn + fp)\n",
    "print('Specificity:', spec)\n",
    "\n",
    "# credit: Heather Robinson at General Assembly  :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Update the scoreboard or not? These are artificially high scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Model # |     Model metrics     |  Score | Before preprocessing shape | train_test_split  | Value |   Pipeline  |        pipe_cvec_nb       | Pipe hyperparameters |                         Value set                         | GridsearchCV parameters | Value | GridsearchCV BEST parameters | Value  |\n",
    "|:-------:|:---------------------:|:------:|:--------------------------:|:-----------------:|:-----:|:-----------:|:-------------------------:|:--------------------:|:---------------------------------------------------------:|:-----------------------:|:-----:|:----------------------------:|--------|\n",
    "|    1    |       Best score      | 0.8389 |          (1800, 7)         |     test_size     |  0.33 | Transformer | 'cvec', CountVectorizer() |     max_features     | 'cvec__max_features': [1_000, 2_000, 3_000, 4_000, 5_000] | k-fold cross-validation |   5   | cvec__max_df                 | 0.98   |\n",
    "|    1    | |  |                            |      stratify     |   y   |  Estimator  |   'nb', MultinomialNB()   |        min_df        |                   'cvec__min_df': [1, 2]                  |                         |       | cvec__max_features           | 4000   |\n",
    "|    1    |   |  |                            |    random_state   |   42  |             |                           |        max_df        |                 'cvec__max_df': [.98, .99]                |                         |       | cvec__min_df                 | 1      |\n",
    "|    1    |                       |        |                            |                   |       |             |                           |      ngram_range     |             'cvec__ngram_range': [(1,1), (1,2)            |                         |       | cvec__ngram_range            | (1, 2) |\n",
    "|    1    |                       |        |                            |                   |       |             |                           |                      |                                                           |                         |       |                              |        |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline 1 Part 2\n",
    "\n",
    "**CountVectorizer (transformer)**:\n",
    "\n",
    "* Produces term frequencies by count \n",
    "\n",
    "\n",
    "**Multinomial Naive Bayes (estimator)**:\n",
    "\n",
    "* Fast modeling algorithm\n",
    "* Variables are positive integers\n",
    "* Assumes all variables are independent (which is not realistic in NLP, but this assumption is accepted anyway)\n",
    "\n",
    "**GridSearchCV parameter search**:\n",
    "\n",
    "* Comparing the grid searched and the best parameters from Pipeline 1 Part 1, I varied the range of the parameters to see what the search would come up with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set a pipeline up with two stages:\n",
    "# 1. CountVectorizer (transformer)\n",
    "# 2. Multinomial Naive Bayes (estimator)\n",
    "\n",
    "pipe_cvec_nb = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('nb', MultinomialNB())    # Naive Bayes\n",
    "])\n",
    "\n",
    "\n",
    "# Search over the following values of hyperparameters:\n",
    "# Maximum number of features fit\n",
    "# Minimum number of documents needed to include token\n",
    "# Check (individual tokens) and also check (individual tokens and 2-grams).\n",
    "\n",
    "pipe_cvec_nb_params = {\n",
    "    'cvec__max_features': [2_000, 4_000, 6_000],\n",
    "    'cvec__min_df': [1, 2],\n",
    "    'cvec__max_df': [.05, .1, .25, .4],\n",
    "    'cvec__ngram_range': [(1, 1), (1, 2)], \n",
    "    'cvec__stop_words': [None, 'english']\n",
    "}\n",
    "\n",
    "# Instantiate GridSearchCV.\n",
    "\n",
    "gs_cvec_nb = GridSearchCV(pipe_cvec_nb, \n",
    "                  param_grid = pipe_cvec_nb_params, \n",
    "                  cv=5)      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('nb', MultinomialNB())]),\n",
       "             param_grid={'cvec__max_df': [0.05, 0.1, 0.25, 0.4],\n",
       "                         'cvec__max_features': [2000, 4000, 6000],\n",
       "                         'cvec__min_df': [1, 2],\n",
       "                         'cvec__ngram_range': [(1, 1), (1, 2)],\n",
       "                         'cvec__stop_words': [None, 'english']})"
      ]
     },
     "execution_count": 161,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit GridSearch to data.\n",
    "gs_cvec_nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Evaluate the model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Grid searched:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': [2000, 4000, 6000],\n",
       " 'cvec__min_df': [1, 2],\n",
       " 'cvec__max_df': [0.05, 0.1, 0.25, 0.4],\n",
       " 'cvec__ngram_range': [(1, 1), (1, 2)],\n",
       " 'cvec__stop_words': [None, 'english']}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Best score**: 0.8749"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Best estimator / parameters:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cvec', CountVectorizer(max_df=0.25, max_features=6000)),\n",
       "                ('nb', MultinomialNB())])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.25,\n",
       " 'cvec__max_features': 6000,\n",
       " 'cvec__min_df': 1,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'cvec__stop_words': None}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printmd('**Grid searched:**')\n",
    "display(gs_cvec_nb.param_grid)\n",
    "printmd(f'**Best score**: {round(gs_cvec_nb.best_score_, 4)}')\n",
    "printmd('**Best estimator / parameters:**')\n",
    "display(gs_cvec_nb.best_estimator_)\n",
    "display(gs_cvec_nb.best_params_)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x17b68490220>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "credit: NLP II: `CountVectorizer`, `TfidfVectorizer`, and Modeling lesson. _Authors: Dave Yerrington (SF), Justin Pounders (ATL), Riley Dallas (ATX), Matt Brems (DC), Noelle Brown (DEN)_"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get predictions\n",
    "preds = gs_cvec_nb.predict(X_test)\n",
    "\n",
    "# Save confusion matrix values\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n",
    "\n",
    "# View confusion matrix\n",
    "\n",
    "display(plot_confusion_matrix(gs_cvec_nb, X_test, y_test, cmap='cubehelix', values_format='d'));\n",
    "plt.title('Confusion matrix')\n",
    "\n",
    "printmd('credit: NLP II: `CountVectorizer`, `TfidfVectorizer`, and Modeling lesson. _Authors: Dave Yerrington (SF), Justin Pounders (ATL), Riley Dallas (ATX), Matt Brems (DC), Noelle Brown (DEN)_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8770226537216829\n",
      "Misclassification: 0.12297734627831715\n",
      "Sensitivity: 0.8831341301460823\n",
      "Precision: 0.8670143415906127\n",
      "Specificity: 0.8712121212121212\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy\n",
    "\n",
    "acc = (tp + tn) / (tp + fp + tn + fn)\n",
    "print('Accuracy:', acc)\n",
    "\n",
    "# Calculate the misclassification rate\n",
    "\n",
    "misclass = (fp + fn) / (tp + fp + tn + fn)\n",
    "print('Misclassification:', misclass)\n",
    "\n",
    "# Calculate the sensitivity\n",
    "\n",
    "sens = tp / (tp + fn)\n",
    "print('Sensitivity:', sens)\n",
    "\n",
    "# Calculate the precision\n",
    "\n",
    "prec = tp / (tp + fp)\n",
    "print('Precision:', prec)\n",
    "\n",
    "# Calculate the specificity\n",
    "\n",
    "spec = tn / (tn + fp)\n",
    "print('Specificity:', spec)\n",
    "\n",
    "# credit: Heather Robinson at General Assembly  :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline 2\n",
    "\n",
    "**CountVectorizer (transformer)**:\n",
    "\n",
    "**TF-IDF (transformer)**:\n",
    "\n",
    "\n",
    "\n",
    "**Logistic Regression (estimator)**:\n",
    "\n",
    "* Relatively interpretable results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-25-5c938e2b4c5d>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mcvec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCountVectorizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstop_words\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'english'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m pd.DataFrame(cvec.fit_transform(X_train).to_dense(),\n\u001b[0m\u001b[0;32m      3\u001b[0m             columns = cvec.get_feature_names())\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mmax_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1198\u001b[1;33m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0m\u001b[0;32m   1199\u001b[0m                                           self.fixed_vocabulary_)\n\u001b[0;32m   1200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m     97\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mdecoder\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 99\u001b[1;33m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    100\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0manalyzer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    101\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0manalyzer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mdecode\u001b[1;34m(self, doc)\u001b[0m\n\u001b[0;32m    206\u001b[0m             \u001b[0mA\u001b[0m \u001b[0mstring\u001b[0m \u001b[0mof\u001b[0m \u001b[0municode\u001b[0m \u001b[0msymbols\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \"\"\"\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minput\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'filename'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'rb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m                 \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfh\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\generic.py\u001b[0m in \u001b[0;36m__nonzero__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1324\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1325\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__nonzero__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1326\u001b[1;33m         raise ValueError(\n\u001b[0m\u001b[0;32m   1327\u001b[0m             \u001b[1;34mf\"The truth value of a {type(self).__name__} is ambiguous. \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1328\u001b[0m             \u001b[1;34m\"Use a.empty, a.bool(), a.item(), a.any() or a.all().\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": [
    "cvec = CountVectorizer(X_train, stop_words = 'english')\n",
    "pd.DataFrame(cvec.fit_transform(X_train).to_dense(),\n",
    "            columns = cvec.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set up another pipeline\n",
    "# 1. CountVectorizer (transformer)\n",
    "# 2. TfidfVectorizer (transformer)\n",
    "# 3. LogisticRegression (estimator)\n",
    "\n",
    "pipe_log_reg_with_cvec_tfidf = Pipeline([\n",
    "    ('cvec', CountVectorizer(lowercase = False)),\n",
    "#     ('tvec', TfidfVectorizer(lowercase = False)),\n",
    "    ('log_reg', LogisticRegression())\n",
    "])\n",
    "\n",
    "# Search over the following values of hyperparameters:\n",
    "# Maximum number of features fit\n",
    "# Minimum number of documents needed to include token\n",
    "# Maximum number of documents needed to include token\n",
    "# Check (individual tokens) and also check (individual tokens and 2-grams).\n",
    "\n",
    "# *****************************************************************************************************************\n",
    "# solver_list = ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga']\n",
    "# params = dict(solver=solver_list)\n",
    "# log_reg = LogisticRegression(C=1, n_jobs=-1, random_state=34)\n",
    "# clf = GridSearchCV(log_reg, params, cv=5)\n",
    "# clf.fit(X_train, y_train)\n",
    "# scores = clf.cv_results_['mean_test_score']\n",
    "\n",
    "# for score, solver in zip(scores, solver_list):\n",
    "#     print(f\"  {solver} {score:.3f}\" )\n",
    "\n",
    "# ref: https://towardsdatascience.com/dont-sweat-the-solver-stuff-aea7cddc3451\n",
    "# *****************************************************************************************************************\n",
    "\n",
    "pipe_log_reg_with_cvec_tfidf_params = {\n",
    "    'cvec__max_features': [1_000, 3_000, 5_000],\n",
    "    'cvec__min_df': [1, 2],\n",
    "    'cvec__max_df': [.98, .99],\n",
    "    'cvec__ngram_range': [(1,1), (2,1)],\n",
    "    'cvec__stop_words': [None, 'english'],\n",
    "#     'tvec__max_features': [3_000, 5_000],\n",
    "#     'tvec__stop_words': [None, 'english'],\n",
    "#     'tvec__ngram_range': [(1,1), (1,2)],\n",
    "    'log_reg__C': [.001, .01, .1, 1],\n",
    "    'log_reg__penalty': ['l1', 'l2'],\n",
    "    'log_reg__max_iter': [50, 75, 100],\n",
    "    'log_reg__random_state': [42], \n",
    "    'log_reg__solver': ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga']\n",
    "}\n",
    "\n",
    "# Instantiate GridSearchCV.\n",
    "\n",
    "gs_log_reg_with_cvec_tfidf = GridSearchCV(pipe_log_reg_with_cvec_tfidf, # what object are we optimizing?\n",
    "                  param_grid = pipe_log_reg_with_cvec_tfidf_params, # what parameters values are we searching?\n",
    "                  cv = 5)                                           # 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cvec', CountVectorizer(lowercase=False)),\n",
       "                ('log_reg', LogisticRegression())])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit GridSearch to data.\n",
    "pipe_log_reg_with_cvec_tfidf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Grid searched:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': [1000, 3000, 5000],\n",
       " 'cvec__min_df': [1, 2],\n",
       " 'cvec__max_df': [0.98, 0.99],\n",
       " 'cvec__ngram_range': [(1, 1), (2, 1)],\n",
       " 'cvec__stop_words': [None, 'english'],\n",
       " 'log_reg__C': [0.001, 0.01, 0.1, 1],\n",
       " 'log_reg__penalty': ['l1', 'l2'],\n",
       " 'log_reg__max_iter': [50, 75, 100],\n",
       " 'log_reg__random_state': [42],\n",
       " 'log_reg__solver': ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga']}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_score_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-9a789d8292e3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprintmd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'**Grid searched:**'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgs_log_reg_with_cvec_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprintmd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'**Best score**: {round(gs_log_reg_with_cvec_tfidf.best_score_, 4)}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprintmd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'**Best estimator / parameters:**'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgs_log_reg_with_cvec_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_score_'"
     ]
    }
   ],
   "source": [
    "printmd('**Grid searched:**')\n",
    "display(gs_log_reg_with_cvec_tfidf.param_grid)\n",
    "printmd(f'**Best score**: {round(gs_log_reg_with_cvec_tfidf.best_score_, 4)}')\n",
    "printmd('**Best estimator / parameters:**')\n",
    "display(gs_log_reg_with_cvec_tfidf.best_estimator_)\n",
    "display(gs_log_reg_with_cvec_tfidf.best_params_)\n",
    "\n",
    "pd.DataFrame(gs_log_reg_with_cvec_tfidf.cv_results_).sort_values('rank_test_score').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline 3\n",
    "\n",
    "**TfidfVectorizer (transformer)**\n",
    "\n",
    "\n",
    "\n",
    "**Multinomial Naive Bayes (estimator)**:\n",
    "\n",
    "* Fast modeling algorithm\n",
    "* Variables are positive integers\n",
    "* Assumes all variables are independent (which is not realistic in NLP, but this assumption is accepted anyway)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set a pipeline up with two stages:\n",
    "# 1. TfidfVectorizer (transformer)\n",
    "# 2. Multinomial Naive Bayes (estimator)\n",
    "\n",
    "pipe_tvec_nb = Pipeline([\n",
    "    ('tvec', TfidfVectorizer()),   # TfidfVectorizer uses natural log, not as interpretable as CountVectorizer\n",
    "    ('nb', MultinomialNB())    # Naive Bayes\n",
    "])\n",
    "\n",
    "\n",
    "# Search over the following values of hyperparameters:\n",
    "# Maximum number of features fit\n",
    "# Minimum number of documents needed to include token\n",
    "# Maximum number of documents needed to include token\n",
    "# Check (individual tokens) and also check (individual tokens and 2-grams).\n",
    "\n",
    "pipe_tvec_nb_params = {\n",
    "    'tvec__max_features': [2_000, 3_000, 4_000, 5_000],\n",
    "    'tvec__stop_words': [None, 'english'],\n",
    "    'tvec__ngram_range': [(1,1), (1,2)]\n",
    "}\n",
    "\n",
    "# Instantiate GridSearchCV.\n",
    "\n",
    "gs_tvec_nb = GridSearchCV(pipe_tvec_nb, # what object are we optimizing?\n",
    "                  param_grid = pipe_tvec_nb_params, # what parameters values are we searching?\n",
    "                  cv = 5)      # 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('tvec', TfidfVectorizer()), ('nb', MultinomialNB())])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit GridSearch to data.\n",
    "pipe_tvec_nb.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Grid searched:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'tvec__max_features': [2000, 3000, 4000, 5000],\n",
       " 'tvec__stop_words': [None, 'english'],\n",
       " 'tvec__ngram_range': [(1, 1), (1, 2)]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "AttributeError",
     "evalue": "'GridSearchCV' object has no attribute 'best_score_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-196-85319eebdbd6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mprintmd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'**Grid searched:**'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgs_tvec_nb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mprintmd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'**Best accuracy score**: {round(gs_tvec_nb.best_score_, 4)}'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprintmd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'**Best estimator / parameters:**'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mdisplay\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgs_tvec_nb\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GridSearchCV' object has no attribute 'best_score_'"
     ]
    }
   ],
   "source": [
    "printmd('**Grid searched:**')\n",
    "display(gs_tvec_nb.param_grid)\n",
    "printmd(f'**Best accuracy score**: {round(gs_tvec_nb.best_score_, 4)}')\n",
    "printmd('**Best estimator / parameters:**')\n",
    "display(gs_tvec_nb.best_estimator_)\n",
    "display(gs_tvec_nb.best_params_)\n",
    "\n",
    "pd.DataFrame(gs_tvec_nb.cv_results_).sort_values('rank_test_score').head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "credit: NLP II: `CountVectorizer`, `TfidfVectorizer`, and Modeling lesson. _Authors: Dave Yerrington (SF), Justin Pounders (ATL), Riley Dallas (ATX), Matt Brems (DC), Noelle Brown (DEN)_"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get predictions\n",
    "preds = gs_tvec_nb.predict(X_test)\n",
    "\n",
    "# Save confusion matrix values\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n",
    "\n",
    "# View confusion matrix\n",
    "\n",
    "plot_confusion_matrix(gs_tvec_nb, X_test, y_test, cmap='cubehelix', values_format='d');\n",
    "plt.title('Confusion matrix')\n",
    "\n",
    "printmd('credit: NLP II: `CountVectorizer`, `TfidfVectorizer`, and Modeling lesson. _Authors: Dave Yerrington (SF), Justin Pounders (ATL), Riley Dallas (ATX), Matt Brems (DC), Noelle Brown (DEN)_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8400673400673401\n",
      "Misclassification: 0.15993265993265993\n",
      "Sensitivity: 0.8534201954397395\n",
      "Precision: 0.8397435897435898\n",
      "Specificity: 0.8257839721254355\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy\n",
    "\n",
    "acc = (tp + tn) / (tp + fp + tn + fn)\n",
    "print('Accuracy:', acc)\n",
    "\n",
    "# Calculate the misclassification rate\n",
    "\n",
    "misclass = (fp + fn) / (tp + fp + tn + fn)\n",
    "print('Misclassification:', misclass)\n",
    "\n",
    "# Calculate the sensitivity\n",
    "\n",
    "sens = tp / (tp + fn)\n",
    "print('Sensitivity:', sens)\n",
    "\n",
    "# Calculate the precision\n",
    "\n",
    "prec = tp / (tp + fp)\n",
    "print('Precision:', prec)\n",
    "\n",
    "# Calculate the specificity\n",
    "\n",
    "spec = tn / (tn + fp)\n",
    "print('Specificity:', spec)\n",
    "\n",
    "def metrics(y_test, y_predict, pred_proba):\n",
    "    print('Accuracy score %s ' % accuracy_score(y_test, y_predict), '\\n')\n",
    "    print('----------------------------------------------------------------')\n",
    "    print(pd.DataFrame(confusion_matrix(y_test, y_predict), \n",
    "                            index=['Not Actual Disaster', 'Actual Disaster'], \n",
    "                            columns=['Predicted Not Actual Disaster', 'Predicted Disaster']), '\\n')\n",
    "    print('-----------------------------------------------------------------')\n",
    "    print(classification_report(y_test, y_predict))\n",
    "    print('-----------------------------------------------------------------')\n",
    "    print('ROC_AUC SCORE %s ' %roc_auc_score(y_test, pred_proba))\n",
    "    \n",
    "# credit: Heather Robinson :-)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline 4\n",
    "\n",
    "\n",
    "\n",
    "**CountVectorizer (transformer)**:\n",
    "\n",
    "\n",
    "\n",
    "**Random Forest (estimator)**:\n",
    "\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set a pipeline up with two stages:\n",
    "# 1. CountVectorizer (transformer)\n",
    "# 2. Random Forest (estimator)\n",
    "\n",
    "pipe_cvec_rf = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('rf', RandomForestClassifier()) \n",
    "])\n",
    "\n",
    "\n",
    "# Search over the following values of hyperparameters:\n",
    "# Maximum number of features fit\n",
    "# Minimum number of documents needed to include token\n",
    "# Maximum number of documents needed to include token\n",
    "# Check (individual tokens) and also check (individual tokens and 2-grams).\n",
    "\n",
    "pipe_cvec_rf_params = {\n",
    "    'cvec__max_features': [5_000],\n",
    "    'cvec__min_df': [1],\n",
    "    'cvec__max_df': [.75],\n",
    "    'cvec__ngram_range': [(1,1)],\n",
    "    'rf__n_estimators': [100, 200], \n",
    "    'rf__max_depth': [None, .25],\n",
    "    'rf__max_features': ['auto', 2_000]\n",
    "}\n",
    "\n",
    "# Instantiate GridSearchCV.\n",
    "\n",
    "gs_cvec_rf = GridSearchCV(pipe_cvec_rf,             # the object we are optimizing\n",
    "                  param_grid = pipe_cvec_rf_params, # the parameters values we are searching\n",
    "                  cv = 5)                           # Number of folds in cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('rf', RandomForestClassifier())]),\n",
       "             param_grid={'cvec__max_df': [0.75], 'cvec__max_features': [5000],\n",
       "                         'cvec__min_df': [1], 'cvec__ngram_range': [(1, 1)],\n",
       "                         'rf__max_depth': [None, 0.25],\n",
       "                         'rf__max_features': ['auto', 2000],\n",
       "                         'rf__n_estimators': [100, 200]})"
      ]
     },
     "execution_count": 262,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit GridSearch to data.\n",
    "gs_cvec_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Grid searched:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_features': [5000],\n",
       " 'cvec__min_df': [1],\n",
       " 'cvec__max_df': [0.75],\n",
       " 'cvec__ngram_range': [(1, 1)],\n",
       " 'rf__n_estimators': [100, 200],\n",
       " 'rf__max_depth': [None, 0.25],\n",
       " 'rf__max_features': ['auto', 2000]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Best accuracy score**: 0.832"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Best estimator / parameters:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(steps=[('cvec', CountVectorizer(max_df=0.75, max_features=5000)),\n",
       "                ('rf', RandomForestClassifier())])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'cvec__max_df': 0.75,\n",
       " 'cvec__max_features': 5000,\n",
       " 'cvec__min_df': 1,\n",
       " 'cvec__ngram_range': (1, 1),\n",
       " 'rf__max_depth': None,\n",
       " 'rf__max_features': 'auto',\n",
       " 'rf__n_estimators': 100}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Accuracy score on train set:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Accuracy score on test set:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8426640926640927"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printmd('**Grid searched:**')\n",
    "display(gs_cvec_rf.param_grid)\n",
    "printmd(f'**Best accuracy score**: {round(gs_cvec_rf.best_score_, 4)}')\n",
    "printmd('**Best estimator / parameters:**')\n",
    "display(gs_cvec_rf.best_estimator_)\n",
    "display(gs_cvec_rf.best_params_)\n",
    "printmd('**Accuracy score on train set:**')\n",
    "display(gs_cvec_rf.score(X_train, y_train))\n",
    "printmd('**Accuracy score on test set:**')\n",
    "display(gs_cvec_rf.score(X_test, y_test))\n",
    "\n",
    "\n",
    "# *****************************************************************\n",
    "# cross val .8912 best score, .99 train, .89 test\n",
    "# Grid searched:\n",
    "\n",
    "# {'cvec__max_features': [5000],\n",
    "#  'cvec__min_df': [1],\n",
    "#  'cvec__max_df': [0.75],\n",
    "#  'cvec__ngram_range': [(1, 1)],\n",
    "#  'rf__n_estimators': [100, 200],\n",
    "#  'rf__max_depth': [None, 0.25],\n",
    "#  'rf__max_features': ['auto', 2000]}\n",
    "# Best accuracy score: 0.8912\n",
    "\n",
    "# Best estimator / parameters:\n",
    "\n",
    "# Pipeline(steps=[('cvec', CountVectorizer(max_df=0.75, max_features=5000)),\n",
    "#                 ('rf', RandomForestClassifier(n_estimators=200))])\n",
    "# {'cvec__max_df': 0.75,\n",
    "#  'cvec__max_features': 5000,\n",
    "#  'cvec__min_df': 1,\n",
    "#  'cvec__ngram_range': (1, 1),\n",
    "#  'rf__max_depth': None,\n",
    "#  'rf__max_features': 'auto',\n",
    "#  'rf__n_estimators': 200}\n",
    "# Accuracy score on train set:\n",
    "\n",
    "# 0.9974473516273133\n",
    "# Accuracy score on test set:\n",
    "\n",
    "# 0.8964401294498382"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2101, 5000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2101,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1036, 5000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1036,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Accuracy score on train set:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Accuracy score on test set:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0.8426640926640927"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Instantiate CountVectorizer\n",
    "cvec = CountVectorizer(max_df = 0.75, max_features = 5_000, min_df = 1, ngram_range = (1, 1), stop_words = 'english')\n",
    "\n",
    "# Fit the features training data so the model learns the vocabulary; transform to create vectors from the vocabulary\n",
    "X_train_cvec = pd.DataFrame(cvec.fit_transform(X_train).todense(),\n",
    "                           columns = cvec.get_feature_names())\n",
    "\n",
    "# Fit the features test data so the model learns the vocabulary; \n",
    "X_test_cvec = pd.DataFrame(cvec.transform(X_test).todense(),\n",
    "                           columns = cvec.get_feature_names())\n",
    "\n",
    "# Check the shapes \n",
    "\n",
    "display(X_train_cvec.shape)\n",
    "display(y_train.shape)\n",
    "display(X_test_cvec.shape)\n",
    "display(y_test.shape)\n",
    "\n",
    "rf_ex_pipe = RandomForestClassifier(n_estimators = 200)\n",
    "\n",
    "rf_ex_pipe.fit(X_train_cvec, y_train)\n",
    "\n",
    "printmd('**Accuracy score on train set:**')\n",
    "display(gs_cvec_rf.score(X_train, y_train))\n",
    "printmd('**Accuracy score on test set:**')\n",
    "display(gs_cvec_rf.score(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's look into the most important features and set up for feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "features = X_train_cvec.columns\n",
    "importances = rf_ex_pipe.feature_importances_\n",
    "indices = np.argsort(importances)[-20:]\n",
    "\n",
    "plt.subplots(figsize = (6, 6))\n",
    "plt.barh(range(len(indices)), importances[indices], color = 'thistle')\n",
    "plt.yticks(range(len(indices)), [features[i] for i in indices]);\n",
    "plt.title('Top 20 feature importances in r/ science and r/ futurology', size = 12)\n",
    "plt.ylabel('Stemmed word', size = 11);\n",
    "\n",
    "# ref: https://www.analyticsvidhya.com/blog/2018/08/dimensionality-reduction-techniques-python/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# This SelectFromModel library is a meta-transformer for selecting features based on importance weights\n",
    "\n",
    "selected_from_model = SelectFromModel(estimator = RandomForestClassifier()).fit(X_train_cvec, y_train)\n",
    "\n",
    "# ref: https://scikit-learn.org/stable/modules/generated/sklearn.feature_selection.SelectFromModel.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aaa</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abil</th>\n",
       "      <th>abl</th>\n",
       "      <th>abnorm</th>\n",
       "      <th>abort</th>\n",
       "      <th>abov</th>\n",
       "      <th>absolut</th>\n",
       "      <th>absorb</th>\n",
       "      <th>abstin</th>\n",
       "      <th>abund</th>\n",
       "      <th>abus</th>\n",
       "      <th>academ</th>\n",
       "      <th>academi</th>\n",
       "      <th>academia</th>\n",
       "      <th>acceler</th>\n",
       "      <th>accept</th>\n",
       "      <th>access</th>\n",
       "      <th>accid</th>\n",
       "      <th>accident</th>\n",
       "      <th>accommod</th>\n",
       "      <th>accomplish</th>\n",
       "      <th>accord</th>\n",
       "      <th>account</th>\n",
       "      <th>accur</th>\n",
       "      <th>accuraci</th>\n",
       "      <th>achiev</th>\n",
       "      <th>acid</th>\n",
       "      <th>acoust</th>\n",
       "      <th>acquir</th>\n",
       "      <th>act</th>\n",
       "      <th>action</th>\n",
       "      <th>activ</th>\n",
       "      <th>actor</th>\n",
       "      <th>actual</th>\n",
       "      <th>acut</th>\n",
       "      <th>ad</th>\n",
       "      <th>adapt</th>\n",
       "      <th>add</th>\n",
       "      <th>addict</th>\n",
       "      <th>addit</th>\n",
       "      <th>adequ</th>\n",
       "      <th>...</th>\n",
       "      <th>yang</th>\n",
       "      <th>yanghai</th>\n",
       "      <th>yard</th>\n",
       "      <th>yarn</th>\n",
       "      <th>ychromosom</th>\n",
       "      <th>ye</th>\n",
       "      <th>year</th>\n",
       "      <th>yearold</th>\n",
       "      <th>years</th>\n",
       "      <th>yellowtail</th>\n",
       "      <th>yemen</th>\n",
       "      <th>yen</th>\n",
       "      <th>yesterday</th>\n",
       "      <th>yield</th>\n",
       "      <th>yo</th>\n",
       "      <th>yoghurtlik</th>\n",
       "      <th>yokohama</th>\n",
       "      <th>york</th>\n",
       "      <th>young</th>\n",
       "      <th>younger</th>\n",
       "      <th>youngster</th>\n",
       "      <th>youth</th>\n",
       "      <th>youtub</th>\n",
       "      <th>yr</th>\n",
       "      <th>yunan</th>\n",
       "      <th>zdisc</th>\n",
       "      <th>zealand</th>\n",
       "      <th>zebrafish</th>\n",
       "      <th>zeolit</th>\n",
       "      <th>zeptosecond</th>\n",
       "      <th>zero</th>\n",
       "      <th>zeroemiss</th>\n",
       "      <th>zhengzhou</th>\n",
       "      <th>zika</th>\n",
       "      <th>zinc</th>\n",
       "      <th>ziplin</th>\n",
       "      <th>zircon</th>\n",
       "      <th>zn</th>\n",
       "      <th>zombi</th>\n",
       "      <th>zone</th>\n",
       "      <th>zoonot</th>\n",
       "      <th>subreddit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3131</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3132</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3133</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3134</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3135</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2761 rows × 5001 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      aaa  abandon  abil  abl  abnorm  abort  abov  absolut  absorb  abstin  \\\n",
       "0     0.0      0.0   0.0  0.0     0.0    0.0   0.0      0.0     0.0     0.0   \n",
       "1     0.0      0.0   0.0  0.0     0.0    0.0   0.0      0.0     0.0     0.0   \n",
       "2     0.0      0.0   0.0  0.0     0.0    0.0   0.0      0.0     0.0     0.0   \n",
       "3     0.0      0.0   0.0  0.0     0.0    0.0   0.0      0.0     0.0     0.0   \n",
       "4     0.0      0.0   0.0  0.0     0.0    0.0   0.0      0.0     0.0     0.0   \n",
       "...   ...      ...   ...  ...     ...    ...   ...      ...     ...     ...   \n",
       "3131  NaN      NaN   NaN  NaN     NaN    NaN   NaN      NaN     NaN     NaN   \n",
       "3132  NaN      NaN   NaN  NaN     NaN    NaN   NaN      NaN     NaN     NaN   \n",
       "3133  NaN      NaN   NaN  NaN     NaN    NaN   NaN      NaN     NaN     NaN   \n",
       "3134  NaN      NaN   NaN  NaN     NaN    NaN   NaN      NaN     NaN     NaN   \n",
       "3135  NaN      NaN   NaN  NaN     NaN    NaN   NaN      NaN     NaN     NaN   \n",
       "\n",
       "      abund  abus  academ  academi  academia  acceler  accept  access  accid  \\\n",
       "0       0.0   0.0     0.0      0.0       0.0      0.0     0.0     0.0    0.0   \n",
       "1       0.0   0.0     0.0      0.0       0.0      0.0     0.0     0.0    0.0   \n",
       "2       0.0   0.0     0.0      0.0       0.0      0.0     0.0     0.0    0.0   \n",
       "3       0.0   0.0     0.0      0.0       0.0      0.0     0.0     0.0    0.0   \n",
       "4       0.0   0.0     0.0      0.0       0.0      0.0     0.0     0.0    0.0   \n",
       "...     ...   ...     ...      ...       ...      ...     ...     ...    ...   \n",
       "3131    NaN   NaN     NaN      NaN       NaN      NaN     NaN     NaN    NaN   \n",
       "3132    NaN   NaN     NaN      NaN       NaN      NaN     NaN     NaN    NaN   \n",
       "3133    NaN   NaN     NaN      NaN       NaN      NaN     NaN     NaN    NaN   \n",
       "3134    NaN   NaN     NaN      NaN       NaN      NaN     NaN     NaN    NaN   \n",
       "3135    NaN   NaN     NaN      NaN       NaN      NaN     NaN     NaN    NaN   \n",
       "\n",
       "      accident  accommod  accomplish  accord  account  accur  accuraci  \\\n",
       "0          0.0       0.0         0.0     0.0      0.0    0.0       0.0   \n",
       "1          0.0       0.0         0.0     0.0      0.0    0.0       0.0   \n",
       "2          0.0       0.0         0.0     0.0      0.0    0.0       0.0   \n",
       "3          0.0       0.0         0.0     0.0      0.0    0.0       0.0   \n",
       "4          0.0       0.0         0.0     0.0      0.0    0.0       0.0   \n",
       "...        ...       ...         ...     ...      ...    ...       ...   \n",
       "3131       NaN       NaN         NaN     NaN      NaN    NaN       NaN   \n",
       "3132       NaN       NaN         NaN     NaN      NaN    NaN       NaN   \n",
       "3133       NaN       NaN         NaN     NaN      NaN    NaN       NaN   \n",
       "3134       NaN       NaN         NaN     NaN      NaN    NaN       NaN   \n",
       "3135       NaN       NaN         NaN     NaN      NaN    NaN       NaN   \n",
       "\n",
       "      achiev  acid  acoust  acquir  act  action  activ  actor  actual  acut  \\\n",
       "0        0.0   0.0     0.0     0.0  0.0     0.0    0.0    0.0     0.0   0.0   \n",
       "1        0.0   0.0     0.0     0.0  0.0     0.0    0.0    0.0     0.0   0.0   \n",
       "2        0.0   0.0     0.0     0.0  0.0     0.0    0.0    0.0     0.0   0.0   \n",
       "3        0.0   0.0     0.0     0.0  0.0     0.0    0.0    0.0     0.0   0.0   \n",
       "4        0.0   0.0     0.0     0.0  0.0     0.0    0.0    0.0     0.0   0.0   \n",
       "...      ...   ...     ...     ...  ...     ...    ...    ...     ...   ...   \n",
       "3131     NaN   NaN     NaN     NaN  NaN     NaN    NaN    NaN     NaN   NaN   \n",
       "3132     NaN   NaN     NaN     NaN  NaN     NaN    NaN    NaN     NaN   NaN   \n",
       "3133     NaN   NaN     NaN     NaN  NaN     NaN    NaN    NaN     NaN   NaN   \n",
       "3134     NaN   NaN     NaN     NaN  NaN     NaN    NaN    NaN     NaN   NaN   \n",
       "3135     NaN   NaN     NaN     NaN  NaN     NaN    NaN    NaN     NaN   NaN   \n",
       "\n",
       "       ad  adapt  add  addict  addit  adequ  ...  yang  yanghai  yard  yarn  \\\n",
       "0     0.0    0.0  0.0     0.0    0.0    0.0  ...   0.0      0.0   0.0   0.0   \n",
       "1     0.0    0.0  0.0     0.0    0.0    0.0  ...   0.0      0.0   0.0   0.0   \n",
       "2     0.0    0.0  0.0     0.0    0.0    0.0  ...   0.0      0.0   0.0   0.0   \n",
       "3     0.0    0.0  0.0     0.0    0.0    0.0  ...   0.0      0.0   0.0   0.0   \n",
       "4     0.0    0.0  0.0     0.0    0.0    0.0  ...   0.0      0.0   0.0   0.0   \n",
       "...   ...    ...  ...     ...    ...    ...  ...   ...      ...   ...   ...   \n",
       "3131  NaN    NaN  NaN     NaN    NaN    NaN  ...   NaN      NaN   NaN   NaN   \n",
       "3132  NaN    NaN  NaN     NaN    NaN    NaN  ...   NaN      NaN   NaN   NaN   \n",
       "3133  NaN    NaN  NaN     NaN    NaN    NaN  ...   NaN      NaN   NaN   NaN   \n",
       "3134  NaN    NaN  NaN     NaN    NaN    NaN  ...   NaN      NaN   NaN   NaN   \n",
       "3135  NaN    NaN  NaN     NaN    NaN    NaN  ...   NaN      NaN   NaN   NaN   \n",
       "\n",
       "      ychromosom   ye  year  yearold  years  yellowtail  yemen  yen  \\\n",
       "0            0.0  0.0   0.0      0.0    0.0         0.0    0.0  0.0   \n",
       "1            0.0  0.0   0.0      0.0    0.0         0.0    0.0  0.0   \n",
       "2            0.0  0.0   0.0      0.0    0.0         0.0    0.0  0.0   \n",
       "3            0.0  0.0   0.0      0.0    0.0         0.0    0.0  0.0   \n",
       "4            0.0  0.0   0.0      0.0    0.0         0.0    0.0  0.0   \n",
       "...          ...  ...   ...      ...    ...         ...    ...  ...   \n",
       "3131         NaN  NaN   NaN      NaN    NaN         NaN    NaN  NaN   \n",
       "3132         NaN  NaN   NaN      NaN    NaN         NaN    NaN  NaN   \n",
       "3133         NaN  NaN   NaN      NaN    NaN         NaN    NaN  NaN   \n",
       "3134         NaN  NaN   NaN      NaN    NaN         NaN    NaN  NaN   \n",
       "3135         NaN  NaN   NaN      NaN    NaN         NaN    NaN  NaN   \n",
       "\n",
       "      yesterday  yield   yo  yoghurtlik  yokohama  york  young  younger  \\\n",
       "0           0.0    0.0  0.0         0.0       0.0   0.0    0.0      0.0   \n",
       "1           0.0    0.0  0.0         0.0       0.0   0.0    0.0      0.0   \n",
       "2           0.0    0.0  0.0         0.0       0.0   0.0    0.0      0.0   \n",
       "3           0.0    0.0  0.0         0.0       0.0   0.0    0.0      0.0   \n",
       "4           0.0    0.0  0.0         0.0       0.0   0.0    0.0      0.0   \n",
       "...         ...    ...  ...         ...       ...   ...    ...      ...   \n",
       "3131        NaN    NaN  NaN         NaN       NaN   NaN    NaN      NaN   \n",
       "3132        NaN    NaN  NaN         NaN       NaN   NaN    NaN      NaN   \n",
       "3133        NaN    NaN  NaN         NaN       NaN   NaN    NaN      NaN   \n",
       "3134        NaN    NaN  NaN         NaN       NaN   NaN    NaN      NaN   \n",
       "3135        NaN    NaN  NaN         NaN       NaN   NaN    NaN      NaN   \n",
       "\n",
       "      youngster  youth  youtub   yr  yunan  zdisc  zealand  zebrafish  zeolit  \\\n",
       "0           0.0    0.0     0.0  0.0    0.0    0.0      0.0        0.0     0.0   \n",
       "1           0.0    0.0     0.0  0.0    0.0    0.0      0.0        0.0     0.0   \n",
       "2           0.0    0.0     0.0  0.0    0.0    0.0      0.0        0.0     0.0   \n",
       "3           0.0    0.0     0.0  0.0    0.0    0.0      0.0        0.0     0.0   \n",
       "4           0.0    0.0     0.0  0.0    0.0    0.0      0.0        0.0     0.0   \n",
       "...         ...    ...     ...  ...    ...    ...      ...        ...     ...   \n",
       "3131        NaN    NaN     NaN  NaN    NaN    NaN      NaN        NaN     NaN   \n",
       "3132        NaN    NaN     NaN  NaN    NaN    NaN      NaN        NaN     NaN   \n",
       "3133        NaN    NaN     NaN  NaN    NaN    NaN      NaN        NaN     NaN   \n",
       "3134        NaN    NaN     NaN  NaN    NaN    NaN      NaN        NaN     NaN   \n",
       "3135        NaN    NaN     NaN  NaN    NaN    NaN      NaN        NaN     NaN   \n",
       "\n",
       "      zeptosecond  zero  zeroemiss  zhengzhou  zika  zinc  ziplin  zircon  \\\n",
       "0             0.0   0.0        0.0        0.0   0.0   0.0     0.0     0.0   \n",
       "1             0.0   0.0        0.0        0.0   0.0   0.0     0.0     0.0   \n",
       "2             0.0   0.0        0.0        0.0   0.0   0.0     0.0     0.0   \n",
       "3             0.0   0.0        0.0        0.0   0.0   0.0     0.0     0.0   \n",
       "4             0.0   0.0        0.0        0.0   0.0   0.0     0.0     0.0   \n",
       "...           ...   ...        ...        ...   ...   ...     ...     ...   \n",
       "3131          NaN   NaN        NaN        NaN   NaN   NaN     NaN     NaN   \n",
       "3132          NaN   NaN        NaN        NaN   NaN   NaN     NaN     NaN   \n",
       "3133          NaN   NaN        NaN        NaN   NaN   NaN     NaN     NaN   \n",
       "3134          NaN   NaN        NaN        NaN   NaN   NaN     NaN     NaN   \n",
       "3135          NaN   NaN        NaN        NaN   NaN   NaN     NaN     NaN   \n",
       "\n",
       "       zn  zombi  zone  zoonot  subreddit  \n",
       "0     0.0    0.0   0.0     0.0        0.0  \n",
       "1     0.0    0.0   0.0     0.0        NaN  \n",
       "2     0.0    0.0   0.0     0.0        0.0  \n",
       "3     0.0    0.0   0.0     0.0        0.0  \n",
       "4     0.0    0.0   0.0     0.0        NaN  \n",
       "...   ...    ...   ...     ...        ...  \n",
       "3131  NaN    NaN   NaN     NaN        1.0  \n",
       "3132  NaN    NaN   NaN     NaN        1.0  \n",
       "3133  NaN    NaN   NaN     NaN        1.0  \n",
       "3134  NaN    NaN   NaN     NaN        1.0  \n",
       "3135  NaN    NaN   NaN     NaN        1.0  \n",
       "\n",
       "[2761 rows x 5001 columns]"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.concat([X_train_cvec, y_train], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**The strongest coefficients start from the top in the table below.**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Holding all else constant, the effect of the stemmed word `studi` is a 0.046 increase in classification ability.**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coeff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>studi</th>\n",
       "      <td>0.050425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suggest</th>\n",
       "      <td>0.015479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>covid</th>\n",
       "      <td>0.013561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>research</th>\n",
       "      <td>0.012980</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>increas</th>\n",
       "      <td>0.009638</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new</th>\n",
       "      <td>0.009087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ai</th>\n",
       "      <td>0.008677</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>power</th>\n",
       "      <td>0.008580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dure</th>\n",
       "      <td>0.007330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>robot</th>\n",
       "      <td>0.006877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sarscov</th>\n",
       "      <td>0.006749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>effect</th>\n",
       "      <td>0.006039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>women</th>\n",
       "      <td>0.005735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>world</th>\n",
       "      <td>0.005674</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peopl</th>\n",
       "      <td>0.005657</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>futur</th>\n",
       "      <td>0.005067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>men</th>\n",
       "      <td>0.004976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reduc</th>\n",
       "      <td>0.004787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>0.004697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>elon</th>\n",
       "      <td>0.004475</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Coeff\n",
       "studi     0.050425\n",
       "suggest   0.015479\n",
       "covid     0.013561\n",
       "research  0.012980\n",
       "increas   0.009638\n",
       "new       0.009087\n",
       "ai        0.008677\n",
       "power     0.008580\n",
       "dure      0.007330\n",
       "robot     0.006877\n",
       "sarscov   0.006749\n",
       "effect    0.006039\n",
       "women     0.005735\n",
       "world     0.005674\n",
       "peopl     0.005657\n",
       "futur     0.005067\n",
       "men       0.004976\n",
       "reduc     0.004787\n",
       "like      0.004697\n",
       "elon      0.004475"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's look at the strongest coefficients by feature\n",
    "\n",
    "printmd('**The strongest coefficients start from the top in the table below.**')\n",
    "printmd('**Holding all else constant, the effect of the stemmed word `studi` is a 0.046 increase in classification ability.**')\n",
    "\n",
    "feature_importances_df = (pd.DataFrame(selected_from_model.estimator_.feature_importances_,\n",
    "                                      index = X_train_cvec.columns, columns = ['Coeff'])\n",
    "                                      .sort_values('Coeff', ascending = False))\n",
    "display(feature_importances_df[:20])\n",
    "\n",
    "# Export to combine with other top 100 features that I'm able to pull from other models\n",
    "feature_importances_df[:100].to_csv('../data/feature_selection/feature_selection_randomforest.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sklearn.metrics._plot.confusion_matrix.ConfusionMatrixDisplay at 0x17b03b05280>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "credit: NLP II: `CountVectorizer`, `TfidfVectorizer`, and Modeling lesson. _Authors: Dave Yerrington (SF), Justin Pounders (ATL), Riley Dallas (ATX), Matt Brems (DC), Noelle Brown (DEN)_"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAATgAAAEWCAYAAADy2YssAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3de5RV5X3/8fcHMIiaRBFQoqQoQgRMHMSMJmnFaFSktoqrNqhx2cZ4aSFqc+lP8+uKxpR4qZekSdRKtGJMpGSZCwHFUOMlJjEKcnHwBj+hOkrkYojRWGDmfH9/7D16JDNn9oY5c87Z83m59ppznr33s7+D8vW57P1sRQRmZkXUr9YBmJlVixOcmRWWE5yZFZYTnJkVlhOcmRWWE5yZFZYTXMFIGiTpp5J+L+kHO1HPmZJ+1pOx1Yqkv5D0bK3jsN4n3wdXG5LOAD4HHAz8AVgGzIyIR3ay3rOAzwIfjYi2nQ60zkkKYHRErK51LFZ/3IKrAUmfA74OfA3YB3g/cCNwcg9U/2fAc30huWUhaUCtY7AaighvvbgB7wVeB06rcMxAkgT4crp9HRiY7jsaaAU+D6wH1gF/n+77CrAV2JZe4xzgcuDOsrpHAgEMSL//HfA8SStyDXBmWfkjZed9FHgc+H3686Nl+x4Evgr8Mq3nZ8CQLn63jvj/uSz+U4ApwHPAq8CXyo5vBn4NbE6P/RbwrnTfw+nv8kb6+36yrP7/A/wW+G5HWXrOqPQah6Xf3wdsBI6u9X8b3np+q3kAfW0DJgNtHQmmi2OuAB4FhgFDgV8BX033HZ2efwWwS5oY/gjsle7fPqF1meCA3YHXgA+k+4YD49PPbyU4YDDwO+Cs9LzT0+97p/sfBP4fMAYYlH6/qovfrSP+L6fxnwtsAL4PvBsYD/wvcGB6/ETgyPS6I4GngYvL6gvgoE7qv5rkfxSDyhNcesy5aT27AfcB19b6vwtv1dncRe19ewMbo3IX8kzgiohYHxEbSFpmZ5Xt35bu3xYR95C0Xj6wg/GUgEMkDYqIdRGxspNj/hJYFRHfjYi2iLgLeAb4q7Jj/jMinouIN4G5QFOFa24jGW/cBswBhgDfiIg/pNdfCXwIICKWRMSj6XXXAv8BTMrwO10WEVvSeN4hImYBq4DfkCT1/9tNfdagnOB63yZgSDdjQ+8D/qfs+/+kZW/VsV2C/COwR95AIuINkm7dBcA6SQskHZwhno6Y9iv7/tsc8WyKiPb0c0cCeqVs/5sd50saI2m+pN9Keo1k3HJIhboBNkTE/3ZzzCzgEOCbEbGlm2OtQTnB9b5fk3TBTqlwzMskkwUd3p+W7Yg3SLpiHfYt3xkR90XEcSQtmWdI/uJ3F09HTC/tYEx53EQS1+iIeA/wJUDdnFPx1gBJe5CMa94KXC5pcE8EavXHCa6XRcTvScafvi3pFEm7SdpF0omSrkkPuwv4F0lDJQ1Jj79zBy+5DDhK0vslvRe4tGOHpH0k/bWk3YEtJF3d9k7quAcYI+kMSQMkfRIYB8zfwZjyeDfJOOHraevyH7bb/wpwYM46vwEsiYjPAAuAm3c6SqtLTnA1EBHXk9wD9y8kA+wvAjOAH6eH/CuwGFgBPAk8kZbtyLUWAf+V1rWEdyalfiSzsS+TzCxOAv6xkzo2ASelx24imQE9KSI27khMOX0BOINkdnYWye9S7nJgtqTNkv62u8oknUwy0XNBWvQ54DBJZ/ZYxFY3fKOvmRWWW3BmVlhOcGZWWE5wZlZYTnBmVlh19SDykCFDYuTIkbUOw3JYsmRJrUOwnCKiu/sIK5o8eXJs3JhtAn3JkiX3RcTknbnezqirBDdy5EgWL15c6zAsB2mn/q5YA9q4cWPmv6fpfZw1U1cJzswaQ6lBbi9zgjOzXIKgPTp74KX+OMGZWW6lyo/71g0nODPLJYBSlGodRiZOcGaWm1twZlZMEZ5kMLNiCtyCM7OCCqDdLTgzKyp3Uc2ssJzgzKyQgvAYnJkVV6kx8puXSzKzfCKSSYYsWxaS+ktaKml++n2wpEWSVqU/9yo79lJJqyU9K+mE7up2gjOz3EqRbcvoIuDpsu+XAPdHxGjg/vQ7ksYB04DxJC8OulFS/0oVO8GZWS7Jo1qRaeuOpP2BvwS+U1Z8MjA7/Tybt98hfDIwJyK2RMQaYDXQXKl+Jzgzyy1HC26IpMVl23nbVfV1ktdQlj/cuk9ErANIfw5Ly/cjecVmh9a0rEueZDCz3HLMMWyMiMM72yHpJGB9RCyRdHSGujpbXbViKE5wZpZL0kXtkao+Bvy1pCnArsB7JN0JvCJpeESskzQcWJ8e3wqMKDt/f5KXlnfJXVQzyyegvZRtq1hNxKURsX9EjCSZPPh5RHwKmAecnR52NvCT9PM8YJqkgZIOAEYDj1W6hltwZpZLD7bgunIVMFfSOcALwGkAEbFS0lzgKaANmB5ReWlhJzgzy62nn9SKiAeBB9PPm4BjuzhuJjAza71OcGaWT7573GrKCc7McmuQZ+2d4Mwsn6D7CYR64QRnZrm5BWdmxRQQ0dk9t/XHCc7McgncgjOzAmuQ16I6wZlZfm7BmVkxBZTaPQZnZkXlFpyZFVEgz6KaWUGFJxnMrMjcRTWzonILzsyKKSA8i2pmheUuqpkVUvDOd2DVMSc4M8vPCc7MisqPaplZMQXJK18agBOcmeXnFpyZFZInGcysyOQEZ2aF1SAJrl+tAzCzBhM5tgok7SrpMUnLJa2U9JW0/HJJL0lalm5Tys65VNJqSc9KOqG7UN2CM7Pc1NYjswxbgGMi4nVJuwCPSLo33XdDRFz7jmtK44BpwHjgfcB/SxoTEe1dXcAtODPLp2OSIctWqZrE6+nXXdKtUuY8GZgTEVsiYg2wGmiudA0nODPLKVAp2wYMkbS4bDuvvCZJ/SUtA9YDiyLiN+muGZJWSLpN0l5p2X7Ai2Wnt6ZlXXKC6yHt7e1MmDCBk046CYAvfvGLHHzwwXzoQx9i6tSpbN68GYC1a9cyaNAgmpqaaGpq4oILLqhl2AZceOGFPPnkk7S0tHDRRRcBcNlll9Ha2srSpUtZunQpJ554Yo2jrDPZx+A2RsThZdst76gmoj0imoD9gWZJhwA3AaOAJmAdcF16eGdLmFTsK1c1wUmanA4GrpZ0STWvVWvf+MY3GDt27FvfjzvuOFpaWlixYgVjxozhyiuvfGvfqFGjWLZsGcuWLePmm2+uRbiWGj9+POeeey7Nzc0ceuihnHTSSRx00EEA3HDDDUyYMIEJEyZw7733dlNTHxLkacFlqzJiM/AgMDkiXkkTXwmYxdvd0FZgRNlp+wMvV6q3aglOUn/g28CJwDjg9HSQsHBaW1tZsGABn/nMZ94qO/744xkwIJnDOfLII2ltba1VeFbB2LFjefTRR3nzzTdpb2/noYceYurUqbUOq/6VIttWgaShkvZMPw8CPgE8I2l42WFTgZb08zxgmqSBkg4ARgOPVbpGNVtwzcDqiHg+IrYCc0gGCQvn4osv5pprrqFfv87/OG+77bZ3dHHWrFnDhAkTmDRpEr/4xS96K0zrREtLC0cddRSDBw9m0KBBTJkyhREjkkbCjBkzWL58Obfeeit77rlnjSOtH4pkFjXL1o3hwAOSVgCPk4zBzQeukfRkWv5x4J8AImIlMBd4ClgITK80gwrVTXCZBgQlndcxALlhw4YqhlMd8+fPZ9iwYUycOLHT/TNnzmTAgAGceeaZAAwfPpwXXniBpUuXcv3113PGGWfw2muv9WbIVuaZZ57h6quvZtGiRSxcuJDly5fT1tbGTTfdxKhRo2hqamLdunVcd9113VfWZ+SaZOi6logVETEhIj4UEYdExBVp+VkR8cG0/K8jYl3ZOTMjYlREfCAiuh03qGaCyzQgGBG3dAxADh06tIrhVMcvf/lL5s2bx8iRI5k2bRo///nP+dSnPgXA7NmzmT9/Pt/73veQkj+OgQMHsvfeewMwceJERo0axXPPPVez+C1pYU+cOJFJkybx6quvsmrVKtavX0+pVCIimDVrFs3NFe9G6FsCFJFpq7VqJrjcA4KN6Morr6S1tZW1a9cyZ84cjjnmGO68804WLlzI1Vdfzbx589htt93eOn7Dhg20tyet6ueff55Vq1Zx4IEH1ip8Azr+xzpixAhOPfVU7rrrLvbdd9+39k+dOpWWlpauTu+bSqVsW41V80mGx4HR6WDgSyR3IJ9RxevVlRkzZrBlyxaOO+44IJlouPnmm3n44Yf58pe/zIABA+jfvz8333wzgwcPrnG0fdvdd9/N3nvvzbZt25g+fTqbN2/mjjvuoKmpiYhg7dq1nH/++bUOs67kmSGtJUUVm5HpM2RfB/oDt0XEzErHH3744bF48eKqxWM9r6PrbY0jdvK19GNHHRp3XHlfpmObPzl8SUQcvjPX2xlVfRY1Iu4B7qnmNcysdwlQg7wY1Q/bm1k+0ThdVCc4M8sp6mICIQsnODPLJ0BOcGZWVPVwj1sWTnBmlk8EamuM9wY6wZlZLiI8i2pmBeYxODMrpAhUqriIR91wgjOz3NxFNbPichfVzAopArVvq3UUmTjBmVlOAe6imllRqfJK4XXDCc7M8okAz6KaWWG5i2pmhRQlaN9a6ygycYIzs1ySBS/dRTWzQgpwgjOzIgqgm/ct141qvjbQzAopbcFl2SqQtKukxyQtl7RS0lfS8sGSFklalf7cq+ycSyWtlvSspBO6i9QJzszyiZ5JcMAW4JiIOBRoAiZLOhK4BLg/IkYD96ffkTSO5PWj44HJwI2S+le6gBOcmeUURGlrpq1iLYnX06+7pFsAJwOz0/LZwCnp55OBORGxJSLWAKuB5krXcIIzs/yyt+CGSFpctp1XXo2k/pKWAeuBRRHxG2CfiFgHkP4clh6+H/Bi2emtaVmXPMlgZjnlmkXdWOnFz5HMVjRJ2hP4kaRDKtTV2QurK74cwgnOzPKJIKJn38kQEZslPUgytvaKpOERsU7ScJLWHSQtthFlp+0PvFypXndRzSynIGjPtFUiaWjackPSIOATwDPAPODs9LCzgZ+kn+cB0yQNlHQAMBp4rNI1umzBSfomFZp/EXFhxejNrKCi2wmEjIYDs9OZ0H7A3IiYL+nXwFxJ5wAvAKcBRMRKSXOBp4A2YHp0c0NepS7q4p74DcysWIIg2PkuakSsACZ0Ur4JOLaLc2YCM7Neo8sEFxGzy79L2j0i3shasZkVV2GeZJD0EUlPAU+n3w+VdGPVIzOzOtUzY3C9Icskw9eBE4BNABGxHDiqmkGZWX2LaM+01Vqm20Qi4kXpHbeg1D5yM6uJICg1SArIkuBelPRRICS9C7iQtLtqZn1QBKXYUusoMsmS4C4AvkHySMRLwH3A9GoGZWb1LCjVQfczi24TXERsBM7shVjMrAFEOsnQCLLMoh4o6aeSNkhaL+knkg7sjeDMrD6VaM+01VqWWdTvA3NJ7jp+H/AD4K5qBmVm9SwKleAUEd+NiLZ0u5NunuA3s+IKoBTtmbZaq/Qs6uD04wOSLgHmkPxunwQW9EJsZlaXSrTT+K8NXEKS0DpugDu/bF8AX61WUGZWvwJor4PuZxaVnkU9oDcDMbNGUawbfUlX2RwH7NpRFhF3VCsoM6tfAcVJcJIuA44mSXD3ACcCjwBOcGZ9UrFacH8DHAosjYi/l7QP8J3qhmVm9SoItrGt1mFkkiXBvRkRJUltkt5Dsj66b/Q166OSLmqp1mFkkiXBLU7XTZ9FMrP6Ot2sg25mRRaNP4vaISL+Mf14s6SFwHvSpYbNrA9Klktq8BacpMMq7YuIJ6oTkpnVuyK04K6rsC+AY3o4FpYsWcJ2C2tandvS3hh3tFviI81H7nQdyVoiDd6Ci4iP92YgZtYYAtjWA2/V6g1+s72Z5VKIFpyZWVfa1RgJLstySWZmb+lowWXZKpE0QtIDkp6WtFLSRWn55ZJekrQs3aaUnXOppNWSnpV0QnexZnlUSyRLlh8YEVdIej+wb0T4XjizPqqHuqhtwOcj4glJ7waWSFqU7rshIq4tP1jSOGAaMJ5k8d3/ljQmKryfMEsL7kbgI8Dp6fc/AN/O93uYWVEkyyVle/VzxXoi1nXcbhYRfyB5W99+FU45GZgTEVsiYg2wGmiudI0sCe6IiJgO/G8ayO+Ad2U4z8wKKAi20p5pA4ZIWly2nddZnZJGAhOA36RFMyStkHSbpL3Ssv2AF8tOa6VyQsw0ybBNUn/SZcolDYUGmUIxsx6XtOAyp4CNEXF4pQMk7QHcDVwcEa9JuolkQd2OhXWvAz7N24vvbh9Ol7K04P4d+BEwTNJMkqWSvpbhPDMrqJ7oogJI2oUkuX0vIn4IEBGvRER7RJRInoHv6Ia2AiPKTt8feLlS/VmeRf2epCXAsSQZ9JSI8JvtzfqoyJi8upNOYN4KPB0R15eVD4+IdenXqUBL+nke8H1J15NMMoymm4U/ssyivh/4I/DT8rKIeCHH72JmBdExydADPgacBTwpaVla9iXgdElN6aXWkr4PJiJWSpoLPEUyAzu90gwqZBuDW8DbL5/ZFTgAeJZkqtbM+pgAtvbAjb4R8Qidj6vdU+GcmcDMrNfI0kX9YPn3dJWR87s43Mz6gB5qwVVd7ke10pvyPlyNYMys/vXUGFxvyDIG97myr/2Aw4ANVYvIzOpaMgbXGLK04N5d9rmNZEzu7uqEY2aNoBAtuPQG3z0i4ou9FI+Z1bkA2hsjv1VcsnxARLRVWrrczPqeALYWoAX3GMl42zJJ84AfAG907Oy469jM+paijcENBjaRvIOh4364AJzgzPqoIiS4YekMagtvJ7YOjdE+NbMeV5QWXH9gD3bgCX4zK7aGn2QA1kXEFb0WiZk1hKK04PyCUjP7E8lrAxtDpQR3bK9FYWYNI7kPrjHaP5Ve/PxqbwZiZo2jCF1UM7M/EUCp0VtwZmZdcQvOzAopQmxzC87MishdVDMrNCc4Myuk5EZfJzgzK6hSAR7VMjP7Ex6DM7PiCtFW6lfrKDJpjCjNrG50tOCybJVIGiHpAUlPS1op6aK0fLCkRZJWpT/3KjvnUkmrJT0r6YTuYnWCM7PcIpRp60Yb8PmIGAscCUyXNA64BLg/IkYD96ffSfdNI3np/GTgxvS9MV1ygjOz3HqiBRcR6yLiifTzH4Cngf2Ak4HZ6WGzgVPSzycDcyJiS0SsAVYDzZWu4TE4M8slMiSvvCSNBCYAvwH2iYh1ybVinaRh6WH7AY+WndaalnXJCc7McmvPPskwRNLisu+3RMQt5QdI2oPkXcsXR8RrUpfJM/fq4k5wZpZLQJbxtQ4bI+LwrnZK2oUkuX2v7E19r0ganrbehgPr0/JWYETZ6fsDL1e6uMfgzCy3HppFFXAr8HREXF+2ax5wdvr5bOAnZeXTJA2UdAAwmuT1pl1yC87M8sk2Q5rFx4CzgCclLUvLvgRcBcyVdA7wAnAaQESslDQXeIpkBnZ6RFRcuckJzsxyi9LOJ7iIeISu3/3S6SsTImImMDPrNZzgzCyXnGNwNeUEZ2b5BJTaG2P43gnOzHLqsTG4qnOCM7PcemIMrjc4wZlZPgE0SAuuMTrSDeTCCy/kySefpKWlhYsuugiAyy67jNbWVpYuXcrSpUs58cQTaxylAbS3t9M88cOc8lfJo46X/PMlfHDcIUxsOozTTv0bNm/eDMCmTZs4/tjjGPyevbjosxfVMuS6EECUsm21VrUEJ+k2SesltVTrGvVm/PjxnHvuuTQ3N3PooYdy0kkncdBBBwFwww03MGHCBCZMmMC9995b40gN4Jv//k0OPvjgt74f+4ljWbpiGUuWPcHoMaO55qqrAdh111257CuXc9U1V9cq1LrTQ6uJVF01W3C3kyxp0meMHTuWRx99lDfffJP29nYeeughpk6dWuuwrBOtra3ce8+9/P05n36r7Ljjj2PAgGTU5ogjjuCl1pcA2H333fnYn3+MXXfdtSax1p0Q0d4v01ZrVYsgIh4GXq1W/fWopaWFo446isGDBzNo0CCmTJnCiBHJo3MzZsxg+fLl3Hrrrey55541jtS+8E+f58qrrqRfv87/Ctz+n7dzwuRu11Psu0oZtxqreYqVdJ6kxdutONCQnnnmGa6++moWLVrEwoULWb58OW1tbdx0002MGjWKpqYm1q1bx3XXXVfrUPu0BfMXMHTYMA6beFin+6/62pUMGDCA0888o5cjaxABlJRtq7GaJ7iIuCUiDq+04kAjue2225g4cSKTJk3i1VdfZdWqVaxfv55SqUREMGvWLJqbK67RZ1X261/9igU/nc+YA0dz1hmf4sEHHuDvzkqe7f7u7Du4Z8E9zL7zDios29PnRWTbaq3mCa5ohg4dCsCIESM49dRTueuuu9h3333f2j916lRaWvrMvEtd+tevzeT5F9bw3POr+O737+Toj3+c2787m/sW3se1/3Ytd//4h+y22261DrO+NUgLzvfB9bC7776bvffem23btjF9+nQ2b97MHXfcQVNTExHB2rVrOf/882sdpnXi4gsvZuuWLUw5IbmNp/mII/j2Td8GYMyBo3nttdfYunUrP/3JPBYsXMDYceNqGW7tBNBe++SVhaJK7UhJdwFHA0OAV4DLIuLWbs6pg0at5bGlfWutQ7AcPtJ8JEsWL9mp7LTLnnvGXn8+KdOxGxbMW1LL4aeqteAi4vRq1W1mNRTUxQxpFu6imll+TnBmVlgNMpjkBGdm+XTcB9cAnODMLJ8AtTVGE84Jzszya4z85gRnZjvAkwxmVki+TcTMCq3UGH1UJzgzy00N0oLzw/Zmlk8A7ZFt60ZnK39LulzSS5KWpduUsn2XSlot6VlJ3S7Y5xacmeWmnuui3g58C7hju/IbIuLad1xTGgdMA8YD7wP+W9KYiGjvqnK34Mwsn6yLwWVYyCPnyt8nA3MiYktErAFWAxUXV3SCM7P8SpFt23EzJK1Iu7B7pWX7AS+WHdOalnXJCc7MchFJFzXLBgzpeCVBup2X4RI3AaOAJmAd0LHGf2fPh1XMoh6DM7N8AmjPPI26Me96cBHxSsdnSbOA+enXVmBE2aH7Ay9XqsstODPLKWP3dAe7qJKGl32dCnTMsM4DpkkaKOkAYDTwWKW63IIzs3wC1EMrgZev/C2pFbgMOFpSU3Il1gLnA0TESklzgaeANmB6pRlUcIIzsx3RQ7eJdLHyd5evNoiImcDMrPU7wZlZftEYjzI4wZlZPrHTt4D0Gic4M8tN7RWHvuqGE5yZ5RTuoppZQQXuoppZgbkFZ2bF5C6qmRVVQLiLambFFFBqq3UQmTjBmVl+JXdRzayIAsJjcGZWTJ5kMLMic4IzsyIKgvAkg5kVksfgzKy4wgnOzArMCc7MisktODMrMCc4MyukiKDkWVQzK6rALTgzKySPwZlZgTnBmVkhBY2T4PrVOgAzazRBKePWHUm3SVovqaWsbLCkRZJWpT/3Ktt3qaTVkp6VdEJ39TvBmVk+AaVSW6Ytg9uByduVXQLcHxGjgfvT70gaB0wDxqfn3Cipf6XKneDMLJcgKGX8p9u6Ih4GXt2u+GRgdvp5NnBKWfmciNgSEWuA1UBzpfo9BmdmuVV5DG6fiFiXXCfWSRqWlu8HPFp2XGta1iUnODPLLcv4WmqIpMVl32+JiFt28LLqpKxiIE5wZpZLEJSyt+A2RsThOS/xiqThaettOLA+LW8FRpQdtz/wcqWKPAZnZrm1R3umbQfNA85OP58N/KSsfJqkgZIOAEYDj1WqqN5acBuB/6l1EFUwhOR3K5yB/d9V6xCqpaj/zv6sB+q4j+TPJ4uKf4aS7gKOJunKtgKXAVcBcyWdA7wAnAYQESslzQWeAtqA6RGVs6giGuMFro1M0uIdaKZbDfnfWTG4i2pmheUEZ2aF5QTXO3Z0Wtxqx//OCsBjcGZWWG7BmVlhOcGZWWE5wVWRpMnpsi6rJV1S63ise50t32ONywmuStJlXL4NnAiMA05Pl3ux+nY7f7p8jzUoJ7jqaQZWR8TzEbEVmEOy3IvVsS6W77EG5QRXPfsBL5Z973ZpFzPrWU5w1ZN7aRcz61lOcNWTe2kXM+tZTnDV8zgwWtIBkt5Fspb8vBrHZNanOMFVSUS0ATNIlpZ5GpgbEStrG5V1J12+59fAByS1pkv2WIPyo1pmVlhuwZlZYTnBmVlhOcGZWWE5wZlZYTnBmVlhOcE1EEntkpZJapH0A0m77URdt0v6m/TzdyotBCDpaEkf3YFrrJX0J29f6qp8u2Nez3mtyyV9IW+MVmxOcI3lzYhoiohDgK3ABeU70xVMcouIz0TEUxUOORrIneDMas0JrnH9AjgobV09IOn7wJOS+kv6N0mPS1oh6XwAJb4l6SlJC4BhHRVJelDS4ennyZKekLRc0v2SRpIk0n9KW49/IWmopLvTazwu6WPpuXtL+pmkpZL+g86fx30HST+WtETSSknnbbfvujSW+yUNTctGSVqYnvMLSQf3xB+mFVO9vfjZMpA0gGSduYVpUTNwSESsSZPE7yPiw5IGAr+U9DNgAvAB4IPAPiQvz71tu3qHArOAo9K6BkfEq5JuBl6PiGvT474P3BARj0h6P8nTGmNJXtr7SERcIekvgXckrC58Or3GIOBxSXdHxCZgd+CJiPi8pC+ndc8geRnMBRGxStIRwI3AMTvwx2h9gBNcYxkkaVn6+RfArSRdx8ciYk1afjzwoY7xNeC9wGjgKOCu9E3gL0v6eSf1Hwk83FFXRHS1LtongHHSWw2090h6d3qNU9NzF0j6XYbf6UJJU9PPI9JYNwEl4L/S8juBH0raI/19f1B27YEZrmF9lBNcY3kzIprKC9K/6G+UFwGfjYj7tjtuCt0v16QMx0AytPGRiHizk1gyP/sn6WiSZPmRiPijpAeBXbs4PNLrbt7+z8CsKx6DK577gH+QtAuApDGSdgceBqalY3TDgY93cu6vgUmSDkjPHZyW/wF4d9lxPyPpLpIe15FwHgbOTMtOBPbqJtb3Ar9Lk9vBJC3IDv2AjlboGSRd39eANZJOS68hSYd2cw3rw5zgiuc7JONrT6QvTvkPkpb6j4BVwJPATbz9ZA4AAACASURBVMBD258YERtIxs1+KGk5b3cRfwpM7ZhkAC4EDk8nMZ7i7dncrwBHSXqCpKv8QjexLgQGSFoBfBV4tGzfG8B4SUtIxtiuSMvPBM5J41uJl4G3CryaiJkVlltwZlZYTnBmVlhOcGZWWE5wZlZYTnBmVlhOcGZWWE5wZlZY/x9eBxqdRIBh/AAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get predictions\n",
    "preds = rf_ex_pipe.predict(X_test_cvec)\n",
    "\n",
    "# Save confusion matrix values\n",
    "tn, fp, fn, tp = confusion_matrix(y_test, preds).ravel()\n",
    "\n",
    "# View confusion matrix\n",
    "\n",
    "display(plot_confusion_matrix(rf_ex_pipe, X_test_cvec, y_test, cmap='cubehelix', values_format='d'));\n",
    "plt.title('Confusion matrix')\n",
    "\n",
    "printmd('credit: NLP II: `CountVectorizer`, `TfidfVectorizer`, and Modeling lesson. _Authors: Dave Yerrington (SF), Justin Pounders (ATL), Riley Dallas (ATX), Matt Brems (DC), Noelle Brown (DEN)_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8166023166023166\n",
      "Misclassification: 0.1833976833976834\n",
      "Sensitivity: 0.8158914728682171\n",
      "Precision: 0.8158914728682171\n",
      "Specificity: 0.8173076923076923\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy\n",
    "\n",
    "acc = (tp + tn) / (tp + fp + tn + fn)\n",
    "print('Accuracy:', acc)\n",
    "\n",
    "# Calculate the misclassification rate\n",
    "\n",
    "misclass = (fp + fn) / (tp + fp + tn + fn)\n",
    "print('Misclassification:', misclass)\n",
    "\n",
    "# Calculate the sensitivity\n",
    "\n",
    "sens = tp / (tp + fn)\n",
    "print('Sensitivity:', sens)\n",
    "\n",
    "# Calculate the precision\n",
    "\n",
    "prec = tp / (tp + fp)\n",
    "print('Precision:', prec)\n",
    "\n",
    "# Calculate the specificity\n",
    "\n",
    "spec = tn / (tn + fp)\n",
    "print('Specificity:', spec)\n",
    "\n",
    "# credit: Heather Robinson at General Assembly  :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set a pipeline up with two stages:\n",
    "# 1. CountVectorizer (transformer)\n",
    "# 2. Random Forest (estimator)\n",
    "\n",
    "pipe_cvec_rf = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('rf', RandomForestClassifier()) \n",
    "])\n",
    "\n",
    "\n",
    "# Search over the following values of hyperparameters:\n",
    "# Maximum number of features fit\n",
    "# Minimum number of documents needed to include token\n",
    "# Maximum number of documents needed to include token\n",
    "# Check (individual tokens) and also check (individual tokens and 2-grams).\n",
    "\n",
    "pipe_cvec_rf_params = {\n",
    "    'cvec__max_features': [5_000],\n",
    "    'cvec__min_df': [1],\n",
    "    'cvec__max_df': [.75],\n",
    "    'cvec__ngram_range': [(1,1)],\n",
    "    'rf__n_estimators': [100, 200], \n",
    "    'rf__max_depth': [None, .25],\n",
    "    'rf__max_features': ['auto', 2_000]\n",
    "}\n",
    "\n",
    "# Instantiate GridSearchCV.\n",
    "\n",
    "gs_cvec_rf = GridSearchCV(pipe_cvec_rf,             # the object we are optimizing\n",
    "                  param_grid = pipe_cvec_rf_params, # the parameters values we are searching\n",
    "                  cv = 5)                           # Number of folds in cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('rf', RandomForestClassifier())]),\n",
       "             param_grid={'cvec__max_df': [0.75], 'cvec__max_features': [5000],\n",
       "                         'cvec__min_df': [1], 'cvec__ngram_range': [(1, 1)],\n",
       "                         'rf__max_depth': [None, 0.25],\n",
       "                         'rf__max_features': ['auto', 2000],\n",
       "                         'rf__n_estimators': [100, 200]})"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit GridSearch to data.\n",
    "gs_cvec_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pipeline 5\n",
    "\n",
    "\n",
    "\n",
    "**CountVectorizer (transformer)**:\n",
    "\n",
    "\n",
    "\n",
    "**Support Vector Machine (estimator)**:\n",
    "\n",
    "* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's set a pipeline up with two stages:\n",
    "# 1. CountVectorizer (transformer)\n",
    "# 2. Random Forest (estimator)\n",
    "\n",
    "pipe_cvec_rf = Pipeline([\n",
    "    ('cvec', CountVectorizer()),\n",
    "    ('rf', RandomForestClassifier()) \n",
    "])\n",
    "\n",
    "\n",
    "# Search over the following values of hyperparameters:\n",
    "# Maximum number of features fit\n",
    "# Minimum number of documents needed to include token\n",
    "# Maximum number of documents needed to include token\n",
    "# Check (individual tokens) and also check (individual tokens and 2-grams).\n",
    "\n",
    "pipe_cvec_rf_params = {\n",
    "    'cvec__max_features': [5_000],\n",
    "    'cvec__min_df': [1],\n",
    "    'cvec__max_df': [.75],\n",
    "    'cvec__ngram_range': [(1,1)],\n",
    "    'rf__n_estimators': [100, 200], \n",
    "    'rf__max_depth': [None, .25],\n",
    "    'rf__max_features': ['auto', 2_000]\n",
    "}\n",
    "\n",
    "# Instantiate GridSearchCV.\n",
    "\n",
    "gs_cvec_rf = GridSearchCV(pipe_cvec_rf,             # the object we are optimizing\n",
    "                  param_grid = pipe_cvec_rf_params, # the parameters values we are searching\n",
    "                  cv = 5)                           # Number of folds in cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=Pipeline(steps=[('cvec', CountVectorizer()),\n",
       "                                       ('rf', RandomForestClassifier())]),\n",
       "             param_grid={'cvec__max_df': [0.75], 'cvec__max_features': [5000],\n",
       "                         'cvec__min_df': [1], 'cvec__ngram_range': [(1, 1)],\n",
       "                         'rf__max_depth': [None, 0.25],\n",
       "                         'rf__max_features': ['auto', 2000],\n",
       "                         'rf__n_estimators': [100, 200]})"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fit GridSearch to data.\n",
    "gs_cvec_rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Break the pipe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2101, 6000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2101,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1036, 6000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1036,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Instantiate CountVectorizer\n",
    "cvec = CountVectorizer(max_df = 0.4, max_features = 6_000, min_df = 1, ngram_range = (1, 2), stop_words = 'english')\n",
    "\n",
    "# Fit the features training data so the model learns the vocabulary; transform to create vectors from the vocabulary\n",
    "X_train_cvec = pd.DataFrame(cvec.fit_transform(X_train).todense(),\n",
    "                           columns = cvec.get_feature_names())\n",
    "\n",
    "# Fit the features test data so the model learns the vocabulary; \n",
    "X_test_cvec = pd.DataFrame(cvec.transform(X_test).todense(),\n",
    "                           columns = cvec.get_feature_names())\n",
    "\n",
    "# Check the shapes \n",
    "\n",
    "display(X_train_cvec.shape)\n",
    "display(y_train.shape)\n",
    "display(X_test_cvec.shape)\n",
    "display(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2101, 6000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(2101,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1036, 6000)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1036,)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Instantiate the TfidfVectorizer transformer\n",
    "tvec = TfidfVectorizer(max_features = 6_000, stop_words = 'english', ngram_range = (1, 2)) \n",
    "\n",
    "# Fit the features training data so the model learns the vocabulary; transform to create vectors from the vocabulary\n",
    "X_train_tvec = pd.DataFrame(tvec.fit_transform(X_train).todense(),\n",
    "                           columns = tvec.get_feature_names())\n",
    "\n",
    "# Fit the features test data so the model learns the vocabulary; \n",
    "X_test_tvec = pd.DataFrame(tvec.transform(X_test).todense(),\n",
    "                           columns = tvec.get_feature_names())\n",
    "\n",
    "# Check the shapes \n",
    "\n",
    "display(X_train_tvec.shape)\n",
    "display(y_train.shape)\n",
    "display(X_test_tvec.shape)\n",
    "display(y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the model\n",
    "logreg = LogisticRegression()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'unit arab emir to launch spacecraft to moon in  '",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-d711c2ddbbc7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Fit the model to train data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mlogreg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Get accuracy scores for train and test data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mprintmd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34mf'**Accuracy score on train data: {logreg.score(X_train, y_train):.3f}**'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1340\u001b[0m             \u001b[0m_dtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1342\u001b[1;33m         X, y = self._validate_data(X, y, accept_sparse='csr', dtype=_dtype,\n\u001b[0m\u001b[0;32m   1343\u001b[0m                                    \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"C\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1344\u001b[0m                                    accept_large_sparse=solver != 'liblinear')\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    793\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[0;32m    796\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    596\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    599\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    795\u001b[0m               dtype='datetime64[ns]')\n\u001b[0;32m    796\u001b[0m         \"\"\"\n\u001b[1;32m--> 797\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    798\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m     \u001b[1;31m# ----------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\numpy_.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[0m_HANDLED_TYPES\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'unit arab emir to launch spacecraft to moon in  '"
     ]
    }
   ],
   "source": [
    "# Fit the model to train data\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Get accuracy scores for train and test data\n",
    "printmd(f'**Accuracy score on train data: {logreg.score(X_train, y_train):.3f}**')\n",
    "printmd(f'**Accuracy score on test data: {logreg.score(X_test, y_test):.3f}**')\n",
    "printmd('**The model is overfit**')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, estimator=LogisticRegression(),\n",
       "             param_grid={'C': [0.001, 0.01, 0.1, 1], 'penalty': ['l1', 'l2']})"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set new parameters\n",
    "params = { 'C': [.001, .01, .1, 1], \n",
    "              'penalty': ['l1', 'l2']}\n",
    "\n",
    "# Instantiate GridSearch cross-validation\n",
    "gs = GridSearchCV(logreg, params, cv = 5)\n",
    "\n",
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Accuracy score on train data: 0.993**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Accuracy score on test data: 0.823**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**The model is still overfit**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Best parameters:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'penalty': 'l2'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get accuracy scores for train and test data\n",
    "printmd(f'**Accuracy score on train data: {gs.score(X_train, y_train):.3f}**')\n",
    "printmd(f'**Accuracy score on test data: {gs.score(X_test, y_test):.3f}**')\n",
    "printmd('**The model is still overfit**')\n",
    "\n",
    "printmd('**Best parameters:**')\n",
    "display(gs.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'unit arab emir to launch spacecraft to moon in  '",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-222-5fbcd0cf69bc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_reg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mean_test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    763\u001b[0m             \u001b[0mrefit_start_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1340\u001b[0m             \u001b[0m_dtype\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1341\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1342\u001b[1;33m         X, y = self._validate_data(X, y, accept_sparse='csr', dtype=_dtype,\n\u001b[0m\u001b[0;32m   1343\u001b[0m                                    \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"C\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1344\u001b[0m                                    accept_large_sparse=solver != 'liblinear')\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    793\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    794\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 795\u001b[1;33m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[0;32m    796\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    797\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    596\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    597\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 598\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    599\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\series.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    795\u001b[0m               dtype='datetime64[ns]')\n\u001b[0;32m    796\u001b[0m         \"\"\"\n\u001b[1;32m--> 797\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    798\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m     \u001b[1;31m# ----------------------------------------------------------------------\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\pandas\\core\\arrays\\numpy_.py\u001b[0m in \u001b[0;36m__array__\u001b[1;34m(self, dtype)\u001b[0m\n\u001b[0;32m    209\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__array__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 211\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_ndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    212\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    213\u001b[0m     \u001b[0m_HANDLED_TYPES\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnumbers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mNumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'unit arab emir to launch spacecraft to moon in  '"
     ]
    }
   ],
   "source": [
    "params = {'solver': ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "               'C': [.0001, .001, .01, .1, 1], \n",
    "               'penalty': ['l1', 'l2']\n",
    "              }\n",
    "\n",
    "log_reg = LogisticRegression(C=1, random_state=42)\n",
    "\n",
    "clf = GridSearchCV(log_reg, params, cv=5)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "scores = clf.cv_results_['mean_test_score']\n",
    "   \n",
    "# ref: https://towardsdatascience.com/dont-sweat-the-solver-stuff-aea7cddc3451    \n",
    "\n",
    "# Get accuracy scores for train and test data\n",
    "printmd(f'**Accuracy score on train data: {clf.score(X_train, y_train):.3f}**')\n",
    "printmd(f'**Accuracy score on test data: {clf.score(X_test, y_test):.3f}**')\n",
    "printmd('**The model is still overfit**')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression model 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-296-47fa53af7e1c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlog_reg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train_tvec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     11\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'mean_test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[0;32m    734\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mresults\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    735\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 736\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    737\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    738\u001b[0m         \u001b[1;31m# For multi-metric evaluation, store the best_index_, best_params_ and\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36m_run_search\u001b[1;34m(self, evaluate_candidates)\u001b[0m\n\u001b[0;32m   1186\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_run_search\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1187\u001b[0m         \u001b[1;34m\"\"\"Search all candidates in param_grid\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1188\u001b[1;33m         \u001b[0mevaluate_candidates\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mParameterGrid\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparam_grid\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1190\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py\u001b[0m in \u001b[0;36mevaluate_candidates\u001b[1;34m(candidate_params)\u001b[0m\n\u001b[0;32m    706\u001b[0m                               n_splits, n_candidates, n_candidates * n_splits))\n\u001b[0;32m    707\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 708\u001b[1;33m                 out = parallel(delayed(_fit_and_score)(clone(base_estimator),\n\u001b[0m\u001b[0;32m    709\u001b[0m                                                        \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    710\u001b[0m                                                        \u001b[0mtrain\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrain\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1032\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1033\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    845\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 847\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    848\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    763\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    529\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 531\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    532\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    533\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m   1405\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1406\u001b[0m             \u001b[0mprefer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'processes'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1407\u001b[1;33m         fold_coefs_ = Parallel(n_jobs=self.n_jobs, verbose=self.verbose,\n\u001b[0m\u001b[0;32m   1408\u001b[0m                                \u001b[1;33m**\u001b[0m\u001b[0m_joblib_parallel_args\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mprefer\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mprefer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1409\u001b[0m             path_func(X, y, pos_class=class_, Cs=[C_],\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1027\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1028\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1029\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1030\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    845\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 847\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    848\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    849\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    763\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    764\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 765\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    766\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    767\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    250\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    251\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 252\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    253\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    254\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py\u001b[0m in \u001b[0;36m_logistic_regression_path\u001b[1;34m(X, y, pos_class, Cs, fit_intercept, max_iter, tol, verbose, solver, coef, class_weight, dual, penalty, intercept_scaling, multi_class, random_state, check_input, max_squared_sum, sample_weight, l1_ratio)\u001b[0m\n\u001b[0;32m    795\u001b[0m                 \u001b[0mbeta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m1.\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mC\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0ml1_ratio\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    796\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 797\u001b[1;33m             w0, n_iter_i, warm_start_sag = sag_solver(\n\u001b[0m\u001b[0;32m    798\u001b[0m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    799\u001b[0m                 \u001b[0mbeta\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     70\u001b[0m                           FutureWarning)\n\u001b[0;32m     71\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 72\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     73\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     74\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_sag.py\u001b[0m in \u001b[0;36msag_solver\u001b[1;34m(X, y, sample_weight, loss, alpha, beta, max_iter, tol, verbose, random_state, check_input, max_squared_sum, warm_start_mem, is_saga)\u001b[0m\n\u001b[0;32m    309\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m     \u001b[0msag\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msag64\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat64\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0msag32\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m     num_seen, n_iter_ = sag(dataset, coef_init,\n\u001b[0m\u001b[0;32m    312\u001b[0m                             \u001b[0mintercept_init\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_samples\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m                             \u001b[0mn_features\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_classes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "params = {'solver': ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'],\n",
    "               'C': [.0001, .001, .01, .1, 1], \n",
    "               'penalty': ['l1', 'l2']\n",
    "              }\n",
    "\n",
    "log_reg = LogisticRegression(C=1, random_state=42)\n",
    "\n",
    "clf = GridSearchCV(log_reg, params, cv=5)\n",
    "\n",
    "clf.fit(X_train_tvec, y_train)\n",
    "\n",
    "scores = clf.cv_results_['mean_test_score']\n",
    "   \n",
    "# ref: https://towardsdatascience.com/dont-sweat-the-solver-stuff-aea7cddc3451    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Grid searched:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'solver': ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga'],\n",
       " 'C': [0.0001, 0.001, 0.01, 0.1, 1],\n",
       " 'penalty': ['l1', 'l2']}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Best accuracy score**: 0.8267"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Best estimator / parameters:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, random_state=42, solver='liblinear')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'C': 1, 'penalty': 'l2', 'solver': 'liblinear'}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Accuracy score on train data: 0.959**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Accuracy score on test data: 0.835**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**The model is still overfit**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printmd('**Grid searched:**')\n",
    "display(clf.param_grid)\n",
    "printmd(f'**Best accuracy score**: {round(clf.best_score_, 4)}')\n",
    "printmd('**Best estimator / parameters:**')\n",
    "display(clf.best_estimator_)\n",
    "display(clf.best_params_)\n",
    "\n",
    "# Get accuracy scores for train and test data\n",
    "printmd(f'**Accuracy score on train data: {clf.score(X_train_tvec, y_train):.3f}**')\n",
    "printmd(f'**Accuracy score on test data: {clf.score(X_test_tvec, y_test):.3f}**')\n",
    "printmd('**The model is still overfit**')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, random_state=42, solver='liblinear')"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg = LogisticRegression(C = 1, penalty = 'l2', solver = 'liblinear', random_state=42)\n",
    "\n",
    "log_reg.fit(X_train_tvec, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([-0.13744292]),\n",
       " array([[-0.10524177,  0.62591884,  0.09646383, ...,  0.06160046,\n",
       "         -0.12670566,  0.06088419]]))"
      ]
     },
     "execution_count": 301,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_reg.intercept_, log_reg.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**The strongest coefficients start from the top in the table below.**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "***Holding all else constant, the effect of `studi` is a 4.6 times increase in predictive accuracy.***"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Coeff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>studi</th>\n",
       "      <td>4.569888</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>covid</th>\n",
       "      <td>2.735273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>suggest</th>\n",
       "      <td>2.426959</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new studi</th>\n",
       "      <td>2.098700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>research</th>\n",
       "      <td>2.056223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>increas</th>\n",
       "      <td>1.790901</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>effect</th>\n",
       "      <td>1.653257</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dure</th>\n",
       "      <td>1.635006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>peopl</th>\n",
       "      <td>1.596396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sarscov</th>\n",
       "      <td>1.549757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>men</th>\n",
       "      <td>1.524014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>new research</th>\n",
       "      <td>1.460708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>women</th>\n",
       "      <td>1.400299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>children</th>\n",
       "      <td>1.388924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reduc</th>\n",
       "      <td>1.366629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>like</th>\n",
       "      <td>1.334470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>associ</th>\n",
       "      <td>1.265025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>brain</th>\n",
       "      <td>1.252246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analysi</th>\n",
       "      <td>1.185132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adult</th>\n",
       "      <td>1.148202</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Coeff\n",
       "studi         4.569888\n",
       "covid         2.735273\n",
       "suggest       2.426959\n",
       "new studi     2.098700\n",
       "research      2.056223\n",
       "increas       1.790901\n",
       "effect        1.653257\n",
       "dure          1.635006\n",
       "peopl         1.596396\n",
       "sarscov       1.549757\n",
       "men           1.524014\n",
       "new research  1.460708\n",
       "women         1.400299\n",
       "children      1.388924\n",
       "reduc         1.366629\n",
       "like          1.334470\n",
       "associ        1.265025\n",
       "brain         1.252246\n",
       "analysi       1.185132\n",
       "adult         1.148202"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "printmd('**The strongest coefficients start from the top in the table below.**')\n",
    "printmd(f'***Holding all else constant, the effect of `studi` is a {log_reg_coef.T.iloc[0, 0]:.1f} times increase in predictive accuracy.***')\n",
    "\n",
    "log_reg_coef = pd.DataFrame(log_reg.coef_.T, index = X_train_tvec.columns, columns = ['Coeff']).sort_values('Coeff', ascending = False)\n",
    "display(log_reg_coef[:20])\n",
    "\n",
    "# Export to combine with other top 100 features that I'm able to pull from other models\n",
    "log_reg_coef[:100].to_csv('../data/feature_selection/feature_selection_logreg.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7844278316930147\n",
      "{'max_depth': 100, 'max_features': 'auto', 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "params_rf = {\n",
    "    'n_estimators': [25, 100],\n",
    "    'max_depth': [None, 100],\n",
    "    'max_features': ['auto', 500]\n",
    "        }\n",
    "\n",
    "\n",
    "gs_rf = GridSearchCV(rf, param_grid = params_rf)\n",
    "gs_rf.fit(X_train_cvec, y_train)\n",
    "\n",
    "print(gs_rf.best_score_)  # cross val score\n",
    "print(gs_rf.best_params_)  # cross val score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Grid searched:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': [100], 'max_depth': [100, 150], 'max_features': ['auto', 0.5]}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Best accuracy score**: 0.7911"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Best estimator / parameters:**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=150)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "{'max_depth': 150, 'max_features': 'auto', 'n_estimators': 100}"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Accuracy score on train data: 0.486**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Accuracy score on test data: 0.487**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**The model is still overfit**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "\n",
    "params_rf_2 = {\n",
    "    'n_estimators': [100],\n",
    "    'max_depth': [100, 150],\n",
    "    'max_features': ['auto', .5]\n",
    "        }\n",
    "\n",
    "\n",
    "gs_rf_2 = GridSearchCV(rf, param_grid = params_rf_2)\n",
    "gs_rf_2.fit(X_train_cvec, y_train)\n",
    "\n",
    "printmd('**Grid searched:**')\n",
    "display(gs_rf_2.param_grid)\n",
    "printmd(f'**Best accuracy score**: {round(gs_rf_2.best_score_, 4)}')\n",
    "printmd('**Best estimator / parameters:**')\n",
    "display(gs_rf_2.best_estimator_)\n",
    "display(gs_rf_2.best_params_)\n",
    "\n",
    "# Get accuracy scores for train and test data\n",
    "printmd(f'**Accuracy score on train data: {gs_rf_2.score(X_train_tvec, y_train):.3f}**')\n",
    "printmd(f'**Accuracy score on test data: {gs_rf_2.score(X_test_tvec, y_test):.3f}**')\n",
    "printmd('**The model is still overfit**')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br></br>\n",
    "\n",
    "<br></br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling with selected features\n",
    "\n",
    "### The methodology is to manually feature-select using the Random Forest and Logistic Regression models' \"best-of\" lists -- aka, the features with the highest weights / coefficients (respectively). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3137, 2)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>subreddit</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>robot encroach on up to  million job around the world</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>measur in ai polici opportun and challeng</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>how egypt is grow forest in middl of the desert</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>energi scaveng nanogener find power all around us</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>there are polit and cultur problem that occur with social chang in a societi with high andor rise life expect</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   subreddit  \\\n",
       "0          0   \n",
       "1          0   \n",
       "2          0   \n",
       "3          0   \n",
       "4          0   \n",
       "\n",
       "                                                                                                            title  \n",
       "0                                                          robot encroach on up to  million job around the world   \n",
       "1                                                                      measur in ai polici opportun and challeng   \n",
       "2                                                                how egypt is grow forest in middl of the desert   \n",
       "3                                                              energi scaveng nanogener find power all around us   \n",
       "4  there are polit and cultur problem that occur with social chang in a societi with high andor rise life expect   "
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the cleaned data\n",
    "subred = pd.read_csv('../data/cleaned_data/cleaned_df.csv')\n",
    "\n",
    "# Check its shape\n",
    "display(subred.shape)\n",
    "\n",
    "# Preview\n",
    "subred.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Set the features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set feature matrix and target variable\n",
    "X = subred['title']\n",
    "y = subred['subreddit']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identify an optimal model with a pipeline and GridSearch\n",
    "\n",
    "### Train-test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train shape: (2101,)\n",
      "y_train shape: (2101,) \n",
      "\n",
      "X_test shape: (1036,)\n",
      "y_test shape: (1036,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X,\n",
    "                                                    y,\n",
    "                                                    test_size = 0.33,\n",
    "                                                    stratify = y,             # equal balance of yes and no in train and test\n",
    "                                                    random_state = 42)\n",
    "\n",
    "print('X_train shape:', X_train.shape)\n",
    "print('y_train shape:', y_train.shape, '\\n')\n",
    "print('X_test shape:', X_test.shape)\n",
    "print('y_test shape:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Baseline accuracy\n",
    "\n",
    "**51.7% is the baseline accuracy percentage we compare with the model's accuracy.**\n",
    "\n",
    "**If the model does better than the baseline, then it is better than null model (predicting the majority / plurality class).**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Balance of classes in `y`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    0.501753\n",
       "1    0.498247\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Balance of classes in `y_train`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    0.501666\n",
       "1    0.498334\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "**Balance of classes in `y_test`**"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0    0.501931\n",
       "1    0.498069\n",
       "Name: subreddit, dtype: float64"
      ]
     },
     "execution_count": 312,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "printmd('**Balance of classes in `y`**')\n",
    "display(y.value_counts(normalize=True))\n",
    "\n",
    "printmd('**Balance of classes in `y_train`**')\n",
    "display(y_train.value_counts(normalize=True))\n",
    "\n",
    "printmd('**Balance of classes in `y_test`**')\n",
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "../data/feature_selection/feature_selection_logreg_randomforest_for_model.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
